{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abhinav1004/LongTailCLR/blob/main/BCCL_Training_CIFAR100.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IwWa7y9mB8la",
        "outputId": "fa103dfd-de6c-4283-b880-deb569532240"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/BCCL\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jE0IY1snCVKP",
        "outputId": "792915fa-d517-423d-c9d4-9bdccf256e52"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/BCCL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.getcwd())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubPln4esC8PJ",
        "outputId": "4334fce1-a6dc-438f-b296-29b40da68883"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/BCCL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kmeans_gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmuBIHLEDCR2",
        "outputId": "0f17b09e-0f1f-405b-850c-fbbbe46bedbe"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kmeans_gpu in /usr/local/lib/python3.11/dist-packages (0.0.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from kmeans_gpu) (2.5.1+cu124)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from kmeans_gpu) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->kmeans_gpu) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->kmeans_gpu) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->kmeans_gpu) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->kmeans_gpu) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->kmeans_gpu) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->kmeans_gpu) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->kmeans_gpu) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->kmeans_gpu) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->kmeans_gpu) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->kmeans_gpu) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->kmeans_gpu) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->kmeans_gpu) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->kmeans_gpu) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->kmeans_gpu) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->kmeans_gpu) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->kmeans_gpu) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->kmeans_gpu) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->kmeans_gpu) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->kmeans_gpu) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->kmeans_gpu) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->kmeans_gpu) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorboardx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6plkDIpDmAE",
        "outputId": "1919c046-eed3-4a3d-9b1d-4d559b1cbc71"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorboardx in /usr/local/lib/python3.11/dist-packages (2.6.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from tensorboardx) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboardx) (24.2)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.11/dist-packages (from tensorboardx) (4.25.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --dataset cifar100 \\\n",
        "  --arch resnet32 --epochs 200 --temp 0.1 \\\n",
        "  --lr 0.15 \\\n",
        "  --wd 5e-4 --cos True \\\n",
        "  -b 128 --feat_dim 128 --tb_save"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0xS2l0GC2Ao",
        "outputId": "063f781b-e42d-4127-e667-b98ecaaa37bd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data/cifar-100-python.tar.gz\n",
            "100% 169M/169M [00:03<00:00, 43.6MB/s]\n",
            "Extracting ./data/cifar-100-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "=> creating model 'resnet32'\n",
            "Model(\n",
            "  (encoder): ResNet(\n",
            "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (layer1): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (shortcut): Sequential()\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (shortcut): Sequential()\n",
            "      )\n",
            "      (2): BasicBlock(\n",
            "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (shortcut): Sequential()\n",
            "      )\n",
            "      (3): BasicBlock(\n",
            "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (shortcut): Sequential()\n",
            "      )\n",
            "      (4): BasicBlock(\n",
            "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (shortcut): Sequential()\n",
            "      )\n",
            "    )\n",
            "    (layer2): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (shortcut): LambdaLayer()\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (shortcut): Sequential()\n",
            "      )\n",
            "      (2): BasicBlock(\n",
            "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (shortcut): Sequential()\n",
            "      )\n",
            "      (3): BasicBlock(\n",
            "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (shortcut): Sequential()\n",
            "      )\n",
            "      (4): BasicBlock(\n",
            "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (shortcut): Sequential()\n",
            "      )\n",
            "    )\n",
            "    (layer3): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (shortcut): LambdaLayer()\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (shortcut): Sequential()\n",
            "      )\n",
            "      (2): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (shortcut): Sequential()\n",
            "      )\n",
            "      (3): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (shortcut): Sequential()\n",
            "      )\n",
            "      (4): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (shortcut): Sequential()\n",
            "      )\n",
            "    )\n",
            "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  )\n",
            "  (head): Sequential(\n",
            "    (0): Linear(in_features=64, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Linear(in_features=512, out_features=128, bias=True)\n",
            "  )\n",
            "  (fc): NormedLinear()\n",
            ")\n",
            "Training(E(1)): BT(0.258, 0.051) CE(5.2142, 4.0819) SCL_v(4.691508, 4.588756) Prec@1(0.484, 0.000): 100%|███████████████████████████████████████████████████████████████| 84/84 [00:21<00:00,  3.87it/s]\n",
            "Evaluating(E(1)): BT(1.940, 2.914) CE(6.1298, 6.2267) Prec@1(2.470, 6.250): 100%|█████████████████████████████████████| 79/79 [00:03<00:00, 25.94it/s]\n",
            "Best Prec@1: 2.470, Many Prec@1: 0.038, Med Prec@1: 0.011, Few Prec@1: 0.026\n",
            "Training(E(2)): BT(0.224, 0.070) CE(3.9450, 3.8245) SCL_v(4.528783, 4.497942) Prec@1(4.027, 8.594): 100%|███████████████████████████████████████████████████████████████| 84/84 [00:19<00:00,  4.42it/s]\n",
            "Evaluating(E(2)): BT(2.191, 3.129) CE(5.6780, 5.4058) Prec@1(4.390, 6.250): 100%|█████████████████████████████████████| 79/79 [00:03<00:00, 24.20it/s]\n",
            "Best Prec@1: 4.390, Many Prec@1: 0.069, Med Prec@1: 0.049, Few Prec@1: 0.008\n",
            "Training(E(3)): BT(0.212, 0.050) CE(3.8408, 3.8024) SCL_v(4.491168, 4.457479) Prec@1(5.664, 7.812): 100%|███████████████████████████████████████████████████████████████| 84/84 [00:17<00:00,  4.69it/s]\n",
            "Evaluating(E(3)): BT(1.934, 2.893) CE(5.4596, 5.2971) Prec@1(5.460, 6.250): 100%|█████████████████████████████████████| 79/79 [00:03<00:00, 26.11it/s]\n",
            "Best Prec@1: 5.460, Many Prec@1: 0.100, Med Prec@1: 0.051, Few Prec@1: 0.007\n",
            "Training(E(4)): BT(0.228, 0.051) CE(3.7921, 3.4760) SCL_v(4.460459, 4.273857) Prec@1(7.041, 7.812): 100%|███████████████████████████████████████████████████████████████| 84/84 [00:19<00:00,  4.35it/s]\n",
            "Evaluating(E(4)): BT(1.835, 2.783) CE(5.3396, 5.2944) Prec@1(7.040, 6.250): 100%|█████████████████████████████████████| 79/79 [00:02<00:00, 26.98it/s]\n",
            "Best Prec@1: 7.040, Many Prec@1: 0.134, Med Prec@1: 0.054, Few Prec@1: 0.015\n",
            "Training(E(5)): BT(0.213, 0.052) CE(3.7078, 3.4970) SCL_v(4.426186, 4.351931) Prec@1(8.278, 10.938): 100%|██████████████████████████████████████████████████████████████| 84/84 [00:18<00:00,  4.65it/s]\n",
            "Evaluating(E(5)): BT(1.872, 2.827) CE(5.2970, 5.3783) Prec@1(7.420, 12.500): 100%|████████████████████████████████████| 79/79 [00:02<00:00, 26.74it/s]\n",
            "Best Prec@1: 7.420, Many Prec@1: 0.139, Med Prec@1: 0.064, Few Prec@1: 0.010\n",
            "Training(E(6)): BT(0.231, 0.054) CE(3.6212, 3.6839) SCL_v(4.392083, 4.361555) Prec@1(10.035, 9.375): 100%|██████████████████████████████████████████████████████████████| 84/84 [00:19<00:00,  4.30it/s]\n",
            "Evaluating(E(6)): BT(1.854, 2.797) CE(5.1995, 5.2970) Prec@1(9.170, 6.250): 100%|█████████████████████████████████████| 79/79 [00:02<00:00, 27.00it/s]\n",
            "Best Prec@1: 9.170, Many Prec@1: 0.176, Med Prec@1: 0.081, Few Prec@1: 0.006\n",
            "Training(E(7)): BT(0.225, 0.053) CE(3.5906, 3.5572) SCL_v(4.364892, 4.307786) Prec@1(10.510, 16.406): 100%|█████████████████████████████████████████████████████████████| 84/84 [00:19<00:00,  4.40it/s]\n",
            "Evaluating(E(7)): BT(2.378, 3.714) CE(5.4618, 5.6472) Prec@1(8.700, 6.250): 100%|█████████████████████████████████████| 79/79 [00:03<00:00, 20.01it/s]\n",
            "Best Prec@1: 9.170, Many Prec@1: 0.176, Med Prec@1: 0.081, Few Prec@1: 0.006\n",
            "Training(E(8)): BT(0.217, 0.053) CE(3.5032, 3.4498) SCL_v(4.323048, 4.323273) Prec@1(12.184, 12.500): 100%|█████████████████████████████████████████████████████████████| 84/84 [00:18<00:00,  4.57it/s]\n",
            "Evaluating(E(8)): BT(1.889, 2.851) CE(5.2754, 5.4385) Prec@1(9.090, 6.250): 100%|█████████████████████████████████████| 79/79 [00:02<00:00, 26.46it/s]\n",
            "Best Prec@1: 9.170, Many Prec@1: 0.176, Med Prec@1: 0.081, Few Prec@1: 0.006\n",
            "Training(E(9)): BT(0.214, 0.053) CE(3.4390, 3.5959) SCL_v(4.282952, 4.224741) Prec@1(12.723, 10.938): 100%|█████████████████████████████████████████████████████████████| 84/84 [00:18<00:00,  4.61it/s]\n",
            "Evaluating(E(9)): BT(2.835, 4.067) CE(5.1381, 4.9081) Prec@1(9.160, 12.500): 100%|████████████████████████████████████| 79/79 [00:04<00:00, 18.82it/s]\n",
            "Best Prec@1: 9.170, Many Prec@1: 0.176, Med Prec@1: 0.081, Few Prec@1: 0.006\n",
            "Training(E(10)): BT(0.214, 0.054) CE(3.3661, 3.2355) SCL_v(4.231404, 4.087327) Prec@1(13.821, 13.281): 100%|████████████████████████████████████████████████████████████| 84/84 [00:18<00:00,  4.64it/s]\n",
            "Evaluating(E(10)): BT(1.918, 2.983) CE(5.0959, 5.4391) Prec@1(10.690, 0.000): 100%|███████████████████████████████████| 79/79 [00:03<00:00, 25.23it/s]\n",
            "Best Prec@1: 10.690, Many Prec@1: 0.203, Med Prec@1: 0.081, Few Prec@1: 0.025\n",
            "Training(E(11)): BT(1.047, 0.806) CE(3.3204, 3.3069) SCL_v(4.192471, 4.212643) CL(0.725588, 0.719917 Prec@1(15.123, 15.625): 100%|██████████████████████████████████████| 84/84 [01:28<00:00,  1.05s/it]\n",
            "Evaluating(E(11)): BT(1.917, 2.929) CE(5.1665, 5.8216) Prec@1(10.740, 12.500): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 25.49it/s]\n",
            "Best Prec@1: 10.740, Many Prec@1: 0.203, Med Prec@1: 0.079, Few Prec@1: 0.030\n",
            "Training(E(12)): BT(0.213, 0.054) CE(3.1815, 3.5411) SCL_v(4.153422, 4.212754) CL(0.700159, 0.678187 Prec@1(16.825, 11.719): 100%|██████████████████████████████████████| 84/84 [00:18<00:00,  4.65it/s]\n",
            "Evaluating(E(12)): BT(2.910, 4.185) CE(4.6315, 4.9103) Prec@1(13.210, 6.250): 100%|███████████████████████████████████| 79/79 [00:04<00:00, 18.23it/s]\n",
            "Best Prec@1: 13.210, Many Prec@1: 0.186, Med Prec@1: 0.167, Few Prec@1: 0.029\n",
            "Training(E(13)): BT(0.215, 0.056) CE(3.1174, 3.1331) SCL_v(4.094636, 4.179590) CL(0.615481, 0.530524 Prec@1(16.871, 21.094): 100%|██████████████████████████████████████| 84/84 [00:18<00:00,  4.60it/s]\n",
            "Evaluating(E(13)): BT(1.916, 2.879) CE(4.8400, 5.3304) Prec@1(15.680, 18.750): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 26.16it/s]\n",
            "Best Prec@1: 15.680, Many Prec@1: 0.275, Med Prec@1: 0.149, Few Prec@1: 0.028\n",
            "Training(E(14)): BT(0.224, 0.058) CE(3.0605, 2.8684) SCL_v(4.076307, 4.085629) CL(0.299358, 0.024538 Prec@1(18.415, 22.656): 100%|██████████████████████████████████████| 84/84 [00:19<00:00,  4.40it/s]\n",
            "Evaluating(E(14)): BT(2.238, 3.209) CE(4.9286, 5.1100) Prec@1(13.670, 12.500): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 23.61it/s]\n",
            "Best Prec@1: 15.680, Many Prec@1: 0.275, Med Prec@1: 0.149, Few Prec@1: 0.028\n",
            "Training(E(15)): BT(0.214, 0.055) CE(2.9855, 2.8902) SCL_v(4.033677, 4.043365) CL(-0.291309, -0.536839 Prec@1(19.206, 17.188): 100%|████████████████████████████████████| 84/84 [00:18<00:00,  4.63it/s]\n",
            "Evaluating(E(15)): BT(1.926, 2.889) CE(4.7948, 4.8379) Prec@1(15.970, 12.500): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 26.11it/s]\n",
            "Best Prec@1: 15.970, Many Prec@1: 0.254, Med Prec@1: 0.159, Few Prec@1: 0.050\n",
            "Training(E(16)): BT(0.232, 0.055) CE(2.9228, 3.0790) SCL_v(3.990044, 4.117136) CL(-0.616348, -0.654823 Prec@1(20.545, 22.656): 100%|████████████████████████████████████| 84/84 [00:19<00:00,  4.28it/s]\n",
            "Evaluating(E(16)): BT(1.903, 2.835) CE(4.9844, 4.7369) Prec@1(14.280, 25.000): 100%|██████████████████████████████████| 79/79 [00:02<00:00, 26.53it/s]\n",
            "Best Prec@1: 15.970, Many Prec@1: 0.254, Med Prec@1: 0.159, Few Prec@1: 0.050\n",
            "Training(E(17)): BT(0.214, 0.055) CE(2.8887, 2.9430) SCL_v(3.977850, 3.946423) CL(-0.674954, -0.671588 Prec@1(20.610, 20.312): 100%|████████████████████████████████████| 84/84 [00:18<00:00,  4.63it/s]\n",
            "Evaluating(E(17)): BT(2.178, 3.527) CE(4.6329, 4.8302) Prec@1(14.910, 12.500): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 20.96it/s]\n",
            "Best Prec@1: 15.970, Many Prec@1: 0.254, Med Prec@1: 0.159, Few Prec@1: 0.050\n",
            "Training(E(18)): BT(0.218, 0.054) CE(2.8250, 2.5199) SCL_v(3.928625, 3.902051) CL(-0.675032, -0.667137 Prec@1(22.098, 32.031): 100%|████████████████████████████████████| 84/84 [00:18<00:00,  4.55it/s]\n",
            "Evaluating(E(18)): BT(1.951, 2.986) CE(5.4942, 4.8879) Prec@1(10.920, 12.500): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 25.24it/s]\n",
            "Best Prec@1: 15.970, Many Prec@1: 0.254, Med Prec@1: 0.159, Few Prec@1: 0.050\n",
            "Training(E(19)): BT(0.212, 0.056) CE(2.7849, 2.8002) SCL_v(3.894855, 3.954314) CL(-0.670853, -0.680779 Prec@1(22.396, 21.875): 100%|████████████████████████████████████| 84/84 [00:18<00:00,  4.66it/s]\n",
            "Evaluating(E(19)): BT(2.843, 4.038) CE(4.3159, 4.3301) Prec@1(18.120, 6.250): 100%|███████████████████████████████████| 79/79 [00:04<00:00, 18.82it/s]\n",
            "Best Prec@1: 18.120, Many Prec@1: 0.262, Med Prec@1: 0.165, Few Prec@1: 0.106\n",
            "Training(E(20)): BT(0.213, 0.054) CE(2.7538, 3.0118) SCL_v(3.857379, 3.996003) CL(-0.665414, -0.670810 Prec@1(23.028, 19.531): 100%|████████████████████████████████████| 84/84 [00:18<00:00,  4.65it/s]\n",
            "Evaluating(E(20)): BT(1.898, 2.839) CE(4.6215, 5.1141) Prec@1(15.990, 0.000): 100%|███████████████████████████████████| 79/79 [00:02<00:00, 26.49it/s]\n",
            "Best Prec@1: 18.120, Many Prec@1: 0.262, Med Prec@1: 0.165, Few Prec@1: 0.106\n",
            "Training(E(21)): BT(1.018, 0.784) CE(2.6974, 2.7428) SCL_v(3.837310, 4.045988) CL(0.546808, 0.550358 Prec@1(23.782, 25.781): 100%|██████████████████████████████████████| 84/84 [01:25<00:00,  1.02s/it]\n",
            "Evaluating(E(21)): BT(1.914, 2.882) CE(4.3263, 4.1404) Prec@1(22.560, 37.500): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 26.13it/s]\n",
            "Best Prec@1: 22.560, Many Prec@1: 0.362, Med Prec@1: 0.199, Few Prec@1: 0.097\n",
            "Training(E(22)): BT(0.212, 0.054) CE(2.6818, 2.5319) SCL_v(3.837654, 3.824837) CL(0.546301, 0.541882 Prec@1(24.544, 21.875): 100%|██████████████████████████████████████| 84/84 [00:17<00:00,  4.69it/s]\n",
            "Evaluating(E(22)): BT(2.614, 4.002) CE(4.4040, 4.7249) Prec@1(20.660, 18.750): 100%|██████████████████████████████████| 79/79 [00:04<00:00, 18.82it/s]\n",
            "Best Prec@1: 22.560, Many Prec@1: 0.362, Med Prec@1: 0.199, Few Prec@1: 0.097\n",
            "Training(E(23)): BT(0.213, 0.053) CE(2.6206, 2.7900) SCL_v(3.798585, 3.869011) CL(0.517699, 0.498881 Prec@1(25.614, 22.656): 100%|██████████████████████████████████████| 84/84 [00:18<00:00,  4.66it/s]\n",
            "Evaluating(E(23)): BT(1.889, 2.825) CE(4.3029, 3.5275) Prec@1(21.290, 31.250): 100%|██████████████████████████████████| 79/79 [00:02<00:00, 26.62it/s]\n",
            "Best Prec@1: 22.560, Many Prec@1: 0.362, Med Prec@1: 0.199, Few Prec@1: 0.097\n",
            "Training(E(24)): BT(0.214, 0.055) CE(2.5673, 2.3415) SCL_v(3.770307, 3.835542) CL(0.402621, 0.284292 Prec@1(25.381, 30.469): 100%|██████████████████████████████████████| 84/84 [00:18<00:00,  4.63it/s]\n",
            "Evaluating(E(24)): BT(2.904, 4.103) CE(4.0202, 4.0046) Prec@1(22.100, 18.750): 100%|██████████████████████████████████| 79/79 [00:04<00:00, 18.61it/s]\n",
            "Best Prec@1: 22.560, Many Prec@1: 0.362, Med Prec@1: 0.199, Few Prec@1: 0.097\n",
            "Training(E(25)): BT(0.214, 0.054) CE(2.5755, 2.5686) SCL_v(3.792254, 3.596173) CL(0.078769, -0.145095 Prec@1(26.302, 27.344): 100%|█████████████████████████████████████| 84/84 [00:18<00:00,  4.63it/s]\n",
            "Evaluating(E(25)): BT(1.930, 2.883) CE(4.5778, 4.7621) Prec@1(21.150, 6.250): 100%|███████████████████████████████████| 79/79 [00:03<00:00, 26.16it/s]\n",
            "Best Prec@1: 22.560, Many Prec@1: 0.362, Med Prec@1: 0.199, Few Prec@1: 0.097\n",
            "Training(E(26)): BT(0.219, 0.065) CE(2.5185, 2.5884) SCL_v(3.730801, 3.843692) CL(-0.308558, -0.437614 Prec@1(27.232, 28.906): 100%|████████████████████████████████████| 84/84 [00:18<00:00,  4.50it/s]\n",
            "Evaluating(E(26)): BT(2.130, 3.060) CE(4.1499, 4.5480) Prec@1(21.570, 6.250): 100%|███████████████████████████████████| 79/79 [00:03<00:00, 24.71it/s]\n",
            "Best Prec@1: 22.560, Many Prec@1: 0.362, Med Prec@1: 0.199, Few Prec@1: 0.097\n",
            "Training(E(27)): BT(0.213, 0.054) CE(2.5331, 2.8290) SCL_v(3.736874, 3.822887) CL(-0.480644, -0.517824 Prec@1(26.925, 19.531): 100%|████████████████████████████████████| 84/84 [00:17<00:00,  4.67it/s]\n",
            "Evaluating(E(27)): BT(1.907, 2.842) CE(5.2206, 5.4444) Prec@1(14.000, 6.250): 100%|███████████████████████████████████| 79/79 [00:02<00:00, 26.51it/s]\n",
            "Best Prec@1: 22.560, Many Prec@1: 0.362, Med Prec@1: 0.199, Few Prec@1: 0.097\n",
            "Training(E(28)): BT(0.230, 0.053) CE(2.5058, 2.4526) SCL_v(3.718420, 3.716455) CL(-0.524899, -0.523319 Prec@1(27.911, 27.344): 100%|████████████████████████████████████| 84/84 [00:19<00:00,  4.32it/s]\n",
            "Evaluating(E(28)): BT(1.906, 2.853) CE(4.2255, 4.7922) Prec@1(24.230, 6.250): 100%|███████████████████████████████████| 79/79 [00:02<00:00, 26.41it/s]\n",
            "Best Prec@1: 24.230, Many Prec@1: 0.351, Med Prec@1: 0.237, Few Prec@1: 0.122\n",
            "Training(E(29)): BT(0.210, 0.053) CE(2.4419, 2.4148) SCL_v(3.695033, 3.547938) CL(-0.532732, -0.530347 Prec@1(28.776, 26.562): 100%|████████████████████████████████████| 84/84 [00:17<00:00,  4.71it/s]\n",
            "Evaluating(E(29)): BT(2.226, 3.639) CE(4.1919, 3.7657) Prec@1(20.620, 25.000): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 20.43it/s]\n",
            "Best Prec@1: 24.230, Many Prec@1: 0.351, Med Prec@1: 0.237, Few Prec@1: 0.122\n",
            "Training(E(30)): BT(0.224, 0.054) CE(2.4276, 2.5010) SCL_v(3.679346, 3.658657) CL(-0.536732, -0.529270 Prec@1(29.157, 28.125): 100%|████████████████████████████████████| 84/84 [00:18<00:00,  4.43it/s]\n",
            "Evaluating(E(30)): BT(1.892, 2.823) CE(4.1099, 3.9845) Prec@1(24.740, 18.750): 100%|██████████████████████████████████| 79/79 [00:02<00:00, 26.47it/s]\n",
            "Best Prec@1: 24.740, Many Prec@1: 0.341, Med Prec@1: 0.277, Few Prec@1: 0.104\n",
            "Training(E(31)): BT(1.000, 1.088) CE(2.4021, 2.2862) SCL_v(3.672288, 3.613724) CL(0.487859, 0.490743 Prec@1(29.613, 28.906): 100%|██████████████████████████████████████| 84/84 [01:24<00:00,  1.00s/it]\n",
            "Evaluating(E(31)): BT(2.408, 3.366) CE(4.2406, 4.1376) Prec@1(21.570, 18.750): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 22.47it/s]\n",
            "Best Prec@1: 24.740, Many Prec@1: 0.341, Med Prec@1: 0.277, Few Prec@1: 0.104\n",
            "Training(E(32)): BT(0.211, 0.053) CE(2.3986, 2.2408) SCL_v(3.643210, 3.457518) CL(0.485557, 0.480125 Prec@1(29.474, 32.031): 100%|██████████████████████████████████████| 84/84 [00:17<00:00,  4.70it/s]\n",
            "Evaluating(E(32)): BT(1.879, 2.818) CE(4.2016, 3.8157) Prec@1(24.910, 12.500): 100%|██████████████████████████████████| 79/79 [00:02<00:00, 26.69it/s]\n",
            "Best Prec@1: 24.910, Many Prec@1: 0.361, Med Prec@1: 0.252, Few Prec@1: 0.115\n",
            "Training(E(33)): BT(0.226, 0.067) CE(2.4095, 2.6611) SCL_v(3.660113, 3.541526) CL(0.461163, 0.436727 Prec@1(29.678, 22.656): 100%|██████████████████████████████████████| 84/84 [00:19<00:00,  4.38it/s]\n",
            "Evaluating(E(33)): BT(2.068, 3.023) CE(3.6998, 3.8864) Prec@1(27.550, 6.250): 100%|███████████████████████████████████| 79/79 [00:03<00:00, 24.85it/s]\n",
            "Best Prec@1: 27.550, Many Prec@1: 0.370, Med Prec@1: 0.312, Few Prec@1: 0.122\n",
            "Training(E(34)): BT(0.208, 0.055) CE(2.3434, 2.3702) SCL_v(3.637317, 3.572849) CL(0.357076, 0.264053 Prec@1(30.748, 27.344): 100%|██████████████████████████████████████| 84/84 [00:17<00:00,  4.77it/s]\n",
            "Evaluating(E(34)): BT(1.862, 2.786) CE(4.1611, 4.1838) Prec@1(24.140, 25.000): 100%|██████████████████████████████████| 79/79 [00:02<00:00, 27.05it/s]\n",
            "Best Prec@1: 27.550, Many Prec@1: 0.370, Med Prec@1: 0.312, Few Prec@1: 0.122\n",
            "Training(E(35)): BT(0.230, 0.054) CE(2.3167, 2.4432) SCL_v(3.613475, 3.786025) CL(0.098556, -0.062197 Prec@1(30.841, 27.344): 100%|█████████████████████████████████████| 84/84 [00:19<00:00,  4.32it/s]\n",
            "Evaluating(E(35)): BT(1.867, 2.822) CE(4.3974, 4.0134) Prec@1(24.890, 25.000): 100%|██████████████████████████████████| 79/79 [00:02<00:00, 26.65it/s]\n",
            "Best Prec@1: 27.550, Many Prec@1: 0.370, Med Prec@1: 0.312, Few Prec@1: 0.122\n",
            "Training(E(36)): BT(0.212, 0.054) CE(2.3071, 2.4305) SCL_v(3.596772, 3.778206) CL(-0.204288, -0.323856 Prec@1(30.738, 31.250): 100%|████████████████████████████████████| 84/84 [00:17<00:00,  4.68it/s]\n",
            "Evaluating(E(36)): BT(2.403, 3.762) CE(4.8303, 5.2731) Prec@1(19.890, 12.500): 100%|██████████████████████████████████| 79/79 [00:04<00:00, 19.61it/s]\n",
            "Best Prec@1: 27.550, Many Prec@1: 0.370, Med Prec@1: 0.312, Few Prec@1: 0.122\n",
            "Training(E(37)): BT(0.210, 0.053) CE(2.2963, 1.9641) SCL_v(3.605757, 3.462542) CL(-0.387712, -0.446414 Prec@1(31.929, 34.375): 100%|████████████████████████████████████| 84/84 [00:17<00:00,  4.73it/s]\n",
            "Evaluating(E(37)): BT(1.860, 2.801) CE(4.0110, 3.9559) Prec@1(24.100, 18.750): 100%|██████████████████████████████████| 79/79 [00:02<00:00, 26.85it/s]\n",
            "Best Prec@1: 27.550, Many Prec@1: 0.370, Med Prec@1: 0.312, Few Prec@1: 0.122\n",
            "Training(E(38)): BT(0.210, 0.066) CE(2.2373, 2.6019) SCL_v(3.569644, 3.540709) CL(-0.450974, -0.467971 Prec@1(32.561, 37.500): 100%|████████████████████████████████████| 84/84 [00:17<00:00,  4.70it/s]\n",
            "Evaluating(E(38)): BT(2.807, 3.944) CE(3.9774, 4.3018) Prec@1(27.630, 43.750): 100%|██████████████████████████████████| 79/79 [00:04<00:00, 19.34it/s]\n",
            "Best Prec@1: 27.630, Many Prec@1: 0.403, Med Prec@1: 0.300, Few Prec@1: 0.100\n",
            "Training(E(39)): BT(0.219, 0.054) CE(2.2719, 2.4592) SCL_v(3.567395, 3.683855) CL(-0.475702, -0.476576 Prec@1(32.013, 32.812): 100%|████████████████████████████████████| 84/84 [00:18<00:00,  4.53it/s]\n",
            "Evaluating(E(39)): BT(1.935, 2.899) CE(4.0901, 4.1484) Prec@1(26.820, 18.750): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 26.02it/s]\n",
            "Best Prec@1: 27.630, Many Prec@1: 0.403, Med Prec@1: 0.300, Few Prec@1: 0.100\n",
            "Training(E(40)): BT(0.222, 0.065) CE(2.2395, 2.2478) SCL_v(3.552777, 3.533365) CL(-0.481757, -0.484836 Prec@1(33.166, 31.250): 100%|████████████████████████████████████| 84/84 [00:18<00:00,  4.45it/s]\n",
            "Evaluating(E(40)): BT(2.249, 3.270) CE(3.7878, 3.5187) Prec@1(27.860, 18.750): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 23.17it/s]\n",
            "Best Prec@1: 27.860, Many Prec@1: 0.381, Med Prec@1: 0.309, Few Prec@1: 0.124\n",
            "Training(E(41)): BT(0.986, 0.755) CE(2.2232, 2.3781) SCL_v(3.551702, 3.635012) CL(0.452250, 0.457224 Prec@1(32.757, 30.469): 100%|██████████████████████████████████████| 84/84 [01:22<00:00,  1.01it/s]\n",
            "Evaluating(E(41)): BT(1.914, 2.972) CE(3.9645, 4.3811) Prec@1(26.440, 12.500): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 24.52it/s]\n",
            "Best Prec@1: 27.860, Many Prec@1: 0.381, Med Prec@1: 0.309, Few Prec@1: 0.124\n",
            "Training(E(42)): BT(0.226, 0.053) CE(2.1919, 2.3572) SCL_v(3.546358, 3.700928) CL(0.453538, 0.451525 Prec@1(33.947, 29.688): 100%|██████████████████████████████████████| 84/84 [00:19<00:00,  4.40it/s]\n",
            "Evaluating(E(42)): BT(1.853, 2.772) CE(3.8923, 3.8456) Prec@1(26.670, 12.500): 100%|██████████████████████████████████| 79/79 [00:02<00:00, 27.09it/s]\n",
            "Best Prec@1: 27.860, Many Prec@1: 0.381, Med Prec@1: 0.309, Few Prec@1: 0.124\n",
            "Training(E(43)): BT(0.210, 0.055) CE(2.1865, 2.0325) SCL_v(3.520601, 3.472305) CL(0.440796, 0.440258 Prec@1(33.808, 34.375): 100%|██████████████████████████████████████| 84/84 [00:17<00:00,  4.73it/s]\n",
            "Evaluating(E(43)): BT(2.857, 4.039) CE(4.2153, 3.9977) Prec@1(22.220, 25.000): 100%|██████████████████████████████████| 79/79 [00:04<00:00, 18.91it/s]\n",
            "Best Prec@1: 27.860, Many Prec@1: 0.381, Med Prec@1: 0.309, Few Prec@1: 0.124\n",
            "Training(E(44)): BT(0.209, 0.054) CE(2.1682, 2.2727) SCL_v(3.527616, 3.444818) CL(0.400096, 0.345275 Prec@1(34.394, 34.375): 100%|██████████████████████████████████████| 84/84 [00:17<00:00,  4.74it/s]\n",
            "Evaluating(E(44)): BT(1.866, 2.857) CE(3.6672, 3.2854) Prec@1(28.000, 37.500): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 26.12it/s]\n",
            "Best Prec@1: 28.000, Many Prec@1: 0.380, Med Prec@1: 0.287, Few Prec@1: 0.155\n",
            "Training(E(45)): BT(0.214, 0.060) CE(2.1770, 2.2204) SCL_v(3.547641, 3.527774) CL(0.262205, 0.153777 Prec@1(33.454, 41.406): 100%|██████████████████████████████████████| 84/84 [00:18<00:00,  4.60it/s]\n",
            "Evaluating(E(45)): BT(2.274, 3.211) CE(3.7641, 3.6053) Prec@1(29.390, 37.500): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 23.50it/s]\n",
            "Best Prec@1: 29.390, Many Prec@1: 0.395, Med Prec@1: 0.314, Few Prec@1: 0.153\n",
            "Training(E(46)): BT(0.212, 0.055) CE(2.1290, 2.0485) SCL_v(3.519476, 3.510862) CL(-0.011088, -0.163534 Prec@1(35.268, 40.625): 100%|████████████████████████████████████| 84/84 [00:17<00:00,  4.68it/s]\n",
            "Evaluating(E(46)): BT(1.828, 2.742) CE(3.9998, 4.2189) Prec@1(23.100, 6.250): 100%|███████████████████████████████████| 79/79 [00:02<00:00, 27.23it/s]\n",
            "Best Prec@1: 29.390, Many Prec@1: 0.395, Med Prec@1: 0.314, Few Prec@1: 0.153\n",
            "Training(E(47)): BT(0.221, 0.094) CE(2.1607, 2.2716) SCL_v(3.524070, 3.605415) CL(-0.278891, -0.359396 Prec@1(35.175, 39.844): 100%|████████████████████████████████████| 84/84 [00:18<00:00,  4.47it/s]\n",
            "Evaluating(E(47)): BT(1.914, 2.853) CE(4.1612, 4.2331) Prec@1(25.360, 31.250): 100%|██████████████████████████████████| 79/79 [00:02<00:00, 26.43it/s]\n",
            "Best Prec@1: 29.390, Many Prec@1: 0.395, Med Prec@1: 0.314, Few Prec@1: 0.153\n",
            "Training(E(48)): BT(0.207, 0.054) CE(2.1139, 2.3386) SCL_v(3.483625, 3.364802) CL(-0.386168, -0.414362 Prec@1(34.961, 30.469): 100%|████████████████████████████████████| 84/84 [00:17<00:00,  4.79it/s]\n",
            "Evaluating(E(48)): BT(1.881, 2.838) CE(3.7689, 4.2499) Prec@1(29.630, 6.250): 100%|███████████████████████████████████| 79/79 [00:02<00:00, 26.53it/s]\n",
            "Best Prec@1: 29.630, Many Prec@1: 0.408, Med Prec@1: 0.326, Few Prec@1: 0.131\n",
            "Training(E(49)): BT(0.230, 0.055) CE(2.0975, 1.8826) SCL_v(3.509306, 3.491417) CL(-0.432504, -0.439223 Prec@1(35.658, 35.156): 100%|████████████████████████████████████| 84/84 [00:19<00:00,  4.32it/s]\n",
            "Evaluating(E(49)): BT(1.861, 2.788) CE(3.7057, 3.9244) Prec@1(30.170, 18.750): 100%|██████████████████████████████████| 79/79 [00:02<00:00, 26.87it/s]\n",
            "Best Prec@1: 30.170, Many Prec@1: 0.420, Med Prec@1: 0.311, Few Prec@1: 0.153\n",
            "Training(E(50)): BT(0.213, 0.053) CE(2.0683, 2.4055) SCL_v(3.473660, 3.657097) CL(-0.448428, -0.455061 Prec@1(36.235, 33.594): 100%|████████████████████████████████████| 84/84 [00:18<00:00,  4.66it/s]\n",
            "Evaluating(E(50)): BT(2.285, 3.630) CE(3.9242, 3.8612) Prec@1(27.910, 18.750): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 20.53it/s]\n",
            "Best Prec@1: 30.170, Many Prec@1: 0.420, Med Prec@1: 0.311, Few Prec@1: 0.153\n",
            "Training(E(51)): BT(0.984, 0.760) CE(2.0693, 2.0365) SCL_v(3.470522, 3.412040) CL(0.425540, 0.433974 Prec@1(36.551, 34.375): 100%|██████████████████████████████████████| 84/84 [01:22<00:00,  1.01it/s]\n",
            "Evaluating(E(51)): BT(2.077, 3.055) CE(3.5316, 3.6215) Prec@1(29.270, 31.250): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 24.74it/s]\n",
            "Best Prec@1: 30.170, Many Prec@1: 0.420, Med Prec@1: 0.311, Few Prec@1: 0.153\n",
            "Training(E(52)): BT(0.216, 0.069) CE(2.0611, 2.0885) SCL_v(3.462465, 3.335137) CL(0.422286, 0.416184 Prec@1(35.975, 35.938): 100%|██████████████████████████████████████| 84/84 [00:18<00:00,  4.58it/s]\n",
            "Evaluating(E(52)): BT(2.595, 3.638) CE(3.4555, 3.0659) Prec@1(29.870, 31.250): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 20.79it/s]\n",
            "Best Prec@1: 30.170, Many Prec@1: 0.420, Med Prec@1: 0.311, Few Prec@1: 0.153\n",
            "Training(E(53)): BT(0.246, 0.055) CE(2.0472, 1.9453) SCL_v(3.460330, 3.399136) CL(0.407543, 0.393380 Prec@1(36.905, 42.969): 100%|██████████████████████████████████████| 84/84 [00:20<00:00,  4.04it/s]\n",
            "Evaluating(E(53)): BT(2.396, 3.762) CE(4.3714, 4.6579) Prec@1(24.530, 18.750): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 19.85it/s]\n",
            "Best Prec@1: 30.170, Many Prec@1: 0.420, Med Prec@1: 0.311, Few Prec@1: 0.153\n",
            "Training(E(54)): BT(0.222, 0.055) CE(2.0193, 2.3292) SCL_v(3.470943, 3.629120) CL(0.347470, 0.275737 Prec@1(37.640, 36.719): 100%|██████████████████████████████████████| 84/84 [00:18<00:00,  4.47it/s]\n",
            "Evaluating(E(54)): BT(1.873, 2.803) CE(3.3212, 2.9380) Prec@1(30.350, 25.000): 100%|██████████████████████████████████| 79/79 [00:02<00:00, 26.82it/s]\n",
            "Best Prec@1: 30.350, Many Prec@1: 0.404, Med Prec@1: 0.306, Few Prec@1: 0.183\n",
            "Training(E(55)): BT(0.210, 0.053) CE(2.0216, 2.0054) SCL_v(3.428768, 3.453022) CL(0.170469, 0.046655 Prec@1(37.026, 35.938): 100%|██████████████████████████████████████| 84/84 [00:17<00:00,  4.72it/s]\n",
            "Evaluating(E(55)): BT(2.612, 4.080) CE(3.7948, 3.7500) Prec@1(27.590, 31.250): 100%|██████████████████████████████████| 79/79 [00:04<00:00, 18.37it/s]\n",
            "Best Prec@1: 30.350, Many Prec@1: 0.404, Med Prec@1: 0.306, Few Prec@1: 0.183\n",
            "Training(E(56)): BT(0.207, 0.053) CE(1.9928, 2.1747) SCL_v(3.431197, 3.646484) CL(-0.088041, -0.213433 Prec@1(37.174, 33.594): 100%|████████████████████████████████████| 84/84 [00:17<00:00,  4.80it/s]\n",
            "Evaluating(E(56)): BT(1.869, 2.822) CE(3.5140, 3.5521) Prec@1(30.330, 31.250): 100%|██████████████████████████████████| 79/79 [00:02<00:00, 26.61it/s]\n",
            "Best Prec@1: 30.350, Many Prec@1: 0.404, Med Prec@1: 0.306, Few Prec@1: 0.183\n",
            "Training(E(57)): BT(0.212, 0.060) CE(2.0206, 2.1118) SCL_v(3.445212, 3.725918) CL(-0.278757, -0.333221 Prec@1(37.230, 35.938): 100%|████████████████████████████████████| 84/84 [00:18<00:00,  4.66it/s]\n",
            "Evaluating(E(57)): BT(2.657, 3.703) CE(3.4170, 3.5867) Prec@1(30.110, 37.500): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 20.48it/s]\n",
            "Best Prec@1: 30.350, Many Prec@1: 0.404, Med Prec@1: 0.306, Few Prec@1: 0.183\n",
            "Training(E(58)): BT(0.208, 0.055) CE(1.9811, 2.0098) SCL_v(3.387812, 3.161874) CL(-0.367867, -0.394912 Prec@1(37.695, 41.406): 100%|████████████████████████████████████| 84/84 [00:17<00:00,  4.76it/s]\n",
            "Evaluating(E(58)): BT(1.880, 2.795) CE(3.5777, 3.5994) Prec@1(32.670, 43.750): 100%|██████████████████████████████████| 79/79 [00:02<00:00, 26.89it/s]\n",
            "Best Prec@1: 32.670, Many Prec@1: 0.465, Med Prec@1: 0.317, Few Prec@1: 0.176\n",
            "Training(E(59)): BT(0.219, 0.057) CE(1.9979, 2.0210) SCL_v(3.440085, 3.419113) CL(-0.404685, -0.398432 Prec@1(38.374, 37.500): 100%|████████████████████████████████████| 84/84 [00:18<00:00,  4.51it/s]\n",
            "Evaluating(E(59)): BT(2.119, 3.051) CE(3.5503, 3.2201) Prec@1(31.110, 25.000): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 24.72it/s]\n",
            "Best Prec@1: 32.670, Many Prec@1: 0.465, Med Prec@1: 0.317, Few Prec@1: 0.176\n",
            "Training(E(60)): BT(0.212, 0.054) CE(1.9573, 2.1727) SCL_v(3.419805, 3.622110) CL(-0.420224, -0.439255 Prec@1(37.993, 31.250): 100%|████████████████████████████████████| 84/84 [00:17<00:00,  4.68it/s]\n",
            "Evaluating(E(60)): BT(1.866, 2.797) CE(3.3838, 3.4230) Prec@1(33.480, 31.250): 100%|██████████████████████████████████| 79/79 [00:02<00:00, 26.72it/s]\n",
            "Best Prec@1: 33.480, Many Prec@1: 0.455, Med Prec@1: 0.357, Few Prec@1: 0.169\n",
            "Training(E(61)): BT(1.006, 0.793) CE(1.9809, 2.0335) SCL_v(3.427618, 3.385776) CL(0.420211, 0.430691 Prec@1(37.928, 41.406): 100%|██████████████████████████████████████| 84/84 [01:24<00:00,  1.01s/it]\n",
            "Evaluating(E(61)): BT(1.914, 2.866) CE(3.5503, 2.9780) Prec@1(29.840, 37.500): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 26.27it/s]\n",
            "Best Prec@1: 33.480, Many Prec@1: 0.455, Med Prec@1: 0.357, Few Prec@1: 0.169\n",
            "Training(E(62)): BT(0.214, 0.054) CE(1.9689, 1.9353) SCL_v(3.401210, 3.460885) CL(0.415900, 0.405481 Prec@1(38.616, 33.594): 100%|██████████████████████████████████████| 84/84 [00:18<00:00,  4.64it/s]\n",
            "Evaluating(E(62)): BT(2.451, 3.808) CE(3.5040, 3.3146) Prec@1(29.710, 37.500): 100%|██████████████████████████████████| 79/79 [00:04<00:00, 19.54it/s]\n",
            "Best Prec@1: 33.480, Many Prec@1: 0.455, Med Prec@1: 0.357, Few Prec@1: 0.169\n",
            "Training(E(63)): BT(0.216, 0.054) CE(1.9417, 2.0154) SCL_v(3.390569, 3.617058) CL(0.398782, 0.389528 Prec@1(38.951, 39.062): 100%|██████████████████████████████████████| 84/84 [00:18<00:00,  4.59it/s]\n",
            "Evaluating(E(63)): BT(1.924, 2.874) CE(3.6520, 3.4326) Prec@1(28.070, 25.000): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 26.18it/s]\n",
            "Best Prec@1: 33.480, Many Prec@1: 0.455, Med Prec@1: 0.357, Few Prec@1: 0.169\n",
            "Training(E(64)): BT(0.217, 0.058) CE(1.9459, 1.8951) SCL_v(3.375220, 3.220977) CL(0.345610, 0.276106 Prec@1(38.858, 41.406): 100%|██████████████████████████████████████| 84/84 [00:18<00:00,  4.55it/s]\n",
            "Evaluating(E(64)): BT(2.883, 3.993) CE(3.4708, 3.9156) Prec@1(32.280, 12.500): 100%|██████████████████████████████████| 79/79 [00:04<00:00, 19.10it/s]\n",
            "Best Prec@1: 33.480, Many Prec@1: 0.455, Med Prec@1: 0.357, Few Prec@1: 0.169\n",
            "Training(E(65)): BT(0.216, 0.058) CE(1.9490, 1.7466) SCL_v(3.383562, 3.188284) CL(0.191515, 0.082008 Prec@1(38.588, 45.312): 100%|██████████████████████████████████████| 84/84 [00:18<00:00,  4.59it/s]\n",
            "Evaluating(E(65)): BT(1.892, 2.829) CE(3.5384, 3.1676) Prec@1(32.070, 43.750): 100%|██████████████████████████████████| 79/79 [00:02<00:00, 26.60it/s]\n",
            "Best Prec@1: 33.480, Many Prec@1: 0.455, Med Prec@1: 0.357, Few Prec@1: 0.169\n",
            "Training(E(66)): BT(0.230, 0.053) CE(1.9427, 2.0836) SCL_v(3.378976, 3.548881) CL(-0.051742, -0.162532 Prec@1(39.862, 39.062): 100%|████████████████████████████████████| 84/84 [00:19<00:00,  4.31it/s]\n",
            "Evaluating(E(66)): BT(1.922, 2.919) CE(3.5629, 3.5938) Prec@1(30.780, 25.000): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 25.64it/s]\n",
            "Best Prec@1: 33.480, Many Prec@1: 0.455, Med Prec@1: 0.357, Few Prec@1: 0.169\n",
            "Training(E(67)): BT(0.211, 0.053) CE(1.9349, 1.9315) SCL_v(3.382509, 3.448134) CL(-0.241080, -0.313442 Prec@1(39.314, 39.844): 100%|████████████████████████████████████| 84/84 [00:17<00:00,  4.71it/s]\n",
            "Evaluating(E(67)): BT(1.981, 3.114) CE(3.7868, 3.7731) Prec@1(26.860, 12.500): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 23.61it/s]\n",
            "Best Prec@1: 33.480, Many Prec@1: 0.455, Med Prec@1: 0.357, Few Prec@1: 0.169\n",
            "Training(E(68)): BT(0.236, 0.055) CE(1.9326, 2.1696) SCL_v(3.381656, 3.646227) CL(-0.341859, -0.374605 Prec@1(39.658, 39.844): 100%|████████████████████████████████████| 84/84 [00:19<00:00,  4.21it/s]\n",
            "Evaluating(E(68)): BT(1.897, 2.835) CE(3.4478, 3.5511) Prec@1(32.410, 31.250): 100%|██████████████████████████████████| 79/79 [00:02<00:00, 26.56it/s]\n",
            "Best Prec@1: 33.480, Many Prec@1: 0.455, Med Prec@1: 0.357, Few Prec@1: 0.169\n",
            "Training(E(69)): BT(0.213, 0.063) CE(1.9219, 1.9621) SCL_v(3.364992, 3.317456) CL(-0.388612, -0.399591 Prec@1(39.983, 36.719): 100%|████████████████████████████████████| 84/84 [00:18<00:00,  4.63it/s]\n",
            "Evaluating(E(69)): BT(2.584, 3.596) CE(3.4901, 3.1745) Prec@1(31.760, 31.250): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 21.12it/s]\n",
            "Best Prec@1: 33.480, Many Prec@1: 0.455, Med Prec@1: 0.357, Few Prec@1: 0.169\n",
            "Training(E(70)): BT(0.208, 0.054) CE(1.9016, 2.0860) SCL_v(3.348441, 3.451325) CL(-0.406665, -0.424283 Prec@1(40.197, 35.938): 100%|████████████████████████████████████| 84/84 [00:17<00:00,  4.76it/s]\n",
            "Evaluating(E(70)): BT(1.929, 2.889) CE(3.6498, 3.9723) Prec@1(32.580, 18.750): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 26.01it/s]\n",
            "Best Prec@1: 33.480, Many Prec@1: 0.455, Med Prec@1: 0.357, Few Prec@1: 0.169\n",
            "Training(E(71)): BT(0.996, 1.020) CE(1.8946, 1.8338) SCL_v(3.343340, 3.180888) CL(0.401592, 0.404509 Prec@1(40.644, 46.875): 100%|██████████████████████████████████████| 84/84 [01:23<00:00,  1.00it/s]\n",
            "Evaluating(E(71)): BT(1.888, 2.829) CE(3.8277, 3.7798) Prec@1(24.240, 31.250): 100%|██████████████████████████████████| 79/79 [00:02<00:00, 26.47it/s]\n",
            "Best Prec@1: 33.480, Many Prec@1: 0.455, Med Prec@1: 0.357, Few Prec@1: 0.169\n",
            "Training(E(72)): BT(0.212, 0.053) CE(1.8992, 1.8599) SCL_v(3.342365, 3.440022) CL(0.402998, 0.406950 Prec@1(40.076, 42.188): 100%|██████████████████████████████████████| 84/84 [00:17<00:00,  4.68it/s]\n",
            "Evaluating(E(72)): BT(1.896, 2.843) CE(3.6162, 3.1227) Prec@1(31.780, 37.500): 100%|██████████████████████████████████| 79/79 [00:02<00:00, 26.38it/s]\n",
            "Best Prec@1: 33.480, Many Prec@1: 0.455, Med Prec@1: 0.357, Few Prec@1: 0.169\n",
            "Training(E(73)): BT(0.228, 0.052) CE(1.9214, 1.8331) SCL_v(3.374593, 3.300143) CL(0.393674, 0.390309 Prec@1(39.602, 40.625): 100%|██████████████████████████████████████| 84/84 [00:19<00:00,  4.36it/s]\n",
            "Evaluating(E(73)): BT(1.842, 2.762) CE(3.3615, 3.6676) Prec@1(32.630, 31.250): 100%|██████████████████████████████████| 79/79 [00:02<00:00, 27.23it/s]\n",
            "Best Prec@1: 33.480, Many Prec@1: 0.455, Med Prec@1: 0.357, Few Prec@1: 0.169\n",
            "Training(E(74)): BT(0.209, 0.053) CE(1.8854, 2.1475) SCL_v(3.332481, 3.591602) CL(0.352699, 0.324655 Prec@1(40.476, 32.031): 100%|██████████████████████████████████████| 84/84 [00:17<00:00,  4.74it/s]\n",
            "Evaluating(E(74)): BT(2.282, 3.615) CE(3.2283, 3.3044) Prec@1(33.970, 18.750): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 20.44it/s]\n",
            "Best Prec@1: 33.970, Many Prec@1: 0.422, Med Prec@1: 0.381, Few Prec@1: 0.196\n",
            "Training(E(75)): BT(0.215, 0.053) CE(1.9070, 2.1346) SCL_v(3.319947, 3.409689) CL(0.237143, 0.141171 Prec@1(40.439, 38.281): 100%|██████████████████████████████████████| 84/84 [00:18<00:00,  4.62it/s]\n",
            "Evaluating(E(75)): BT(1.858, 2.776) CE(3.5382, 3.3240) Prec@1(29.570, 37.500): 100%|██████████████████████████████████| 79/79 [00:02<00:00, 27.06it/s]\n",
            "Best Prec@1: 33.970, Many Prec@1: 0.422, Med Prec@1: 0.381, Few Prec@1: 0.196\n",
            "Training(E(76)): BT(0.214, 0.062) CE(1.8763, 1.9447) SCL_v(3.323490, 3.410952) CL(0.016499, -0.106552 Prec@1(40.532, 41.406): 100%|█████████████████████████████████████| 84/84 [00:18<00:00,  4.60it/s]\n",
            "Evaluating(E(76)): BT(2.639, 3.657) CE(3.4028, 3.6619) Prec@1(34.460, 18.750): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 20.81it/s]\n",
            "Best Prec@1: 34.460, Many Prec@1: 0.476, Med Prec@1: 0.374, Few Prec@1: 0.157\n",
            "Training(E(77)): BT(0.210, 0.053) CE(1.8908, 2.0926) SCL_v(3.341358, 3.567290) CL(-0.194291, -0.268565 Prec@1(41.025, 38.281): 100%|████████████████████████████████████| 84/84 [00:17<00:00,  4.72it/s]\n",
            "Evaluating(E(77)): BT(1.879, 2.823) CE(3.5382, 3.4827) Prec@1(30.820, 25.000): 100%|██████████████████████████████████| 79/79 [00:02<00:00, 26.61it/s]\n",
            "Best Prec@1: 34.460, Many Prec@1: 0.476, Med Prec@1: 0.374, Few Prec@1: 0.157\n",
            "Training(E(78)): BT(0.219, 0.063) CE(1.8773, 2.2773) SCL_v(3.315596, 3.745966) CL(-0.310833, -0.351556 Prec@1(41.304, 35.938): 100%|████████████████████████████████████| 84/84 [00:18<00:00,  4.50it/s]\n",
            "Evaluating(E(78)): BT(2.207, 3.191) CE(3.5044, 3.6468) Prec@1(33.230, 37.500): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 23.71it/s]\n",
            "Best Prec@1: 34.460, Many Prec@1: 0.476, Med Prec@1: 0.374, Few Prec@1: 0.157\n",
            "Training(E(79)): BT(0.210, 0.053) CE(1.8259, 1.7885) SCL_v(3.275404, 3.182724) CL(-0.361731, -0.390625 Prec@1(42.141, 46.094): 100%|████████████████████████████████████| 84/84 [00:17<00:00,  4.71it/s]\n",
            "Evaluating(E(79)): BT(1.870, 2.820) CE(3.3475, 2.7853) Prec@1(33.060, 43.750): 100%|██████████████████████████████████| 79/79 [00:02<00:00, 26.73it/s]\n",
            "Best Prec@1: 34.460, Many Prec@1: 0.476, Med Prec@1: 0.374, Few Prec@1: 0.157\n",
            "Training(E(80)): BT(0.226, 0.052) CE(1.8505, 1.7288) SCL_v(3.310378, 3.160492) CL(-0.391036, -0.396643 Prec@1(41.834, 44.531): 100%|████████████████████████████████████| 84/84 [00:19<00:00,  4.40it/s]\n",
            "Evaluating(E(80)): BT(2.010, 2.978) CE(3.6254, 3.9143) Prec@1(30.230, 18.750): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 25.35it/s]\n",
            "Best Prec@1: 34.460, Many Prec@1: 0.476, Med Prec@1: 0.374, Few Prec@1: 0.157\n",
            "Training(E(81)): BT(0.972, 0.767) CE(1.8477, 1.5701) SCL_v(3.300528, 3.157178) CL(0.384422, 0.399692 Prec@1(42.094, 49.219): 100%|██████████████████████████████████████| 84/84 [01:21<00:00,  1.03it/s]\n",
            "Evaluating(E(81)): BT(1.867, 2.825) CE(3.4388, 3.1089) Prec@1(31.310, 50.000): 100%|██████████████████████████████████| 79/79 [00:02<00:00, 26.66it/s]\n",
            "Best Prec@1: 34.460, Many Prec@1: 0.476, Med Prec@1: 0.374, Few Prec@1: 0.157\n",
            "Training(E(82)): BT(0.232, 0.056) CE(1.8380, 1.7529) SCL_v(3.294429, 3.069061) CL(0.390799, 0.385364 Prec@1(41.639, 42.188): 100%|██████████████████████████████████████| 84/84 [00:19<00:00,  4.28it/s]\n",
            "Evaluating(E(82)): BT(1.928, 2.875) CE(3.4419, 3.3904) Prec@1(34.150, 37.500): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 26.11it/s]\n",
            "Best Prec@1: 34.460, Many Prec@1: 0.476, Med Prec@1: 0.374, Few Prec@1: 0.157\n",
            "Training(E(83)): BT(0.213, 0.054) CE(1.8244, 1.7162) SCL_v(3.277349, 3.122837) CL(0.375682, 0.364809 Prec@1(42.959, 44.531): 100%|██████████████████████████████████████| 84/84 [00:18<00:00,  4.65it/s]\n",
            "Evaluating(E(83)): BT(2.422, 3.809) CE(3.2439, 3.2730) Prec@1(32.470, 43.750): 100%|██████████████████████████████████| 79/79 [00:04<00:00, 19.55it/s]\n",
            "Best Prec@1: 34.460, Many Prec@1: 0.476, Med Prec@1: 0.374, Few Prec@1: 0.157\n",
            "Training(E(84)): BT(0.216, 0.059) CE(1.8011, 1.9202) SCL_v(3.272675, 3.312258) CL(0.325868, 0.296485 Prec@1(43.313, 43.750): 100%|██████████████████████████████████████| 84/84 [00:18<00:00,  4.60it/s]\n",
            "Evaluating(E(84)): BT(1.951, 3.026) CE(3.2957, 3.2035) Prec@1(35.030, 37.500): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 24.85it/s]\n",
            "Best Prec@1: 35.030, Many Prec@1: 0.481, Med Prec@1: 0.347, Few Prec@1: 0.202\n",
            "Training(E(85)): BT(0.216, 0.067) CE(1.7877, 1.8231) SCL_v(3.264332, 3.435235) CL(0.202727, 0.112025 Prec@1(43.648, 39.844): 100%|██████████████████████████████████████| 84/84 [00:18<00:00,  4.58it/s]\n",
            "Evaluating(E(85)): BT(2.592, 3.587) CE(3.0717, 2.9195) Prec@1(35.020, 43.750): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 21.19it/s]\n",
            "Best Prec@1: 35.030, Many Prec@1: 0.481, Med Prec@1: 0.347, Few Prec@1: 0.202\n",
            "Training(E(86)): BT(0.211, 0.054) CE(1.7698, 1.9342) SCL_v(3.235407, 3.219471) CL(-0.014758, -0.121654 Prec@1(43.676, 36.719): 100%|████████████████████████████████████| 84/84 [00:17<00:00,  4.70it/s]\n",
            "Evaluating(E(86)): BT(1.897, 2.855) CE(3.1992, 3.1842) Prec@1(36.200, 50.000): 100%|██████████████████████████████████| 79/79 [00:02<00:00, 26.36it/s]\n",
            "Best Prec@1: 36.200, Many Prec@1: 0.473, Med Prec@1: 0.372, Few Prec@1: 0.222\n",
            "Training(E(87)): BT(0.231, 0.053) CE(1.7847, 1.5999) SCL_v(3.261413, 3.349312) CL(-0.194184, -0.249119 Prec@1(43.545, 42.969): 100%|████████████████████████████████████| 84/84 [00:19<00:00,  4.29it/s]\n",
            "Evaluating(E(87)): BT(1.905, 2.870) CE(3.2906, 2.9180) Prec@1(33.960, 43.750): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 26.18it/s]\n",
            "Best Prec@1: 36.200, Many Prec@1: 0.473, Med Prec@1: 0.372, Few Prec@1: 0.222\n",
            "Training(E(88)): BT(0.211, 0.055) CE(1.7715, 1.9589) SCL_v(3.233658, 3.267088) CL(-0.293728, -0.328040 Prec@1(44.252, 40.625): 100%|████████████████████████████████████| 84/84 [00:17<00:00,  4.70it/s]\n",
            "Evaluating(E(88)): BT(1.971, 3.090) CE(3.1884, 3.1783) Prec@1(37.080, 37.500): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 24.00it/s]\n",
            "Best Prec@1: 37.080, Many Prec@1: 0.504, Med Prec@1: 0.411, Few Prec@1: 0.169\n",
            "Training(E(89)): BT(0.229, 0.056) CE(1.7733, 1.7061) SCL_v(3.241060, 3.277249) CL(-0.346979, -0.367687 Prec@1(43.629, 47.656): 100%|████████████████████████████████████| 84/84 [00:19<00:00,  4.34it/s]\n",
            "Evaluating(E(89)): BT(1.920, 2.872) CE(3.2356, 3.3337) Prec@1(33.040, 37.500): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 26.11it/s]\n",
            "Best Prec@1: 37.080, Many Prec@1: 0.504, Med Prec@1: 0.411, Few Prec@1: 0.169\n",
            "Training(E(90)): BT(0.212, 0.055) CE(1.7831, 1.3645) SCL_v(3.236333, 2.921657) CL(-0.369593, -0.373123 Prec@1(43.499, 56.250): 100%|████████████████████████████████████| 84/84 [00:17<00:00,  4.67it/s]\n",
            "Evaluating(E(90)): BT(2.879, 4.158) CE(3.2031, 2.8359) Prec@1(35.550, 50.000): 100%|██████████████████████████████████| 79/79 [00:04<00:00, 18.37it/s]\n",
            "Best Prec@1: 37.080, Many Prec@1: 0.504, Med Prec@1: 0.411, Few Prec@1: 0.169\n",
            "Training(E(91)): BT(0.986, 0.762) CE(1.7782, 1.7845) SCL_v(3.218580, 3.108568) CL(0.376171, 0.383396 Prec@1(43.583, 43.750): 100%|██████████████████████████████████████| 84/84 [01:22<00:00,  1.01it/s]\n",
            "Evaluating(E(91)): BT(1.947, 2.907) CE(3.1923, 2.7663) Prec@1(36.300, 50.000): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 25.87it/s]\n",
            "Best Prec@1: 37.080, Many Prec@1: 0.504, Med Prec@1: 0.411, Few Prec@1: 0.169\n",
            "Training(E(92)): BT(0.225, 0.057) CE(1.7420, 1.7861) SCL_v(3.224985, 3.281596) CL(0.376245, 0.370912 Prec@1(44.773, 46.875): 100%|██████████████████████████████████████| 84/84 [00:19<00:00,  4.38it/s]\n",
            "Evaluating(E(92)): BT(2.161, 3.108) CE(3.2049, 3.6924) Prec@1(37.960, 31.250): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 24.21it/s]\n",
            "Best Prec@1: 37.960, Many Prec@1: 0.516, Med Prec@1: 0.380, Few Prec@1: 0.220\n",
            "Training(E(93)): BT(0.218, 0.056) CE(1.7502, 1.7159) SCL_v(3.221016, 3.264406) CL(0.363911, 0.358011 Prec@1(43.834, 40.625): 100%|██████████████████████████████████████| 84/84 [00:18<00:00,  4.55it/s]\n",
            "Evaluating(E(93)): BT(1.912, 2.877) CE(3.1451, 2.6836) Prec@1(37.190, 50.000): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 25.89it/s]\n",
            "Best Prec@1: 37.960, Many Prec@1: 0.516, Med Prec@1: 0.380, Few Prec@1: 0.220\n",
            "Training(E(94)): BT(0.234, 0.054) CE(1.7359, 1.7599) SCL_v(3.229791, 3.307598) CL(0.335626, 0.309059 Prec@1(44.913, 51.562): 100%|██████████████████████████████████████| 84/84 [00:19<00:00,  4.24it/s]\n",
            "Evaluating(E(94)): BT(1.984, 2.969) CE(3.3569, 3.6669) Prec@1(34.410, 25.000): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 25.34it/s]\n",
            "Best Prec@1: 37.960, Many Prec@1: 0.516, Med Prec@1: 0.380, Few Prec@1: 0.220\n",
            "Training(E(95)): BT(0.214, 0.054) CE(1.7111, 1.6480) SCL_v(3.196437, 3.075739) CL(0.259167, 0.191229 Prec@1(45.052, 44.531): 100%|██████████████████████████████████████| 84/84 [00:18<00:00,  4.63it/s]\n",
            "Evaluating(E(95)): BT(3.008, 4.361) CE(3.1697, 3.3071) Prec@1(35.970, 43.750): 100%|██████████████████████████████████| 79/79 [00:04<00:00, 17.53it/s]\n",
            "Best Prec@1: 37.960, Many Prec@1: 0.516, Med Prec@1: 0.380, Few Prec@1: 0.220\n",
            "Training(E(96)): BT(0.213, 0.054) CE(1.7385, 2.0257) SCL_v(3.207917, 3.424681) CL(0.097039, 0.003132 Prec@1(44.150, 37.500): 100%|██████████████████████████████████████| 84/84 [00:18<00:00,  4.66it/s]\n",
            "Evaluating(E(96)): BT(1.862, 2.799) CE(3.1619, 3.2275) Prec@1(34.280, 43.750): 100%|██████████████████████████████████| 79/79 [00:02<00:00, 26.80it/s]\n",
            "Best Prec@1: 37.960, Many Prec@1: 0.516, Med Prec@1: 0.380, Few Prec@1: 0.220\n",
            "Training(E(97)): BT(0.224, 0.058) CE(1.7275, 1.6033) SCL_v(3.210619, 3.064858) CL(-0.080961, -0.160654 Prec@1(44.708, 40.625): 100%|████████████████████████████████████| 84/84 [00:19<00:00,  4.40it/s]\n",
            "Evaluating(E(97)): BT(2.353, 3.320) CE(3.2234, 3.2109) Prec@1(31.530, 25.000): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 22.80it/s]\n",
            "Best Prec@1: 37.960, Many Prec@1: 0.516, Med Prec@1: 0.380, Few Prec@1: 0.220\n",
            "Training(E(98)): BT(0.217, 0.052) CE(1.7115, 1.8137) SCL_v(3.197348, 3.071863) CL(-0.215943, -0.264124 Prec@1(44.885, 46.875): 100%|████████████████████████████████████| 84/84 [00:18<00:00,  4.58it/s]\n",
            "Evaluating(E(98)): BT(1.941, 2.897) CE(2.9822, 2.6809) Prec@1(38.250, 50.000): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 25.95it/s]\n",
            "Best Prec@1: 38.250, Many Prec@1: 0.498, Med Prec@1: 0.397, Few Prec@1: 0.230\n",
            "Training(E(99)): BT(0.232, 0.054) CE(1.7078, 1.4416) SCL_v(3.187612, 3.057959) CL(-0.289031, -0.298706 Prec@1(44.624, 50.781): 100%|████████████████████████████████████| 84/84 [00:19<00:00,  4.27it/s]\n",
            "Evaluating(E(99)): BT(1.938, 2.901) CE(3.0072, 3.0653) Prec@1(37.820, 43.750): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 25.98it/s]\n",
            "Best Prec@1: 38.250, Many Prec@1: 0.498, Med Prec@1: 0.397, Few Prec@1: 0.230\n",
            "Training(E(100)): BT(0.219, 0.052) CE(1.6688, 1.6258) SCL_v(3.156053, 3.120909) CL(-0.328448, -0.344166 Prec@1(45.796, 49.219): 100%|███████████████████████████████████| 84/84 [00:18<00:00,  4.52it/s]\n",
            "Evaluating(E(100)): BT(2.549, 3.953) CE(3.3616, 3.5869) Prec@1(34.250, 37.500): 100%|█████████████████████████████████| 79/79 [00:04<00:00, 18.90it/s]\n",
            "Best Prec@1: 38.250, Many Prec@1: 0.498, Med Prec@1: 0.397, Few Prec@1: 0.230\n",
            "Training(E(101)): BT(0.988, 0.736) CE(1.6877, 1.6587) SCL_v(3.149522, 3.024646) CL(0.358971, 0.363552 Prec@1(45.154, 39.844): 100%|█████████████████████████████████████| 84/84 [01:23<00:00,  1.01it/s]\n",
            "Evaluating(E(101)): BT(1.941, 2.914) CE(3.1458, 3.0219) Prec@1(35.610, 31.250): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 25.79it/s]\n",
            "Best Prec@1: 38.250, Many Prec@1: 0.498, Med Prec@1: 0.397, Few Prec@1: 0.230\n",
            "Training(E(102)): BT(0.226, 0.059) CE(1.6801, 1.7582) SCL_v(3.176604, 3.196521) CL(0.359558, 0.358503 Prec@1(46.503, 46.875): 100%|█████████████████████████████████████| 84/84 [00:19<00:00,  4.36it/s]\n",
            "Evaluating(E(102)): BT(2.469, 3.421) CE(3.1927, 3.2239) Prec@1(37.160, 43.750): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 22.07it/s]\n",
            "Best Prec@1: 38.250, Many Prec@1: 0.498, Med Prec@1: 0.397, Few Prec@1: 0.230\n",
            "Training(E(103)): BT(0.212, 0.057) CE(1.6895, 1.4748) SCL_v(3.189934, 3.132685) CL(0.351255, 0.338473 Prec@1(46.801, 56.250): 100%|█████████████████████████████████████| 84/84 [00:17<00:00,  4.68it/s]\n",
            "Evaluating(E(103)): BT(1.954, 3.004) CE(3.2540, 3.2006) Prec@1(35.460, 43.750): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 25.07it/s]\n",
            "Best Prec@1: 38.250, Many Prec@1: 0.498, Med Prec@1: 0.397, Few Prec@1: 0.230\n",
            "Training(E(104)): BT(0.231, 0.056) CE(1.6593, 1.2395) SCL_v(3.157157, 2.843811) CL(0.322778, 0.301376 Prec@1(46.438, 60.938): 100%|█████████████████████████████████████| 84/84 [00:19<00:00,  4.30it/s]\n",
            "Evaluating(E(104)): BT(1.945, 2.895) CE(3.1088, 3.4575) Prec@1(39.100, 25.000): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 26.01it/s]\n",
            "Best Prec@1: 39.100, Many Prec@1: 0.537, Med Prec@1: 0.409, Few Prec@1: 0.199\n",
            "Training(E(105)): BT(0.217, 0.054) CE(1.6694, 1.8399) SCL_v(3.152504, 3.149204) CL(0.257918, 0.200048 Prec@1(45.861, 42.969): 100%|█████████████████████████████████████| 84/84 [00:18<00:00,  4.57it/s]\n",
            "Evaluating(E(105)): BT(2.073, 3.309) CE(3.1313, 2.6910) Prec@1(37.160, 62.500): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 22.45it/s]\n",
            "Best Prec@1: 39.100, Many Prec@1: 0.537, Med Prec@1: 0.409, Few Prec@1: 0.199\n",
            "Training(E(106)): BT(0.220, 0.055) CE(1.6591, 1.6882) SCL_v(3.132574, 3.029407) CL(0.115840, 0.022244 Prec@1(46.642, 46.875): 100%|█████████████████████████████████████| 84/84 [00:18<00:00,  4.50it/s]\n",
            "Evaluating(E(106)): BT(1.881, 2.834) CE(3.1822, 3.2874) Prec@1(37.520, 31.250): 100%|█████████████████████████████████| 79/79 [00:02<00:00, 26.53it/s]\n",
            "Best Prec@1: 39.100, Many Prec@1: 0.537, Med Prec@1: 0.409, Few Prec@1: 0.199\n",
            "Training(E(107)): BT(0.214, 0.060) CE(1.6335, 1.7775) SCL_v(3.123424, 3.202845) CL(-0.060976, -0.134870 Prec@1(47.452, 48.438): 100%|███████████████████████████████████| 84/84 [00:18<00:00,  4.62it/s]\n",
            "Evaluating(E(107)): BT(2.865, 4.057) CE(3.2028, 3.5718) Prec@1(36.530, 31.250): 100%|█████████████████████████████████| 79/79 [00:04<00:00, 18.78it/s]\n",
            "Best Prec@1: 39.100, Many Prec@1: 0.537, Med Prec@1: 0.409, Few Prec@1: 0.199\n",
            "Training(E(108)): BT(0.215, 0.055) CE(1.6314, 1.9115) SCL_v(3.127133, 3.266648) CL(-0.185326, -0.229382 Prec@1(46.875, 34.375): 100%|███████████████████████████████████| 84/84 [00:18<00:00,  4.61it/s]\n",
            "Evaluating(E(108)): BT(1.876, 2.821) CE(3.1992, 3.1460) Prec@1(38.400, 43.750): 100%|█████████████████████████████████| 79/79 [00:02<00:00, 26.65it/s]\n",
            "Best Prec@1: 39.100, Many Prec@1: 0.537, Med Prec@1: 0.409, Few Prec@1: 0.199\n",
            "Training(E(109)): BT(0.224, 0.057) CE(1.6050, 1.6416) SCL_v(3.113330, 3.069054) CL(-0.263326, -0.284304 Prec@1(46.754, 45.312): 100%|███████████████████████████████████| 84/84 [00:19<00:00,  4.41it/s]\n",
            "Evaluating(E(109)): BT(2.061, 3.009) CE(3.1803, 3.1231) Prec@1(34.440, 31.250): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 25.06it/s]\n",
            "Best Prec@1: 39.100, Many Prec@1: 0.537, Med Prec@1: 0.409, Few Prec@1: 0.199\n",
            "Training(E(110)): BT(0.212, 0.054) CE(1.5924, 1.7180) SCL_v(3.107839, 3.194985) CL(-0.304018, -0.321164 Prec@1(47.666, 42.969): 100%|███████████████████████████████████| 84/84 [00:17<00:00,  4.67it/s]\n",
            "Evaluating(E(110)): BT(1.975, 3.048) CE(3.4756, 3.3299) Prec@1(34.800, 43.750): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 24.68it/s]\n",
            "Best Prec@1: 39.100, Many Prec@1: 0.537, Med Prec@1: 0.409, Few Prec@1: 0.199\n",
            "Training(E(111)): BT(1.002, 0.748) CE(1.5764, 1.7492) SCL_v(3.098527, 3.160304) CL(0.347481, 0.360887 Prec@1(48.707, 42.969): 100%|█████████████████████████████████████| 84/84 [01:24<00:00,  1.00s/it]\n",
            "Evaluating(E(111)): BT(1.867, 2.837) CE(3.3703, 3.0709) Prec@1(34.670, 50.000): 100%|█████████████████████████████████| 79/79 [00:02<00:00, 26.41it/s]\n",
            "Best Prec@1: 39.100, Many Prec@1: 0.537, Med Prec@1: 0.409, Few Prec@1: 0.199\n",
            "Training(E(112)): BT(0.217, 0.054) CE(1.6153, 1.7588) SCL_v(3.108424, 3.000505) CL(0.355477, 0.359408 Prec@1(47.907, 41.406): 100%|█████████████████████████████████████| 84/84 [00:18<00:00,  4.56it/s]\n",
            "Evaluating(E(112)): BT(2.188, 3.514) CE(3.1411, 2.6247) Prec@1(36.140, 50.000): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 21.19it/s]\n",
            "Best Prec@1: 39.100, Many Prec@1: 0.537, Med Prec@1: 0.409, Few Prec@1: 0.199\n",
            "Training(E(113)): BT(0.226, 0.053) CE(1.5805, 1.2263) SCL_v(3.074163, 2.959235) CL(0.344086, 0.356011 Prec@1(47.972, 61.719): 100%|█████████████████████████████████████| 84/84 [00:19<00:00,  4.39it/s]\n",
            "Evaluating(E(113)): BT(1.898, 2.849) CE(3.1518, 2.9442) Prec@1(37.720, 37.500): 100%|█████████████████████████████████| 79/79 [00:02<00:00, 26.45it/s]\n",
            "Best Prec@1: 39.100, Many Prec@1: 0.537, Med Prec@1: 0.409, Few Prec@1: 0.199\n",
            "Training(E(114)): BT(0.216, 0.054) CE(1.5714, 1.6826) SCL_v(3.080809, 3.264359) CL(0.331351, 0.323851 Prec@1(49.405, 45.312): 100%|█████████████████████████████████████| 84/84 [00:18<00:00,  4.57it/s]\n",
            "Evaluating(E(114)): BT(3.029, 4.323) CE(2.9858, 3.0969) Prec@1(40.130, 37.500): 100%|█████████████████████████████████| 79/79 [00:04<00:00, 17.67it/s]\n",
            "Best Prec@1: 40.130, Many Prec@1: 0.499, Med Prec@1: 0.425, Few Prec@1: 0.260\n",
            "Training(E(115)): BT(0.215, 0.055) CE(1.5698, 1.7197) SCL_v(3.103645, 3.277577) CL(0.288216, 0.258781 Prec@1(48.800, 51.562): 100%|█████████████████████████████████████| 84/84 [00:18<00:00,  4.61it/s]\n",
            "Evaluating(E(115)): BT(1.955, 2.936) CE(2.7934, 2.6593) Prec@1(39.860, 43.750): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 25.72it/s]\n",
            "Best Prec@1: 40.130, Many Prec@1: 0.499, Med Prec@1: 0.425, Few Prec@1: 0.260\n",
            "Training(E(116)): BT(0.233, 0.056) CE(1.5646, 1.4189) SCL_v(3.059858, 3.014545) CL(0.190073, 0.125706 Prec@1(49.377, 53.125): 100%|█████████████████████████████████████| 84/84 [00:19<00:00,  4.26it/s]\n",
            "Evaluating(E(116)): BT(1.918, 2.874) CE(2.9744, 3.3089) Prec@1(38.600, 43.750): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 26.03it/s]\n",
            "Best Prec@1: 40.130, Many Prec@1: 0.499, Med Prec@1: 0.425, Few Prec@1: 0.260\n",
            "Training(E(117)): BT(0.217, 0.054) CE(1.5420, 1.8152) SCL_v(3.055020, 3.265214) CL(0.044970, -0.040325 Prec@1(48.698, 46.094): 100%|████████████████████████████████████| 84/84 [00:18<00:00,  4.58it/s]\n",
            "Evaluating(E(117)): BT(2.006, 3.169) CE(2.8878, 2.5850) Prec@1(40.170, 50.000): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 23.12it/s]\n",
            "Best Prec@1: 40.170, Many Prec@1: 0.522, Med Prec@1: 0.408, Few Prec@1: 0.254\n",
            "Training(E(118)): BT(0.224, 0.061) CE(1.5312, 1.5358) SCL_v(3.040883, 3.009999) CL(-0.086385, -0.142379 Prec@1(49.433, 57.031): 100%|███████████████████████████████████| 84/84 [00:18<00:00,  4.43it/s]\n",
            "Evaluating(E(118)): BT(1.976, 2.949) CE(2.9564, 2.9130) Prec@1(38.880, 37.500): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 25.51it/s]\n",
            "Best Prec@1: 40.170, Many Prec@1: 0.522, Med Prec@1: 0.408, Few Prec@1: 0.254\n",
            "Training(E(119)): BT(0.213, 0.053) CE(1.5111, 1.3138) SCL_v(3.035834, 3.012509) CL(-0.189744, -0.223108 Prec@1(49.767, 56.250): 100%|███████████████████████████████████| 84/84 [00:18<00:00,  4.64it/s]\n",
            "Evaluating(E(119)): BT(2.862, 4.084) CE(2.8972, 2.6821) Prec@1(41.060, 43.750): 100%|█████████████████████████████████| 79/79 [00:04<00:00, 18.62it/s]\n",
            "Best Prec@1: 41.060, Many Prec@1: 0.561, Med Prec@1: 0.401, Few Prec@1: 0.247\n",
            "Training(E(120)): BT(0.229, 0.055) CE(1.5151, 1.6997) SCL_v(3.023762, 3.035456) CL(-0.242832, -0.274268 Prec@1(50.707, 46.094): 100%|███████████████████████████████████| 84/84 [00:19<00:00,  4.32it/s]\n",
            "Evaluating(E(120)): BT(1.956, 2.917) CE(2.9040, 2.9069) Prec@1(38.590, 43.750): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 25.68it/s]\n",
            "Best Prec@1: 41.060, Many Prec@1: 0.561, Med Prec@1: 0.401, Few Prec@1: 0.247\n",
            "Training(E(121)): BT(0.995, 0.991) CE(1.4950, 1.2599) SCL_v(3.016210, 2.882064) CL(0.333916, 0.321769 Prec@1(50.381, 55.469): 100%|█████████████████████████████████████| 84/84 [01:23<00:00,  1.00it/s]\n",
            "Evaluating(E(121)): BT(1.914, 2.879) CE(2.8966, 2.8589) Prec@1(41.630, 37.500): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 26.11it/s]\n",
            "Best Prec@1: 41.630, Many Prec@1: 0.535, Med Prec@1: 0.442, Few Prec@1: 0.248\n",
            "Training(E(122)): BT(0.210, 0.052) CE(1.4812, 1.4284) SCL_v(3.017700, 2.960179) CL(0.335813, 0.334680 Prec@1(51.516, 58.594): 100%|█████████████████████████████████████| 84/84 [00:17<00:00,  4.72it/s]\n",
            "Evaluating(E(122)): BT(1.906, 2.910) CE(3.0090, 2.4346) Prec@1(39.270, 56.250): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 25.39it/s]\n",
            "Best Prec@1: 41.630, Many Prec@1: 0.535, Med Prec@1: 0.442, Few Prec@1: 0.248\n",
            "Training(E(123)): BT(0.228, 0.054) CE(1.4880, 1.6763) SCL_v(3.005300, 3.142994) CL(0.323547, 0.323091 Prec@1(51.358, 50.781): 100%|█████████████████████████████████████| 84/84 [00:19<00:00,  4.34it/s]\n",
            "Evaluating(E(123)): BT(1.874, 2.829) CE(2.9246, 2.9103) Prec@1(39.650, 31.250): 100%|█████████████████████████████████| 79/79 [00:02<00:00, 26.56it/s]\n",
            "Best Prec@1: 41.630, Many Prec@1: 0.535, Med Prec@1: 0.442, Few Prec@1: 0.248\n",
            "Training(E(124)): BT(0.215, 0.059) CE(1.4695, 1.3589) SCL_v(2.978082, 2.843477) CL(0.303560, 0.296865 Prec@1(50.939, 49.219): 100%|█████████████████████████████████████| 84/84 [00:18<00:00,  4.62it/s]\n",
            "Evaluating(E(124)): BT(2.496, 3.908) CE(2.9968, 3.5612) Prec@1(39.770, 37.500): 100%|█████████████████████████████████| 79/79 [00:04<00:00, 19.07it/s]\n",
            "Best Prec@1: 41.630, Many Prec@1: 0.535, Med Prec@1: 0.442, Few Prec@1: 0.248\n",
            "Training(E(125)): BT(0.211, 0.060) CE(1.4707, 1.5896) SCL_v(2.984187, 3.129945) CL(0.262373, 0.224906 Prec@1(51.535, 45.312): 100%|█████████████████████████████████████| 84/84 [00:17<00:00,  4.69it/s]\n",
            "Evaluating(E(125)): BT(1.863, 2.805) CE(2.9362, 2.7442) Prec@1(41.210, 37.500): 100%|█████████████████████████████████| 79/79 [00:02<00:00, 26.77it/s]\n",
            "Best Prec@1: 41.630, Many Prec@1: 0.535, Med Prec@1: 0.442, Few Prec@1: 0.248\n",
            "Training(E(126)): BT(0.211, 0.070) CE(1.4515, 1.5056) SCL_v(2.972512, 2.938070) CL(0.168643, 0.121770 Prec@1(51.097, 55.469): 100%|█████████████████████████████████████| 84/84 [00:17<00:00,  4.68it/s]\n",
            "Evaluating(E(126)): BT(2.847, 4.054) CE(2.8122, 2.8902) Prec@1(44.580, 31.250): 100%|█████████████████████████████████| 79/79 [00:04<00:00, 18.75it/s]\n",
            "Best Prec@1: 44.580, Many Prec@1: 0.583, Med Prec@1: 0.473, Few Prec@1: 0.253\n",
            "Training(E(127)): BT(0.214, 0.058) CE(1.4562, 1.3970) SCL_v(2.990936, 2.783550) CL(0.049118, -0.011838 Prec@1(51.795, 52.344): 100%|████████████████████████████████████| 84/84 [00:18<00:00,  4.64it/s]\n",
            "Evaluating(E(127)): BT(1.906, 2.882) CE(3.0480, 3.1264) Prec@1(38.530, 50.000): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 26.17it/s]\n",
            "Best Prec@1: 44.580, Many Prec@1: 0.583, Med Prec@1: 0.473, Few Prec@1: 0.253\n",
            "Training(E(128)): BT(0.229, 0.070) CE(1.4505, 1.5207) SCL_v(2.988739, 3.055583) CL(-0.065457, -0.113307 Prec@1(51.842, 53.125): 100%|███████████████████████████████████| 84/84 [00:19<00:00,  4.32it/s]\n",
            "Evaluating(E(128)): BT(1.933, 2.890) CE(3.1537, 3.7090) Prec@1(38.440, 31.250): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 26.09it/s]\n",
            "Best Prec@1: 44.580, Many Prec@1: 0.583, Med Prec@1: 0.473, Few Prec@1: 0.253\n",
            "Training(E(129)): BT(0.219, 0.055) CE(1.4231, 1.6186) SCL_v(2.959068, 3.165551) CL(-0.141885, -0.180499 Prec@1(52.176, 47.656): 100%|███████████████████████████████████| 84/84 [00:18<00:00,  4.54it/s]\n",
            "Evaluating(E(129)): BT(2.134, 3.272) CE(3.2568, 2.9608) Prec@1(36.770, 56.250): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 22.53it/s]\n",
            "Best Prec@1: 44.580, Many Prec@1: 0.583, Med Prec@1: 0.473, Few Prec@1: 0.253\n",
            "Training(E(130)): BT(0.232, 0.054) CE(1.4122, 1.4971) SCL_v(2.942354, 3.030338) CL(-0.203919, -0.219984 Prec@1(52.697, 53.125): 100%|███████████████████████████████████| 84/84 [00:19<00:00,  4.28it/s]\n",
            "Evaluating(E(130)): BT(1.957, 2.933) CE(2.9599, 3.2495) Prec@1(42.180, 43.750): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 25.69it/s]\n",
            "Best Prec@1: 44.580, Many Prec@1: 0.583, Med Prec@1: 0.473, Few Prec@1: 0.253\n",
            "Training(E(131)): BT(0.985, 0.796) CE(1.3878, 1.4831) SCL_v(2.927193, 2.901686) CL(0.324312, 0.341139 Prec@1(52.734, 47.656): 100%|█████████████████████████████████████| 84/84 [01:22<00:00,  1.01it/s]\n",
            "Evaluating(E(131)): BT(2.830, 4.005) CE(2.8239, 2.4183) Prec@1(41.330, 50.000): 100%|█████████████████████████████████| 79/79 [00:04<00:00, 19.06it/s]\n",
            "Best Prec@1: 44.580, Many Prec@1: 0.583, Med Prec@1: 0.473, Few Prec@1: 0.253\n",
            "Training(E(132)): BT(0.217, 0.055) CE(1.4068, 1.7264) SCL_v(2.919536, 2.993256) CL(0.326363, 0.317643 Prec@1(53.516, 43.750): 100%|█████████████████████████████████████| 84/84 [00:18<00:00,  4.57it/s]\n",
            "Evaluating(E(132)): BT(1.902, 2.850) CE(2.8658, 2.7046) Prec@1(43.320, 56.250): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 26.28it/s]\n",
            "Best Prec@1: 44.580, Many Prec@1: 0.583, Med Prec@1: 0.473, Few Prec@1: 0.253\n",
            "Training(E(133)): BT(0.224, 0.060) CE(1.3922, 1.6834) SCL_v(2.926367, 3.038855) CL(0.324123, 0.306146 Prec@1(53.664, 49.219): 100%|█████████████████████████████████████| 84/84 [00:19<00:00,  4.40it/s]\n",
            "Evaluating(E(133)): BT(2.365, 3.384) CE(2.9221, 2.7205) Prec@1(40.700, 43.750): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 22.39it/s]\n",
            "Best Prec@1: 44.580, Many Prec@1: 0.583, Med Prec@1: 0.473, Few Prec@1: 0.253\n",
            "Training(E(134)): BT(0.221, 0.056) CE(1.3747, 1.4374) SCL_v(2.921774, 2.861081) CL(0.313688, 0.298178 Prec@1(53.478, 51.562): 100%|█████████████████████████████████████| 84/84 [00:18<00:00,  4.49it/s]\n",
            "Evaluating(E(134)): BT(1.994, 3.062) CE(3.3467, 3.4137) Prec@1(38.540, 43.750): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 23.73it/s]\n",
            "Best Prec@1: 44.580, Many Prec@1: 0.583, Med Prec@1: 0.473, Few Prec@1: 0.253\n",
            "Training(E(135)): BT(0.236, 0.056) CE(1.3666, 1.5170) SCL_v(2.880374, 2.868398) CL(0.285613, 0.273946 Prec@1(54.064, 57.031): 100%|█████████████████████████████████████| 84/84 [00:20<00:00,  4.20it/s]\n",
            "Evaluating(E(135)): BT(2.004, 2.998) CE(2.8173, 2.8051) Prec@1(43.700, 43.750): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 25.09it/s]\n",
            "Best Prec@1: 44.580, Many Prec@1: 0.583, Med Prec@1: 0.473, Few Prec@1: 0.253\n",
            "Training(E(136)): BT(0.223, 0.060) CE(1.3561, 1.3115) SCL_v(2.909981, 2.896526) CL(0.239740, 0.213702 Prec@1(53.916, 56.250): 100%|█████████████████████████████████████| 84/84 [00:18<00:00,  4.43it/s]\n",
            "Evaluating(E(136)): BT(2.825, 3.934) CE(2.9253, 2.8963) Prec@1(40.940, 43.750): 100%|█████████████████████████████████| 79/79 [00:04<00:00, 19.35it/s]\n",
            "Best Prec@1: 44.580, Many Prec@1: 0.583, Med Prec@1: 0.473, Few Prec@1: 0.253\n",
            "Training(E(137)): BT(0.221, 0.055) CE(1.3586, 1.0328) SCL_v(2.886985, 2.674949) CL(0.150516, 0.092901 Prec@1(54.585, 62.500): 100%|█████████████████████████████████████| 84/84 [00:18<00:00,  4.48it/s]\n",
            "Evaluating(E(137)): BT(2.015, 3.130) CE(2.7964, 2.7571) Prec@1(43.330, 31.250): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 24.18it/s]\n",
            "Best Prec@1: 44.580, Many Prec@1: 0.583, Med Prec@1: 0.473, Few Prec@1: 0.253\n",
            "Training(E(138)): BT(0.235, 0.056) CE(1.3525, 1.2286) SCL_v(2.878669, 2.922395) CL(0.043858, 0.001190 Prec@1(54.232, 57.812): 100%|█████████████████████████████████████| 84/84 [00:19<00:00,  4.23it/s]\n",
            "Evaluating(E(138)): BT(1.930, 2.893) CE(2.8841, 2.7774) Prec@1(42.230, 43.750): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 26.02it/s]\n",
            "Best Prec@1: 44.580, Many Prec@1: 0.583, Med Prec@1: 0.473, Few Prec@1: 0.253\n",
            "Training(E(139)): BT(0.217, 0.054) CE(1.3147, 1.6357) SCL_v(2.869911, 2.897312) CL(-0.031513, -0.059637 Prec@1(55.636, 45.312): 100%|███████████████████████████████████| 84/84 [00:18<00:00,  4.56it/s]\n",
            "Evaluating(E(139)): BT(2.211, 3.569) CE(2.8326, 2.6858) Prec@1(40.420, 37.500): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 20.92it/s]\n",
            "Best Prec@1: 44.580, Many Prec@1: 0.583, Med Prec@1: 0.473, Few Prec@1: 0.253\n",
            "Training(E(140)): BT(0.226, 0.053) CE(1.2867, 1.3627) SCL_v(2.843215, 3.015555) CL(-0.098622, -0.128004 Prec@1(56.231, 54.688): 100%|███████████████████████████████████| 84/84 [00:19<00:00,  4.38it/s]\n",
            "Evaluating(E(140)): BT(1.931, 2.864) CE(2.7463, 2.7226) Prec@1(43.820, 43.750): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 26.22it/s]\n",
            "Best Prec@1: 44.580, Many Prec@1: 0.583, Med Prec@1: 0.473, Few Prec@1: 0.253\n",
            "Training(E(141)): BT(0.973, 0.754) CE(1.2791, 1.3783) SCL_v(2.832494, 2.824477) CL(0.311574, 0.314891 Prec@1(55.999, 57.812): 100%|█████████████████████████████████████| 84/84 [01:21<00:00,  1.03it/s]\n",
            "Evaluating(E(141)): BT(2.691, 4.124) CE(2.7572, 2.6927) Prec@1(44.570, 43.750): 100%|█████████████████████████████████| 79/79 [00:04<00:00, 18.20it/s]\n",
            "Best Prec@1: 44.580, Many Prec@1: 0.583, Med Prec@1: 0.473, Few Prec@1: 0.253\n",
            "Training(E(142)): BT(0.226, 0.053) CE(1.2842, 1.4817) SCL_v(2.829605, 2.852082) CL(0.314328, 0.310922 Prec@1(56.194, 55.469): 100%|█████████████████████████████████████| 84/84 [00:19<00:00,  4.39it/s]\n",
            "Evaluating(E(142)): BT(1.964, 2.962) CE(2.7708, 2.9198) Prec@1(45.230, 50.000): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 25.31it/s]\n",
            "Best Prec@1: 45.230, Many Prec@1: 0.610, Med Prec@1: 0.464, Few Prec@1: 0.255\n",
            "Training(E(143)): BT(0.229, 0.059) CE(1.2892, 1.3522) SCL_v(2.834305, 2.761841) CL(0.310655, 0.311541 Prec@1(56.985, 58.594): 100%|█████████████████████████████████████| 84/84 [00:19<00:00,  4.30it/s]\n",
            "Evaluating(E(143)): BT(2.219, 3.200) CE(2.8241, 2.7215) Prec@1(45.210, 31.250): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 23.63it/s]\n",
            "Best Prec@1: 45.230, Many Prec@1: 0.610, Med Prec@1: 0.464, Few Prec@1: 0.255\n",
            "Training(E(144)): BT(0.220, 0.059) CE(1.2698, 1.5738) SCL_v(2.806827, 3.133494) CL(0.296873, 0.300036 Prec@1(56.455, 44.531): 100%|█████████████████████████████████████| 84/84 [00:18<00:00,  4.52it/s]\n",
            "Evaluating(E(144)): BT(1.924, 2.885) CE(2.9214, 2.7474) Prec@1(43.340, 43.750): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 25.80it/s]\n",
            "Best Prec@1: 45.230, Many Prec@1: 0.610, Med Prec@1: 0.464, Few Prec@1: 0.255\n",
            "Training(E(145)): BT(0.238, 0.054) CE(1.2629, 1.1708) SCL_v(2.807581, 2.750933) CL(0.274640, 0.258401 Prec@1(56.789, 59.375): 100%|█████████████████████████████████████| 84/84 [00:20<00:00,  4.17it/s]\n",
            "Evaluating(E(145)): BT(1.936, 2.893) CE(2.8203, 2.8372) Prec@1(43.340, 37.500): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 26.07it/s]\n",
            "Best Prec@1: 45.230, Many Prec@1: 0.610, Med Prec@1: 0.464, Few Prec@1: 0.255\n",
            "Training(E(146)): BT(0.220, 0.069) CE(1.2333, 1.2627) SCL_v(2.781112, 2.688716) CL(0.224573, 0.197876 Prec@1(57.496, 60.938): 100%|█████████████████████████████████████| 84/84 [00:18<00:00,  4.48it/s]\n",
            "Evaluating(E(146)): BT(2.860, 4.073) CE(2.7861, 2.9493) Prec@1(44.860, 37.500): 100%|█████████████████████████████████| 79/79 [00:04<00:00, 18.69it/s]\n",
            "Best Prec@1: 45.230, Many Prec@1: 0.610, Med Prec@1: 0.464, Few Prec@1: 0.255\n",
            "Training(E(147)): BT(0.216, 0.054) CE(1.2341, 1.3611) SCL_v(2.783438, 2.650754) CL(0.154945, 0.122945 Prec@1(57.896, 62.500): 100%|█████████████████████████████████████| 84/84 [00:18<00:00,  4.59it/s]\n",
            "Evaluating(E(147)): BT(1.917, 2.879) CE(2.7302, 2.4384) Prec@1(45.690, 50.000): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 26.15it/s]\n",
            "Best Prec@1: 45.690, Many Prec@1: 0.603, Med Prec@1: 0.461, Few Prec@1: 0.281\n",
            "Training(E(148)): BT(0.229, 0.058) CE(1.1959, 1.0972) SCL_v(2.786719, 2.785016) CL(0.079342, 0.051019 Prec@1(58.287, 58.594): 100%|█████████████████████████████████████| 84/84 [00:19<00:00,  4.33it/s]\n",
            "Evaluating(E(148)): BT(2.142, 3.106) CE(2.7919, 2.8782) Prec@1(44.100, 56.250): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 24.30it/s]\n",
            "Best Prec@1: 45.690, Many Prec@1: 0.603, Med Prec@1: 0.461, Few Prec@1: 0.281\n",
            "Training(E(149)): BT(0.216, 0.055) CE(1.2096, 1.3298) SCL_v(2.771381, 2.868641) CL(0.022627, -0.010465 Prec@1(58.315, 60.156): 100%|████████████████████████████████████| 84/84 [00:18<00:00,  4.60it/s]\n",
            "Evaluating(E(149)): BT(1.957, 2.914) CE(2.7269, 3.1218) Prec@1(45.410, 50.000): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 25.82it/s]\n",
            "Best Prec@1: 45.690, Many Prec@1: 0.603, Med Prec@1: 0.461, Few Prec@1: 0.281\n",
            "Training(E(150)): BT(0.236, 0.059) CE(1.1940, 1.3507) SCL_v(2.757516, 2.777141) CL(-0.037926, -0.056816 Prec@1(58.845, 53.125): 100%|███████████████████████████████████| 84/84 [00:19<00:00,  4.21it/s]\n",
            "Evaluating(E(150)): BT(1.937, 2.897) CE(2.6300, 2.5958) Prec@1(47.240, 62.500): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 26.01it/s]\n",
            "Best Prec@1: 47.240, Many Prec@1: 0.603, Med Prec@1: 0.470, Few Prec@1: 0.323\n",
            "Training(E(151)): BT(0.980, 0.767) CE(1.1821, 1.4675) SCL_v(2.751240, 3.018290) CL(0.303678, 0.317834 Prec@1(58.770, 55.469): 100%|█████████████████████████████████████| 84/84 [01:22<00:00,  1.02it/s]\n",
            "Evaluating(E(151)): BT(2.033, 3.251) CE(2.6567, 2.8900) Prec@1(45.580, 43.750): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 22.88it/s]\n",
            "Best Prec@1: 47.240, Many Prec@1: 0.603, Med Prec@1: 0.470, Few Prec@1: 0.323\n",
            "Training(E(152)): BT(0.224, 0.055) CE(1.1858, 0.9701) SCL_v(2.737730, 2.382439) CL(0.307853, 0.293275 Prec@1(58.984, 66.406): 100%|█████████████████████████████████████| 84/84 [00:18<00:00,  4.43it/s]\n",
            "Evaluating(E(152)): BT(1.937, 2.885) CE(2.7080, 3.3538) Prec@1(44.570, 50.000): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 26.10it/s]\n",
            "Best Prec@1: 47.240, Many Prec@1: 0.603, Med Prec@1: 0.470, Few Prec@1: 0.323\n",
            "Training(E(153)): BT(0.216, 0.059) CE(1.1560, 1.0465) SCL_v(2.721971, 2.650194) CL(0.299988, 0.282096 Prec@1(59.561, 67.188): 100%|█████████████████████████████████████| 84/84 [00:18<00:00,  4.60it/s]\n",
            "Evaluating(E(153)): BT(2.574, 3.995) CE(2.7992, 2.7825) Prec@1(45.170, 31.250): 100%|█████████████████████████████████| 79/79 [00:04<00:00, 18.83it/s]\n",
            "Best Prec@1: 47.240, Many Prec@1: 0.603, Med Prec@1: 0.470, Few Prec@1: 0.323\n",
            "Training(E(154)): BT(0.217, 0.056) CE(1.1472, 1.0030) SCL_v(2.704757, 2.693588) CL(0.286565, 0.274347 Prec@1(60.342, 71.094): 100%|█████████████████████████████████████| 84/84 [00:18<00:00,  4.57it/s]\n",
            "Evaluating(E(154)): BT(1.941, 2.933) CE(2.8402, 2.8757) Prec@1(45.060, 43.750): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 25.73it/s]\n",
            "Best Prec@1: 47.240, Many Prec@1: 0.603, Med Prec@1: 0.470, Few Prec@1: 0.323\n",
            "Training(E(155)): BT(0.216, 0.069) CE(1.1366, 1.1337) SCL_v(2.705899, 2.823746) CL(0.263034, 0.247434 Prec@1(60.454, 62.500): 100%|█████████████████████████████████████| 84/84 [00:18<00:00,  4.56it/s]\n",
            "Evaluating(E(155)): BT(2.671, 3.668) CE(2.7067, 2.4303) Prec@1(45.190, 43.750): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 20.71it/s]\n",
            "Best Prec@1: 47.240, Many Prec@1: 0.603, Med Prec@1: 0.470, Few Prec@1: 0.323\n",
            "Training(E(156)): BT(0.214, 0.055) CE(1.1405, 1.3499) SCL_v(2.706048, 3.048149) CL(0.219469, 0.203739 Prec@1(60.156, 53.125): 100%|█████████████████████████████████████| 84/84 [00:18<00:00,  4.64it/s]\n",
            "Evaluating(E(156)): BT(2.042, 3.047) CE(2.7708, 2.7969) Prec@1(44.730, 43.750): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 24.71it/s]\n",
            "Best Prec@1: 47.240, Many Prec@1: 0.603, Med Prec@1: 0.470, Few Prec@1: 0.323\n",
            "Training(E(157)): BT(0.230, 0.054) CE(1.1146, 1.3543) SCL_v(2.668791, 2.746940) CL(0.160735, 0.125162 Prec@1(61.365, 53.125): 100%|█████████████████████████████████████| 84/84 [00:19<00:00,  4.31it/s]\n",
            "Evaluating(E(157)): BT(1.934, 2.877) CE(2.7949, 2.8939) Prec@1(45.680, 43.750): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 26.11it/s]\n",
            "Best Prec@1: 47.240, Many Prec@1: 0.603, Med Prec@1: 0.470, Few Prec@1: 0.323\n",
            "Training(E(158)): BT(0.218, 0.054) CE(1.1034, 1.1675) SCL_v(2.666671, 2.877526) CL(0.107049, 0.086192 Prec@1(61.291, 56.250): 100%|█████████████████████████████████████| 84/84 [00:18<00:00,  4.54it/s]\n",
            "Evaluating(E(158)): BT(2.020, 3.182) CE(2.7299, 3.5225) Prec@1(46.160, 31.250): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 22.98it/s]\n",
            "Best Prec@1: 47.240, Many Prec@1: 0.603, Med Prec@1: 0.470, Few Prec@1: 0.323\n",
            "Training(E(159)): BT(0.225, 0.055) CE(1.1069, 1.0918) SCL_v(2.656435, 2.588711) CL(0.058865, 0.036237 Prec@1(61.217, 62.500): 100%|█████████████████████████████████████| 84/84 [00:19<00:00,  4.42it/s]\n",
            "Evaluating(E(159)): BT(1.869, 2.801) CE(2.6147, 2.7690) Prec@1(47.480, 50.000): 100%|█████████████████████████████████| 79/79 [00:02<00:00, 26.89it/s]\n",
            "Best Prec@1: 47.480, Many Prec@1: 0.601, Med Prec@1: 0.506, Few Prec@1: 0.292\n",
            "Training(E(160)): BT(0.212, 0.054) CE(1.0601, 1.2734) SCL_v(2.638706, 2.856785) CL(0.013410, -0.001287 Prec@1(63.151, 64.062): 100%|████████████████████████████████████| 84/84 [00:17<00:00,  4.67it/s]\n",
            "Evaluating(E(160)): BT(2.819, 4.221) CE(2.6214, 2.5684) Prec@1(47.510, 62.500): 100%|█████████████████████████████████| 79/79 [00:04<00:00, 17.82it/s]\n",
            "Best Prec@1: 47.510, Many Prec@1: 0.615, Med Prec@1: 0.498, Few Prec@1: 0.286\n",
            "Training(E(161)): BT(0.985, 0.771) CE(1.0615, 1.0122) SCL_v(2.636339, 2.598894) CL(0.294503, 0.313891 Prec@1(63.263, 64.844): 100%|█████████████████████████████████████| 84/84 [01:22<00:00,  1.01it/s]\n",
            "Evaluating(E(161)): BT(1.942, 2.906) CE(2.5802, 2.7357) Prec@1(47.820, 50.000): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 25.82it/s]\n",
            "Best Prec@1: 47.820, Many Prec@1: 0.621, Med Prec@1: 0.478, Few Prec@1: 0.311\n",
            "Training(E(162)): BT(0.220, 0.066) CE(1.0538, 1.1955) SCL_v(2.624096, 2.596446) CL(0.297533, 0.291309 Prec@1(62.937, 60.156): 100%|█████████████████████████████████████| 84/84 [00:18<00:00,  4.50it/s]\n",
            "Evaluating(E(162)): BT(2.639, 3.645) CE(2.6210, 2.8059) Prec@1(48.550, 43.750): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 20.74it/s]\n",
            "Best Prec@1: 48.550, Many Prec@1: 0.631, Med Prec@1: 0.505, Few Prec@1: 0.292\n",
            "Training(E(163)): BT(0.222, 0.058) CE(1.0339, 1.1159) SCL_v(2.606346, 2.668747) CL(0.292269, 0.286944 Prec@1(63.365, 62.500): 100%|█████████████████████████████████████| 84/84 [00:18<00:00,  4.47it/s]\n",
            "Evaluating(E(163)): BT(1.954, 2.893) CE(2.6633, 2.6647) Prec@1(47.700, 50.000): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 25.96it/s]\n",
            "Best Prec@1: 48.550, Many Prec@1: 0.631, Med Prec@1: 0.505, Few Prec@1: 0.292\n",
            "Training(E(164)): BT(0.237, 0.054) CE(1.0453, 0.8307) SCL_v(2.613853, 2.527096) CL(0.283943, 0.272607 Prec@1(63.170, 66.406): 100%|█████████████████████████████████████| 84/84 [00:20<00:00,  4.18it/s]\n",
            "Evaluating(E(164)): BT(1.882, 2.805) CE(2.5796, 2.8295) Prec@1(47.760, 43.750): 100%|█████████████████████████████████| 79/79 [00:02<00:00, 26.69it/s]\n",
            "Best Prec@1: 48.550, Many Prec@1: 0.631, Med Prec@1: 0.505, Few Prec@1: 0.292\n",
            "Training(E(165)): BT(0.218, 0.058) CE(1.0210, 0.7851) SCL_v(2.574990, 2.556898) CL(0.270096, 0.261429 Prec@1(63.979, 69.531): 100%|█████████████████████████████████████| 84/84 [00:18<00:00,  4.54it/s]\n",
            "Evaluating(E(165)): BT(2.212, 3.563) CE(2.5268, 2.3686) Prec@1(47.480, 62.500): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 20.79it/s]\n",
            "Best Prec@1: 48.550, Many Prec@1: 0.631, Med Prec@1: 0.505, Few Prec@1: 0.292\n",
            "Training(E(166)): BT(0.224, 0.053) CE(1.0001, 0.8000) SCL_v(2.573937, 2.116144) CL(0.251004, 0.238604 Prec@1(64.174, 66.406): 100%|█████████████████████████████████████| 84/84 [00:19<00:00,  4.42it/s]\n",
            "Evaluating(E(166)): BT(1.982, 2.951) CE(2.5683, 2.6022) Prec@1(48.010, 62.500): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 25.50it/s]\n",
            "Best Prec@1: 48.550, Many Prec@1: 0.631, Med Prec@1: 0.505, Few Prec@1: 0.292\n",
            "Training(E(167)): BT(0.218, 0.057) CE(0.9907, 1.0933) SCL_v(2.558373, 2.704330) CL(0.224576, 0.208168 Prec@1(65.141, 58.594): 100%|█████████████████████████████████████| 84/84 [00:18<00:00,  4.54it/s]\n",
            "Evaluating(E(167)): BT(2.686, 3.720) CE(2.5028, 2.5780) Prec@1(49.200, 50.000): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 20.43it/s]\n",
            "Best Prec@1: 49.200, Many Prec@1: 0.622, Med Prec@1: 0.503, Few Prec@1: 0.327\n",
            "Training(E(168)): BT(0.214, 0.053) CE(0.9598, 0.8681) SCL_v(2.526359, 2.517840) CL(0.190201, 0.177469 Prec@1(65.392, 69.531): 100%|█████████████████████████████████████| 84/84 [00:18<00:00,  4.63it/s]\n",
            "Evaluating(E(168)): BT(1.949, 2.910) CE(2.6531, 2.9427) Prec@1(47.450, 43.750): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 25.89it/s]\n",
            "Best Prec@1: 49.200, Many Prec@1: 0.622, Med Prec@1: 0.503, Few Prec@1: 0.327\n",
            "Training(E(169)): BT(0.227, 0.066) CE(0.9539, 1.2296) SCL_v(2.525729, 2.880305) CL(0.159015, 0.150986 Prec@1(65.569, 60.938): 100%|█████████████████████████████████████| 84/84 [00:19<00:00,  4.35it/s]\n",
            "Evaluating(E(169)): BT(1.943, 2.892) CE(2.5560, 2.8115) Prec@1(49.440, 37.500): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 26.03it/s]\n",
            "Best Prec@1: 49.440, Many Prec@1: 0.649, Med Prec@1: 0.513, Few Prec@1: 0.293\n",
            "Training(E(170)): BT(0.213, 0.055) CE(0.9813, 1.2110) SCL_v(2.543541, 2.662171) CL(0.129393, 0.116239 Prec@1(65.299, 56.250): 100%|█████████████████████████████████████| 84/84 [00:18<00:00,  4.65it/s]\n",
            "Evaluating(E(170)): BT(1.879, 2.802) CE(2.5086, 2.7095) Prec@1(49.230, 56.250): 100%|█████████████████████████████████| 79/79 [00:02<00:00, 26.68it/s]\n",
            "Best Prec@1: 49.440, Many Prec@1: 0.649, Med Prec@1: 0.513, Few Prec@1: 0.293\n",
            "Training(E(171)): BT(0.988, 0.771) CE(0.9557, 0.9800) SCL_v(2.519818, 2.466047) CL(0.284151, 0.277806 Prec@1(65.737, 65.625): 100%|█████████████████████████████████████| 84/84 [01:23<00:00,  1.01it/s]\n",
            "Evaluating(E(171)): BT(1.938, 2.900) CE(2.5827, 2.6436) Prec@1(48.480, 50.000): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 25.88it/s]\n",
            "Best Prec@1: 49.440, Many Prec@1: 0.649, Med Prec@1: 0.513, Few Prec@1: 0.293\n",
            "Training(E(172)): BT(0.214, 0.056) CE(0.9038, 0.7067) SCL_v(2.474377, 2.370273) CL(0.277888, 0.280923 Prec@1(67.094, 68.750): 100%|█████████████████████████████████████| 84/84 [00:18<00:00,  4.63it/s]\n",
            "Evaluating(E(172)): BT(2.249, 3.580) CE(2.4743, 2.4661) Prec@1(49.850, 50.000): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 20.50it/s]\n",
            "Best Prec@1: 49.850, Many Prec@1: 0.635, Med Prec@1: 0.511, Few Prec@1: 0.325\n",
            "Training(E(173)): BT(0.222, 0.052) CE(0.8957, 0.8450) SCL_v(2.492373, 2.340340) CL(0.279861, 0.278806 Prec@1(67.206, 71.094): 100%|█████████████████████████████████████| 84/84 [00:18<00:00,  4.48it/s]\n",
            "Evaluating(E(173)): BT(1.887, 2.844) CE(2.4974, 2.6294) Prec@1(49.730, 50.000): 100%|█████████████████████████████████| 79/79 [00:02<00:00, 26.37it/s]\n",
            "Best Prec@1: 49.850, Many Prec@1: 0.635, Med Prec@1: 0.511, Few Prec@1: 0.325\n",
            "Training(E(174)): BT(0.214, 0.063) CE(0.9331, 0.8471) SCL_v(2.520130, 2.455291) CL(0.277921, 0.271548 Prec@1(66.639, 68.750): 100%|█████████████████████████████████████| 84/84 [00:18<00:00,  4.61it/s]\n",
            "Evaluating(E(174)): BT(2.716, 3.898) CE(2.4935, 2.8503) Prec@1(50.200, 43.750): 100%|█████████████████████████████████| 79/79 [00:04<00:00, 19.47it/s]\n",
            "Best Prec@1: 50.200, Many Prec@1: 0.645, Med Prec@1: 0.517, Few Prec@1: 0.317\n",
            "Training(E(175)): BT(0.212, 0.053) CE(0.9058, 1.0951) SCL_v(2.488840, 2.598798) CL(0.269082, 0.274548 Prec@1(67.532, 64.844): 100%|█████████████████████████████████████| 84/84 [00:17<00:00,  4.68it/s]\n",
            "Evaluating(E(175)): BT(1.831, 2.756) CE(2.4661, 2.5670) Prec@1(50.790, 68.750): 100%|█████████████████████████████████| 79/79 [00:02<00:00, 27.33it/s]\n",
            "Best Prec@1: 50.790, Many Prec@1: 0.652, Med Prec@1: 0.527, Few Prec@1: 0.318\n",
            "Training(E(176)): BT(0.218, 0.063) CE(0.9220, 1.0580) SCL_v(2.496368, 2.466804) CL(0.266824, 0.258568 Prec@1(67.011, 64.062): 100%|█████████████████████████████████████| 84/84 [00:18<00:00,  4.52it/s]\n",
            "Evaluating(E(176)): BT(2.292, 3.219) CE(2.4804, 2.4974) Prec@1(49.790, 62.500): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 23.51it/s]\n",
            "Best Prec@1: 50.790, Many Prec@1: 0.652, Med Prec@1: 0.527, Few Prec@1: 0.318\n",
            "Training(E(177)): BT(0.215, 0.055) CE(0.9053, 0.8970) SCL_v(2.458117, 2.500484) CL(0.255894, 0.254083 Prec@1(67.253, 66.406): 100%|█████████████████████████████████████| 84/84 [00:18<00:00,  4.61it/s]\n",
            "Evaluating(E(177)): BT(1.895, 2.829) CE(2.4807, 2.5565) Prec@1(50.240, 56.250): 100%|█████████████████████████████████| 79/79 [00:02<00:00, 26.65it/s]\n",
            "Best Prec@1: 50.790, Many Prec@1: 0.652, Med Prec@1: 0.527, Few Prec@1: 0.318\n",
            "Training(E(178)): BT(0.229, 0.063) CE(0.8935, 0.9489) SCL_v(2.451492, 2.637258) CL(0.246393, 0.243804 Prec@1(67.587, 65.625): 100%|█████████████████████████████████████| 84/84 [00:19<00:00,  4.32it/s]\n",
            "Evaluating(E(178)): BT(2.027, 2.978) CE(2.4576, 2.6516) Prec@1(50.460, 56.250): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 25.27it/s]\n",
            "Best Prec@1: 50.790, Many Prec@1: 0.652, Med Prec@1: 0.527, Few Prec@1: 0.318\n",
            "Training(E(179)): BT(0.210, 0.054) CE(0.8719, 0.6284) SCL_v(2.433321, 2.018466) CL(0.234873, 0.224958 Prec@1(68.629, 73.438): 100%|█████████████████████████████████████| 84/84 [00:17<00:00,  4.72it/s]\n",
            "Evaluating(E(179)): BT(1.867, 2.809) CE(2.4377, 2.4312) Prec@1(51.030, 56.250): 100%|█████████████████████████████████| 79/79 [00:02<00:00, 26.76it/s]\n",
            "Best Prec@1: 51.030, Many Prec@1: 0.656, Med Prec@1: 0.525, Few Prec@1: 0.323\n",
            "Training(E(180)): BT(0.234, 0.055) CE(0.8484, 0.8277) SCL_v(2.400841, 2.142592) CL(0.221566, 0.216604 Prec@1(68.759, 68.750): 100%|█████████████████████████████████████| 84/84 [00:19<00:00,  4.23it/s]\n",
            "Evaluating(E(180)): BT(2.009, 2.957) CE(2.4874, 2.6824) Prec@1(50.890, 62.500): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 25.40it/s]\n",
            "Best Prec@1: 51.030, Many Prec@1: 0.656, Med Prec@1: 0.525, Few Prec@1: 0.323\n",
            "Training(E(181)): BT(0.966, 0.761) CE(0.8583, 0.9390) SCL_v(2.432868, 2.358625) CL(0.275673, 0.273856 Prec@1(68.834, 66.406): 100%|█████████████████████████████████████| 84/84 [01:21<00:00,  1.03it/s]\n",
            "Evaluating(E(181)): BT(1.884, 2.842) CE(2.4592, 2.6046) Prec@1(50.980, 62.500): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 26.28it/s]\n",
            "Best Prec@1: 51.030, Many Prec@1: 0.656, Med Prec@1: 0.525, Few Prec@1: 0.323\n",
            "Training(E(182)): BT(0.227, 0.055) CE(0.8273, 0.8293) SCL_v(2.385543, 2.342391) CL(0.275624, 0.277566 Prec@1(69.754, 64.844): 100%|█████████████████████████████████████| 84/84 [00:19<00:00,  4.37it/s]\n",
            "Evaluating(E(182)): BT(2.093, 3.023) CE(2.4009, 2.5508) Prec@1(51.420, 50.000): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 24.91it/s]\n",
            "Best Prec@1: 51.420, Many Prec@1: 0.661, Med Prec@1: 0.522, Few Prec@1: 0.334\n",
            "Training(E(183)): BT(0.212, 0.053) CE(0.8474, 0.7855) SCL_v(2.425257, 2.375876) CL(0.276977, 0.277127 Prec@1(69.373, 71.094): 100%|█████████████████████████████████████| 84/84 [00:17<00:00,  4.68it/s]\n",
            "Evaluating(E(183)): BT(2.378, 3.718) CE(2.4035, 2.3684) Prec@1(51.380, 56.250): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 19.86it/s]\n",
            "Best Prec@1: 51.420, Many Prec@1: 0.661, Med Prec@1: 0.522, Few Prec@1: 0.334\n",
            "Training(E(184)): BT(0.216, 0.055) CE(0.8553, 0.9693) SCL_v(2.419166, 2.513371) CL(0.276414, 0.269249 Prec@1(69.224, 69.531): 100%|█████████████████████████████████████| 84/84 [00:18<00:00,  4.58it/s]\n",
            "Evaluating(E(184)): BT(1.896, 2.842) CE(2.4443, 2.4867) Prec@1(51.210, 62.500): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 26.29it/s]\n",
            "Best Prec@1: 51.420, Many Prec@1: 0.661, Med Prec@1: 0.522, Few Prec@1: 0.334\n",
            "Training(E(185)): BT(0.215, 0.070) CE(0.8213, 0.7295) SCL_v(2.391978, 2.244966) CL(0.274116, 0.273669 Prec@1(70.368, 75.781): 100%|█████████████████████████████████████| 84/84 [00:18<00:00,  4.59it/s]\n",
            "Evaluating(E(185)): BT(2.679, 3.717) CE(2.4212, 2.4677) Prec@1(51.210, 62.500): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 20.45it/s]\n",
            "Best Prec@1: 51.420, Many Prec@1: 0.661, Med Prec@1: 0.522, Few Prec@1: 0.334\n",
            "Training(E(186)): BT(0.212, 0.055) CE(0.8107, 0.7673) SCL_v(2.390595, 2.448630) CL(0.274789, 0.272589 Prec@1(70.396, 75.000): 100%|█████████████████████████████████████| 84/84 [00:17<00:00,  4.68it/s]\n",
            "Evaluating(E(186)): BT(1.929, 2.873) CE(2.4011, 2.3872) Prec@1(51.560, 62.500): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 26.10it/s]\n",
            "Best Prec@1: 51.560, Many Prec@1: 0.665, Med Prec@1: 0.526, Few Prec@1: 0.330\n",
            "Training(E(187)): BT(0.224, 0.059) CE(0.8054, 0.6769) SCL_v(2.379848, 2.259245) CL(0.271776, 0.273465 Prec@1(70.201, 76.562): 100%|█████████████████████████████████████| 84/84 [00:19<00:00,  4.39it/s]\n",
            "Evaluating(E(187)): BT(2.156, 3.098) CE(2.4201, 2.5443) Prec@1(51.450, 56.250): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 24.27it/s]\n",
            "Best Prec@1: 51.560, Many Prec@1: 0.665, Med Prec@1: 0.526, Few Prec@1: 0.330\n",
            "Training(E(188)): BT(0.217, 0.054) CE(0.8000, 0.6587) SCL_v(2.382109, 2.176708) CL(0.274164, 0.271851 Prec@1(70.945, 75.000): 100%|█████████████████████████████████████| 84/84 [00:18<00:00,  4.56it/s]\n",
            "Evaluating(E(188)): BT(1.881, 2.829) CE(2.4263, 2.4748) Prec@1(51.270, 50.000): 100%|█████████████████████████████████| 79/79 [00:02<00:00, 26.46it/s]\n",
            "Best Prec@1: 51.560, Many Prec@1: 0.665, Med Prec@1: 0.526, Few Prec@1: 0.330\n",
            "Training(E(189)): BT(0.227, 0.058) CE(0.7952, 0.8208) SCL_v(2.383337, 2.209386) CL(0.272042, 0.268808 Prec@1(71.066, 70.312): 100%|█████████████████████████████████████| 84/84 [00:19<00:00,  4.36it/s]\n",
            "Evaluating(E(189)): BT(2.048, 3.040) CE(2.4175, 2.4550) Prec@1(51.660, 62.500): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 24.78it/s]\n",
            "Best Prec@1: 51.660, Many Prec@1: 0.669, Med Prec@1: 0.521, Few Prec@1: 0.333\n",
            "Training(E(190)): BT(0.213, 0.054) CE(0.7866, 0.7793) SCL_v(2.356415, 2.534297) CL(0.270264, 0.270131 Prec@1(71.094, 69.531): 100%|█████████████████████████████████████| 84/84 [00:18<00:00,  4.65it/s]\n",
            "Evaluating(E(190)): BT(2.073, 3.280) CE(2.4200, 2.4749) Prec@1(51.600, 62.500): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 22.69it/s]\n",
            "Best Prec@1: 51.660, Many Prec@1: 0.669, Med Prec@1: 0.521, Few Prec@1: 0.333\n",
            "Training(E(191)): BT(0.985, 0.730) CE(0.7871, 0.8490) SCL_v(2.351078, 2.576124) CL(0.272982, 0.276793 Prec@1(71.336, 70.312): 100%|█████████████████████████████████████| 84/84 [01:22<00:00,  1.01it/s]\n",
            "Evaluating(E(191)): BT(1.887, 2.840) CE(2.4203, 2.4662) Prec@1(51.530, 62.500): 100%|█████████████████████████████████| 79/79 [00:02<00:00, 26.45it/s]\n",
            "Best Prec@1: 51.660, Many Prec@1: 0.669, Med Prec@1: 0.521, Few Prec@1: 0.333\n",
            "Training(E(192)): BT(0.212, 0.052) CE(0.8029, 0.8361) SCL_v(2.351935, 2.355445) CL(0.270986, 0.269733 Prec@1(70.778, 67.188): 100%|█████████████████████████████████████| 84/84 [00:17<00:00,  4.67it/s]\n",
            "Evaluating(E(192)): BT(2.451, 3.823) CE(2.4013, 2.4362) Prec@1(51.730, 62.500): 100%|█████████████████████████████████| 79/79 [00:04<00:00, 19.50it/s]\n",
            "Best Prec@1: 51.730, Many Prec@1: 0.670, Med Prec@1: 0.526, Few Prec@1: 0.329\n",
            "Training(E(193)): BT(0.215, 0.052) CE(0.7704, 0.8100) SCL_v(2.342998, 2.358357) CL(0.271768, 0.270072 Prec@1(71.912, 74.219): 100%|█████████████████████████████████████| 84/84 [00:18<00:00,  4.60it/s]\n",
            "Evaluating(E(193)): BT(1.997, 3.028) CE(2.4014, 2.4037) Prec@1(51.600, 62.500): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 24.96it/s]\n",
            "Best Prec@1: 51.730, Many Prec@1: 0.670, Med Prec@1: 0.526, Few Prec@1: 0.329\n",
            "Training(E(194)): BT(0.212, 0.060) CE(0.7824, 0.5279) SCL_v(2.358731, 2.354418) CL(0.272660, 0.269671 Prec@1(71.243, 82.031): 100%|█████████████████████████████████████| 84/84 [00:18<00:00,  4.65it/s]\n",
            "Evaluating(E(194)): BT(2.672, 3.736) CE(2.4012, 2.3852) Prec@1(51.630, 62.500): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 20.36it/s]\n",
            "Best Prec@1: 51.730, Many Prec@1: 0.670, Med Prec@1: 0.526, Few Prec@1: 0.329\n",
            "Training(E(195)): BT(0.215, 0.054) CE(0.7798, 0.7417) SCL_v(2.351648, 2.417831) CL(0.273292, 0.276678 Prec@1(71.577, 73.438): 100%|█████████████████████████████████████| 84/84 [00:18<00:00,  4.62it/s]\n",
            "Evaluating(E(195)): BT(1.901, 2.840) CE(2.4132, 2.4804) Prec@1(51.780, 62.500): 100%|█████████████████████████████████| 79/79 [00:02<00:00, 26.45it/s]\n",
            "Best Prec@1: 51.780, Many Prec@1: 0.667, Med Prec@1: 0.528, Few Prec@1: 0.332\n",
            "Training(E(196)): BT(0.223, 0.059) CE(0.7811, 0.7920) SCL_v(2.329530, 2.590766) CL(0.272937, 0.276069 Prec@1(71.475, 72.656): 100%|█████████████████████████████████████| 84/84 [00:18<00:00,  4.42it/s]\n",
            "Evaluating(E(196)): BT(2.199, 3.139) CE(2.4097, 2.4515) Prec@1(51.720, 62.500): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 24.01it/s]\n",
            "Best Prec@1: 51.780, Many Prec@1: 0.667, Med Prec@1: 0.528, Few Prec@1: 0.332\n",
            "Training(E(197)): BT(0.213, 0.055) CE(0.7764, 0.8129) SCL_v(2.336988, 2.327804) CL(0.271320, 0.272565 Prec@1(71.754, 73.438): 100%|█████████████████████████████████████| 84/84 [00:18<00:00,  4.66it/s]\n",
            "Evaluating(E(197)): BT(1.926, 2.890) CE(2.4054, 2.4135) Prec@1(51.830, 62.500): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 25.90it/s]\n",
            "Best Prec@1: 51.830, Many Prec@1: 0.669, Med Prec@1: 0.527, Few Prec@1: 0.332\n",
            "Training(E(198)): BT(0.233, 0.060) CE(0.7677, 0.9275) SCL_v(2.340067, 2.468506) CL(0.271486, 0.276373 Prec@1(72.582, 67.969): 100%|█████████████████████████████████████| 84/84 [00:19<00:00,  4.26it/s]\n",
            "Evaluating(E(198)): BT(1.937, 2.878) CE(2.4068, 2.4288) Prec@1(51.950, 62.500): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 26.07it/s]\n",
            "Best Prec@1: 51.950, Many Prec@1: 0.670, Med Prec@1: 0.531, Few Prec@1: 0.330\n",
            "Training(E(199)): BT(0.213, 0.054) CE(0.7748, 0.5905) SCL_v(2.341630, 2.313739) CL(0.271615, 0.268531 Prec@1(71.903, 71.875): 100%|█████████████████████████████████████| 84/84 [00:18<00:00,  4.64it/s]\n",
            "Evaluating(E(199)): BT(2.114, 3.390) CE(2.4069, 2.4224) Prec@1(51.890, 62.500): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 21.98it/s]\n",
            "Best Prec@1: 51.950, Many Prec@1: 0.670, Med Prec@1: 0.531, Few Prec@1: 0.330\n",
            "Training(E(200)): BT(0.217, 0.052) CE(0.7698, 0.5917) SCL_v(2.326659, 2.188384) CL(0.271790, 0.263719 Prec@1(71.615, 76.562): 100%|█████████████████████████████████████| 84/84 [00:18<00:00,  4.57it/s]\n",
            "Evaluating(E(200)): BT(1.962, 3.049) CE(2.4035, 2.4377) Prec@1(51.960, 56.250): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 24.72it/s]\n",
            "Best Prec@1: 51.960, Many Prec@1: 0.671, Med Prec@1: 0.531, Few Prec@1: 0.330\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qDbya7C6C5XV"
      },
      "execution_count": 6,
      "outputs": []
    }
  ]
}