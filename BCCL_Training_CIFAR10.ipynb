{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abhinav1004/LongTailCLR/blob/main/BCCL_Training_CIFAR10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IwWa7y9mB8la",
        "outputId": "06c16be3-a109-4f3c-f8e3-f65e63a4db70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/BCCL\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jE0IY1snCVKP",
        "outputId": "f1e05992-9e71-4d1b-857c-5e65b6697f28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/BCCL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.getcwd())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubPln4esC8PJ",
        "outputId": "3328b7a2-1170-4f28-a184-55ab23b8b028"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/BCCL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kmeans_gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmuBIHLEDCR2",
        "outputId": "1a87b3bf-85b3-48ba-e3f9-0a7ecb7a2dd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting kmeans_gpu\n",
            "  Downloading kmeans_gpu-0.0.5-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from kmeans_gpu) (2.5.1+cu124)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from kmeans_gpu) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->kmeans_gpu) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->kmeans_gpu) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->kmeans_gpu) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->kmeans_gpu) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->kmeans_gpu) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->kmeans_gpu)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->kmeans_gpu)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->kmeans_gpu)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->kmeans_gpu)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->kmeans_gpu)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->kmeans_gpu)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->kmeans_gpu)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->kmeans_gpu)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->kmeans_gpu)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->kmeans_gpu) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->kmeans_gpu) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->kmeans_gpu)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->kmeans_gpu) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->kmeans_gpu) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->kmeans_gpu) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->kmeans_gpu) (3.0.2)\n",
            "Downloading kmeans_gpu-0.0.5-py3-none-any.whl (6.2 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m106.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m84.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m93.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, kmeans_gpu\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed kmeans_gpu-0.0.5 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorboardx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6plkDIpDmAE",
        "outputId": "a80258ca-39cc-46d3-91ee-8907c5fc3954"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorboardx\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from tensorboardx) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboardx) (24.2)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.11/dist-packages (from tensorboardx) (4.25.6)\n",
            "Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/101.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorboardx\n",
            "Successfully installed tensorboardx-2.6.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --dataset cifar10 \\\n",
        "  --arch resnet32 --epochs 200 --temp 0.1 \\\n",
        "  --lr 0.15  \\\n",
        "  --wd 5e-4 --cos True \\\n",
        "  -b 128 --feat_dim 128 --tb_save"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0xS2l0GC2Ao",
        "outputId": "a4e01f9f-768a-48d2-cc03-46583c69a0e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n",
            "100% 170M/170M [00:05<00:00, 30.9MB/s]\n",
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "=> creating model 'resnet32'\n",
            "Model(\n",
            "  (encoder): ResNet(\n",
            "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (layer1): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (shortcut): Sequential()\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (shortcut): Sequential()\n",
            "      )\n",
            "      (2): BasicBlock(\n",
            "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (shortcut): Sequential()\n",
            "      )\n",
            "      (3): BasicBlock(\n",
            "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (shortcut): Sequential()\n",
            "      )\n",
            "      (4): BasicBlock(\n",
            "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (shortcut): Sequential()\n",
            "      )\n",
            "    )\n",
            "    (layer2): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (shortcut): LambdaLayer()\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (shortcut): Sequential()\n",
            "      )\n",
            "      (2): BasicBlock(\n",
            "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (shortcut): Sequential()\n",
            "      )\n",
            "      (3): BasicBlock(\n",
            "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (shortcut): Sequential()\n",
            "      )\n",
            "      (4): BasicBlock(\n",
            "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (shortcut): Sequential()\n",
            "      )\n",
            "    )\n",
            "    (layer3): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (shortcut): LambdaLayer()\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (shortcut): Sequential()\n",
            "      )\n",
            "      (2): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (shortcut): Sequential()\n",
            "      )\n",
            "      (3): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (shortcut): Sequential()\n",
            "      )\n",
            "      (4): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (shortcut): Sequential()\n",
            "      )\n",
            "    )\n",
            "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  )\n",
            "  (head): Sequential(\n",
            "    (0): Linear(in_features=64, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Linear(in_features=512, out_features=128, bias=True)\n",
            "  )\n",
            "  (fc): NormedLinear()\n",
            ")\n",
            "Training(E(1)): BT(0.243, 0.061) CE(1.7733, 1.3608) SCL_v(2.871284, 2.787681) Prec@1(17.529, 25.781): 100%|█████████████████████████████████████████████████████████████| 96/96 [00:23<00:00,  4.09it/s]\n",
            "Evaluating(E(1)): BT(2.050, 3.060) CE(2.8798, 2.7279) Prec@1(22.930, 25.000): 100%|███████████████████████████████████| 79/79 [00:03<00:00, 24.64it/s]\n",
            "Best Prec@1: 22.930, Many Prec@1: 0.233, Med Prec@1: 0.216, Few Prec@1: 0.000\n",
            "Training(E(2)): BT(0.200, 0.047) CE(1.4122, 1.1943) SCL_v(2.724844, 2.585607) Prec@1(32.194, 23.438): 100%|█████████████████████████████████████████████████████████████| 96/96 [00:19<00:00,  4.96it/s]\n",
            "Evaluating(E(2)): BT(2.003, 3.162) CE(2.7189, 2.6207) Prec@1(26.010, 18.750): 100%|███████████████████████████████████| 79/79 [00:03<00:00, 23.33it/s]\n",
            "Best Prec@1: 26.010, Many Prec@1: 0.266, Med Prec@1: 0.235, Few Prec@1: 0.000\n",
            "Training(E(3)): BT(0.214, 0.048) CE(1.3624, 1.2811) SCL_v(2.659425, 2.703915) Prec@1(34.497, 31.250): 100%|█████████████████████████████████████████████████████████████| 96/96 [00:20<00:00,  4.63it/s]\n",
            "Evaluating(E(3)): BT(1.839, 2.766) CE(3.0395, 3.1127) Prec@1(27.800, 31.250): 100%|███████████████████████████████████| 79/79 [00:02<00:00, 27.07it/s]\n",
            "Best Prec@1: 27.800, Many Prec@1: 0.278, Med Prec@1: 0.279, Few Prec@1: 0.000\n",
            "Training(E(4)): BT(0.218, 0.059) CE(1.2870, 1.3227) SCL_v(2.625634, 2.491419) Prec@1(37.907, 29.688): 100%|█████████████████████████████████████████████████████████████| 96/96 [00:21<00:00,  4.53it/s]\n",
            "Evaluating(E(4)): BT(2.104, 3.019) CE(2.8678, 2.9334) Prec@1(30.330, 12.500): 100%|███████████████████████████████████| 79/79 [00:03<00:00, 25.08it/s]\n",
            "Best Prec@1: 30.330, Many Prec@1: 0.304, Med Prec@1: 0.301, Few Prec@1: 0.000\n",
            "Training(E(5)): BT(0.210, 0.054) CE(1.2360, 1.2683) SCL_v(2.597721, 2.442006) Prec@1(40.039, 48.438): 100%|█████████████████████████████████████████████████████████████| 96/96 [00:20<00:00,  4.72it/s]\n",
            "Evaluating(E(5)): BT(2.185, 3.520) CE(2.6900, 2.6924) Prec@1(29.160, 25.000): 100%|███████████████████████████████████| 79/79 [00:03<00:00, 20.93it/s]\n",
            "Best Prec@1: 30.330, Many Prec@1: 0.304, Med Prec@1: 0.301, Few Prec@1: 0.000\n",
            "Training(E(6)): BT(0.209, 0.048) CE(1.1920, 1.3123) SCL_v(2.559022, 2.641949) Prec@1(41.398, 49.219): 100%|█████████████████████████████████████████████████████████████| 96/96 [00:20<00:00,  4.76it/s]\n",
            "Evaluating(E(6)): BT(2.051, 2.992) CE(2.6008, 2.7551) Prec@1(36.810, 25.000): 100%|███████████████████████████████████| 79/79 [00:03<00:00, 25.20it/s]\n",
            "Best Prec@1: 36.810, Many Prec@1: 0.444, Med Prec@1: 0.065, Few Prec@1: 0.000\n",
            "Training(E(7)): BT(0.234, 0.051) CE(1.1693, 1.0317) SCL_v(2.543106, 2.347495) Prec@1(43.140, 49.219): 100%|█████████████████████████████████████████████████████████████| 96/96 [00:22<00:00,  4.25it/s]\n",
            "Evaluating(E(7)): BT(2.002, 2.954) CE(2.5984, 2.8915) Prec@1(37.130, 18.750): 100%|███████████████████████████████████| 79/79 [00:03<00:00, 25.57it/s]\n",
            "Best Prec@1: 37.130, Many Prec@1: 0.416, Med Prec@1: 0.194, Few Prec@1: 0.000\n",
            "Training(E(8)): BT(0.207, 0.051) CE(1.1157, 0.9891) SCL_v(2.487828, 2.429390) Prec@1(45.532, 55.469): 100%|█████████████████████████████████████████████████████████████| 96/96 [00:20<00:00,  4.80it/s]\n",
            "Evaluating(E(8)): BT(2.819, 3.973) CE(2.8077, 2.5936) Prec@1(33.680, 18.750): 100%|███████████████████████████████████| 79/79 [00:04<00:00, 19.21it/s]\n",
            "Best Prec@1: 37.130, Many Prec@1: 0.416, Med Prec@1: 0.194, Few Prec@1: 0.000\n",
            "Training(E(9)): BT(0.206, 0.051) CE(1.1054, 1.0873) SCL_v(2.471584, 2.506444) Prec@1(46.403, 46.094): 100%|█████████████████████████████████████████████████████████████| 96/96 [00:19<00:00,  4.82it/s]\n",
            "Evaluating(E(9)): BT(1.907, 2.847) CE(1.9519, 2.3427) Prec@1(41.670, 37.500): 100%|███████████████████████████████████| 79/79 [00:02<00:00, 26.45it/s]\n",
            "Best Prec@1: 41.670, Many Prec@1: 0.351, Med Prec@1: 0.680, Few Prec@1: 0.000\n",
            "Training(E(10)): BT(0.225, 0.047) CE(1.0589, 0.8901) SCL_v(2.447161, 2.281024) Prec@1(48.275, 50.000): 100%|████████████████████████████████████████████████████████████| 96/96 [00:21<00:00,  4.41it/s]\n",
            "Evaluating(E(10)): BT(1.924, 2.903) CE(2.0299, 2.2831) Prec@1(47.660, 43.750): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 25.93it/s]\n",
            "Best Prec@1: 47.660, Many Prec@1: 0.493, Med Prec@1: 0.409, Few Prec@1: 0.000\n",
            "Training(E(11)): BT(0.300, 0.130) CE(1.0514, 1.0824) SCL_v(2.412086, 2.405645) CL(0.614653, 0.629596 Prec@1(49.316, 47.656): 100%|██████████████████████████████████████| 96/96 [00:28<00:00,  3.31it/s]\n",
            "Evaluating(E(11)): BT(1.945, 2.906) CE(2.5675, 2.7879) Prec@1(42.450, 31.250): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 25.90it/s]\n",
            "Best Prec@1: 47.660, Many Prec@1: 0.493, Med Prec@1: 0.409, Few Prec@1: 0.000\n",
            "Training(E(12)): BT(0.228, 0.050) CE(1.0228, 1.1201) SCL_v(2.381019, 2.617599) CL(0.602898, 0.573958 Prec@1(49.845, 26.562): 100%|██████████████████████████████████████| 96/96 [00:21<00:00,  4.37it/s]\n",
            "Evaluating(E(12)): BT(1.915, 2.856) CE(2.0816, 2.4463) Prec@1(50.430, 50.000): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 26.30it/s]\n",
            "Best Prec@1: 50.430, Many Prec@1: 0.486, Med Prec@1: 0.580, Few Prec@1: 0.000\n",
            "Training(E(13)): BT(0.215, 0.053) CE(0.9683, 0.8478) SCL_v(2.354873, 2.226899) CL(0.523551, 0.453492 Prec@1(50.317, 54.688): 100%|██████████████████████████████████████| 96/96 [00:20<00:00,  4.58it/s]\n",
            "Evaluating(E(13)): BT(2.605, 3.630) CE(2.1259, 1.7597) Prec@1(40.860, 43.750): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 20.91it/s]\n",
            "Best Prec@1: 50.430, Many Prec@1: 0.486, Med Prec@1: 0.580, Few Prec@1: 0.000\n",
            "Training(E(14)): BT(0.214, 0.049) CE(0.9376, 0.9573) SCL_v(2.343684, 2.461081) CL(0.316898, 0.137599 Prec@1(53.385, 61.719): 100%|██████████████████████████████████████| 96/96 [00:20<00:00,  4.65it/s]\n",
            "Evaluating(E(14)): BT(2.094, 3.380) CE(1.9359, 2.2605) Prec@1(50.050, 37.500): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 22.04it/s]\n",
            "Best Prec@1: 50.430, Many Prec@1: 0.486, Med Prec@1: 0.580, Few Prec@1: 0.000\n",
            "Training(E(15)): BT(0.219, 0.049) CE(0.8898, 0.9065) SCL_v(2.302241, 2.221468) CL(-0.078200, -0.280990 Prec@1(54.688, 61.719): 100%|████████████████████████████████████| 96/96 [00:21<00:00,  4.53it/s]\n",
            "Evaluating(E(15)): BT(1.881, 2.850) CE(2.3579, 2.3455) Prec@1(46.540, 56.250): 100%|██████████████████████████████████| 79/79 [00:02<00:00, 26.36it/s]\n",
            "Best Prec@1: 50.430, Many Prec@1: 0.486, Med Prec@1: 0.580, Few Prec@1: 0.000\n",
            "Training(E(16)): BT(0.226, 0.050) CE(0.8994, 0.8687) SCL_v(2.286338, 2.504546) CL(-0.428694, -0.524054 Prec@1(54.793, 55.469): 100%|████████████████████████████████████| 96/96 [00:21<00:00,  4.40it/s]\n",
            "Evaluating(E(16)): BT(1.956, 2.932) CE(1.8282, 2.0893) Prec@1(49.780, 43.750): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 25.67it/s]\n",
            "Best Prec@1: 50.430, Many Prec@1: 0.486, Med Prec@1: 0.580, Few Prec@1: 0.000\n",
            "Training(E(17)): BT(0.214, 0.056) CE(0.9008, 0.9481) SCL_v(2.291665, 2.170112) CL(-0.576862, -0.611986 Prec@1(54.818, 51.562): 100%|████████████████████████████████████| 96/96 [00:20<00:00,  4.61it/s]\n",
            "Evaluating(E(17)): BT(2.864, 3.947) CE(2.0598, 2.2667) Prec@1(49.530, 31.250): 100%|██████████████████████████████████| 79/79 [00:04<00:00, 19.28it/s]\n",
            "Best Prec@1: 50.430, Many Prec@1: 0.486, Med Prec@1: 0.580, Few Prec@1: 0.000\n",
            "Training(E(18)): BT(0.213, 0.052) CE(0.8707, 1.0671) SCL_v(2.264668, 2.359601) CL(-0.618777, -0.634210 Prec@1(56.624, 48.438): 100%|████████████████████████████████████| 96/96 [00:20<00:00,  4.66it/s]\n",
            "Evaluating(E(18)): BT(2.100, 3.293) CE(1.5389, 1.1647) Prec@1(51.310, 50.000): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 22.21it/s]\n",
            "Best Prec@1: 51.310, Many Prec@1: 0.451, Med Prec@1: 0.764, Few Prec@1: 0.000\n",
            "Training(E(19)): BT(0.223, 0.051) CE(0.8628, 0.8093) SCL_v(2.243177, 2.296417) CL(-0.628854, -0.629380 Prec@1(56.649, 55.469): 100%|████████████████████████████████████| 96/96 [00:21<00:00,  4.45it/s]\n",
            "Evaluating(E(19)): BT(1.948, 2.920) CE(1.8863, 2.1802) Prec@1(58.010, 56.250): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 25.79it/s]\n",
            "Best Prec@1: 58.010, Many Prec@1: 0.626, Med Prec@1: 0.398, Few Prec@1: 0.000\n",
            "Training(E(20)): BT(0.229, 0.054) CE(0.8582, 0.7569) SCL_v(2.231890, 2.268132) CL(-0.633167, -0.631763 Prec@1(57.397, 61.719): 100%|████████████████████████████████████| 96/96 [00:22<00:00,  4.34it/s]\n",
            "Evaluating(E(20)): BT(1.927, 2.877) CE(1.7455, 1.9980) Prec@1(50.330, 43.750): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 26.11it/s]\n",
            "Best Prec@1: 58.010, Many Prec@1: 0.626, Med Prec@1: 0.398, Few Prec@1: 0.000\n",
            "Training(E(21)): BT(0.301, 0.135) CE(0.8236, 0.8175) SCL_v(2.216770, 2.301045) CL(0.563616, 0.567800 Prec@1(58.789, 59.375): 100%|██████████████████████████████████████| 96/96 [00:29<00:00,  3.31it/s]\n",
            "Evaluating(E(21)): BT(1.965, 2.925) CE(2.0896, 2.5304) Prec@1(50.170, 37.500): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 25.71it/s]\n",
            "Best Prec@1: 58.010, Many Prec@1: 0.626, Med Prec@1: 0.398, Few Prec@1: 0.000\n",
            "Training(E(22)): BT(0.228, 0.051) CE(0.8349, 0.8897) SCL_v(2.215102, 2.386746) CL(0.546509, 0.541861 Prec@1(58.577, 59.375): 100%|██████████████████████████████████████| 96/96 [00:22<00:00,  4.36it/s]\n",
            "Evaluating(E(22)): BT(1.915, 2.860) CE(1.6328, 1.9667) Prec@1(56.860, 56.250): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 26.16it/s]\n",
            "Best Prec@1: 58.010, Many Prec@1: 0.626, Med Prec@1: 0.398, Few Prec@1: 0.000\n",
            "Training(E(23)): BT(0.212, 0.060) CE(0.8216, 0.9054) SCL_v(2.219119, 2.422865) CL(0.487179, 0.426162 Prec@1(59.058, 63.281): 100%|██████████████████████████████████████| 96/96 [00:20<00:00,  4.65it/s]\n",
            "Evaluating(E(23)): BT(2.925, 4.077) CE(2.1069, 2.1114) Prec@1(52.330, 56.250): 100%|██████████████████████████████████| 79/79 [00:04<00:00, 18.69it/s]\n",
            "Best Prec@1: 58.010, Many Prec@1: 0.626, Med Prec@1: 0.398, Few Prec@1: 0.000\n",
            "Training(E(24)): BT(0.209, 0.052) CE(0.8222, 0.8172) SCL_v(2.212862, 2.231676) CL(0.324345, 0.189628 Prec@1(58.927, 60.156): 100%|██████████████████████████████████████| 96/96 [00:20<00:00,  4.76it/s]\n",
            "Evaluating(E(24)): BT(2.058, 3.097) CE(1.8371, 2.0983) Prec@1(59.230, 56.250): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 23.64it/s]\n",
            "Best Prec@1: 59.230, Many Prec@1: 0.626, Med Prec@1: 0.458, Few Prec@1: 0.000\n",
            "Training(E(25)): BT(0.223, 0.051) CE(0.7935, 0.5856) SCL_v(2.167689, 2.091585) CL(0.002115, -0.184506 Prec@1(60.677, 67.969): 100%|█████████████████████████████████████| 96/96 [00:21<00:00,  4.46it/s]\n",
            "Evaluating(E(25)): BT(1.943, 2.899) CE(1.8444, 2.3145) Prec@1(59.520, 50.000): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 25.95it/s]\n",
            "Best Prec@1: 59.520, Many Prec@1: 0.610, Med Prec@1: 0.535, Few Prec@1: 0.000\n",
            "Training(E(26)): BT(0.226, 0.062) CE(0.8270, 0.7596) SCL_v(2.203463, 2.153904) CL(-0.341915, -0.449599 Prec@1(60.433, 64.062): 100%|████████████████████████████████████| 96/96 [00:21<00:00,  4.37it/s]\n",
            "Evaluating(E(26)): BT(1.937, 2.907) CE(1.7276, 1.6825) Prec@1(54.470, 56.250): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 25.86it/s]\n",
            "Best Prec@1: 59.520, Many Prec@1: 0.610, Med Prec@1: 0.535, Few Prec@1: 0.000\n",
            "Training(E(27)): BT(0.215, 0.050) CE(0.7736, 0.7185) SCL_v(2.176171, 2.003903) CL(-0.508397, -0.552524 Prec@1(60.767, 51.562): 100%|████████████████████████████████████| 96/96 [00:20<00:00,  4.62it/s]\n",
            "Evaluating(E(27)): BT(2.515, 4.001) CE(2.1145, 1.8251) Prec@1(53.940, 56.250): 100%|██████████████████████████████████| 79/79 [00:04<00:00, 18.61it/s]\n",
            "Best Prec@1: 59.520, Many Prec@1: 0.610, Med Prec@1: 0.535, Few Prec@1: 0.000\n",
            "Training(E(28)): BT(0.217, 0.051) CE(0.7556, 0.6761) SCL_v(2.153781, 1.941983) CL(-0.567113, -0.584390 Prec@1(62.443, 53.125): 100%|████████████████████████████████████| 96/96 [00:20<00:00,  4.57it/s]\n",
            "Evaluating(E(28)): BT(1.943, 2.897) CE(1.3421, 1.8846) Prec@1(62.880, 68.750): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 25.89it/s]\n",
            "Best Prec@1: 62.880, Many Prec@1: 0.621, Med Prec@1: 0.659, Few Prec@1: 0.000\n",
            "Training(E(29)): BT(0.228, 0.051) CE(0.7597, 0.7674) SCL_v(2.161462, 2.168226) CL(-0.588387, -0.594404 Prec@1(62.500, 66.406): 100%|████████████████████████████████████| 96/96 [00:22<00:00,  4.35it/s]\n",
            "Evaluating(E(29)): BT(2.019, 2.984) CE(1.6741, 1.3503) Prec@1(51.920, 62.500): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 25.25it/s]\n",
            "Best Prec@1: 62.880, Many Prec@1: 0.621, Med Prec@1: 0.659, Few Prec@1: 0.000\n",
            "Training(E(30)): BT(0.216, 0.055) CE(0.7719, 0.8106) SCL_v(2.150030, 2.323303) CL(-0.595184, -0.594359 Prec@1(61.312, 70.312): 100%|████████████████████████████████████| 96/96 [00:20<00:00,  4.58it/s]\n",
            "Evaluating(E(30)): BT(2.374, 3.329) CE(1.3957, 1.7823) Prec@1(64.320, 68.750): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 22.74it/s]\n",
            "Best Prec@1: 64.320, Many Prec@1: 0.625, Med Prec@1: 0.716, Few Prec@1: 0.000\n",
            "Training(E(31)): BT(0.299, 0.126) CE(0.7522, 0.6070) SCL_v(2.146416, 2.087807) CL(0.543975, 0.541921 Prec@1(61.621, 64.062): 100%|██████████████████████████████████████| 96/96 [00:28<00:00,  3.32it/s]\n",
            "Evaluating(E(31)): BT(1.923, 2.870) CE(1.8170, 1.6890) Prec@1(63.540, 50.000): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 26.27it/s]\n",
            "Best Prec@1: 64.320, Many Prec@1: 0.625, Med Prec@1: 0.716, Few Prec@1: 0.000\n",
            "Training(E(32)): BT(0.218, 0.053) CE(0.7441, 0.8365) SCL_v(2.133523, 2.335430) CL(0.514977, 0.493373 Prec@1(63.631, 59.375): 100%|██████████████████████████████████████| 96/96 [00:21<00:00,  4.52it/s]\n",
            "Evaluating(E(32)): BT(2.309, 3.305) CE(1.2763, 1.0246) Prec@1(60.750, 87.500): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 22.88it/s]\n",
            "Best Prec@1: 64.320, Many Prec@1: 0.625, Med Prec@1: 0.716, Few Prec@1: 0.000\n",
            "Training(E(33)): BT(0.215, 0.049) CE(0.7155, 0.8981) SCL_v(2.135131, 2.349034) CL(0.438490, 0.377613 Prec@1(63.582, 65.625): 100%|██████████████████████████████████████| 96/96 [00:20<00:00,  4.62it/s]\n",
            "Evaluating(E(33)): BT(2.222, 3.548) CE(1.8276, 2.2356) Prec@1(63.130, 62.500): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 20.90it/s]\n",
            "Best Prec@1: 64.320, Many Prec@1: 0.625, Med Prec@1: 0.716, Few Prec@1: 0.000\n",
            "Training(E(34)): BT(0.212, 0.048) CE(0.7336, 0.7921) SCL_v(2.134001, 2.152482) CL(0.263093, 0.112410 Prec@1(62.996, 67.969): 100%|██████████████████████████████████████| 96/96 [00:20<00:00,  4.69it/s]\n",
            "Evaluating(E(34)): BT(1.897, 2.827) CE(1.4464, 1.8575) Prec@1(57.470, 37.500): 100%|██████████████████████████████████| 79/79 [00:02<00:00, 26.61it/s]\n",
            "Best Prec@1: 64.320, Many Prec@1: 0.625, Med Prec@1: 0.716, Few Prec@1: 0.000\n",
            "Training(E(35)): BT(0.222, 0.050) CE(0.7277, 0.6203) SCL_v(2.132803, 2.003457) CL(-0.053228, -0.222625 Prec@1(63.794, 71.094): 100%|████████████████████████████████████| 96/96 [00:21<00:00,  4.48it/s]\n",
            "Evaluating(E(35)): BT(1.889, 2.839) CE(1.5605, 1.4882) Prec@1(63.150, 56.250): 100%|██████████████████████████████████| 79/79 [00:02<00:00, 26.48it/s]\n",
            "Best Prec@1: 64.320, Many Prec@1: 0.625, Med Prec@1: 0.716, Few Prec@1: 0.000\n",
            "Training(E(36)): BT(0.205, 0.051) CE(0.7174, 0.8597) SCL_v(2.130039, 2.279068) CL(-0.346445, -0.448263 Prec@1(63.680, 70.312): 100%|████████████████████████████████████| 96/96 [00:19<00:00,  4.84it/s]\n",
            "Evaluating(E(36)): BT(2.396, 3.762) CE(1.8464, 1.9378) Prec@1(59.400, 56.250): 100%|██████████████████████████████████| 79/79 [00:04<00:00, 19.67it/s]\n",
            "Best Prec@1: 64.320, Many Prec@1: 0.625, Med Prec@1: 0.716, Few Prec@1: 0.000\n",
            "Training(E(37)): BT(0.210, 0.051) CE(0.7020, 0.7427) SCL_v(2.107236, 2.294719) CL(-0.498367, -0.537246 Prec@1(65.698, 59.375): 100%|████████████████████████████████████| 96/96 [00:20<00:00,  4.73it/s]\n",
            "Evaluating(E(37)): BT(1.889, 2.825) CE(1.2749, 1.6992) Prec@1(66.650, 62.500): 100%|██████████████████████████████████| 79/79 [00:02<00:00, 26.59it/s]\n",
            "Best Prec@1: 66.650, Many Prec@1: 0.653, Med Prec@1: 0.722, Few Prec@1: 0.000\n",
            "Training(E(38)): BT(0.226, 0.050) CE(0.7062, 0.7201) SCL_v(2.099593, 2.346132) CL(-0.551537, -0.574039 Prec@1(64.551, 67.188): 100%|████████████████████████████████████| 96/96 [00:21<00:00,  4.39it/s]\n",
            "Evaluating(E(38)): BT(1.906, 2.842) CE(1.7214, 1.5926) Prec@1(61.400, 62.500): 100%|██████████████████████████████████| 79/79 [00:02<00:00, 26.41it/s]\n",
            "Best Prec@1: 66.650, Many Prec@1: 0.653, Med Prec@1: 0.722, Few Prec@1: 0.000\n",
            "Training(E(39)): BT(0.209, 0.055) CE(0.7092, 0.6213) SCL_v(2.104934, 2.017341) CL(-0.569144, -0.584838 Prec@1(63.761, 75.000): 100%|████████████████████████████████████| 96/96 [00:20<00:00,  4.71it/s]\n",
            "Evaluating(E(39)): BT(2.767, 3.838) CE(1.8371, 1.9857) Prec@1(64.030, 56.250): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 19.85it/s]\n",
            "Best Prec@1: 66.650, Many Prec@1: 0.653, Med Prec@1: 0.722, Few Prec@1: 0.000\n",
            "Training(E(40)): BT(0.208, 0.050) CE(0.6997, 0.8512) SCL_v(2.107984, 2.267781) CL(-0.576959, -0.579009 Prec@1(64.868, 61.719): 100%|████████████████████████████████████| 96/96 [00:20<00:00,  4.77it/s]\n",
            "Evaluating(E(40)): BT(2.079, 3.263) CE(1.6715, 1.8597) Prec@1(60.180, 56.250): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 22.47it/s]\n",
            "Best Prec@1: 66.650, Many Prec@1: 0.653, Med Prec@1: 0.722, Few Prec@1: 0.000\n",
            "Training(E(41)): BT(0.299, 0.188) CE(0.7264, 0.6487) SCL_v(2.087725, 1.909881) CL(0.532745, 0.524938 Prec@1(64.616, 58.594): 100%|██████████████████████████████████████| 96/96 [00:28<00:00,  3.32it/s]\n",
            "Evaluating(E(41)): BT(2.743, 3.761) CE(1.7601, 2.0195) Prec@1(53.590, 50.000): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 20.21it/s]\n",
            "Best Prec@1: 66.650, Many Prec@1: 0.653, Med Prec@1: 0.722, Few Prec@1: 0.000\n",
            "Training(E(42)): BT(0.208, 0.050) CE(0.6964, 0.6474) SCL_v(2.080455, 1.892860) CL(0.511562, 0.500784 Prec@1(65.723, 63.281): 100%|██████████████████████████████████████| 96/96 [00:20<00:00,  4.77it/s]\n",
            "Evaluating(E(42)): BT(1.910, 2.948) CE(1.8157, 1.5265) Prec@1(63.750, 62.500): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 24.96it/s]\n",
            "Best Prec@1: 66.650, Many Prec@1: 0.653, Med Prec@1: 0.722, Few Prec@1: 0.000\n",
            "Training(E(43)): BT(0.220, 0.054) CE(0.6805, 0.6255) SCL_v(2.080437, 2.124883) CL(0.458334, 0.421864 Prec@1(65.633, 64.062): 100%|██████████████████████████████████████| 96/96 [00:21<00:00,  4.51it/s]\n",
            "Evaluating(E(43)): BT(1.854, 2.795) CE(1.1668, 1.2506) Prec@1(65.180, 75.000): 100%|██████████████████████████████████| 79/79 [00:02<00:00, 26.72it/s]\n",
            "Best Prec@1: 66.650, Many Prec@1: 0.653, Med Prec@1: 0.722, Few Prec@1: 0.000\n",
            "Training(E(44)): BT(0.221, 0.062) CE(0.6900, 0.6195) SCL_v(2.073181, 1.910017) CL(0.312277, 0.189306 Prec@1(65.552, 67.969): 100%|██████████████████████████████████████| 96/96 [00:21<00:00,  4.48it/s]\n",
            "Evaluating(E(44)): BT(1.974, 2.918) CE(1.4596, 1.5821) Prec@1(62.810, 56.250): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 25.83it/s]\n",
            "Best Prec@1: 66.650, Many Prec@1: 0.653, Med Prec@1: 0.722, Few Prec@1: 0.000\n",
            "Training(E(45)): BT(0.210, 0.052) CE(0.6919, 0.8886) SCL_v(2.072765, 2.312470) CL(0.024399, -0.141390 Prec@1(66.016, 56.250): 100%|█████████████████████████████████████| 96/96 [00:20<00:00,  4.73it/s]\n",
            "Evaluating(E(45)): BT(2.460, 3.856) CE(1.6914, 1.8873) Prec@1(60.950, 43.750): 100%|██████████████████████████████████| 79/79 [00:04<00:00, 19.30it/s]\n",
            "Best Prec@1: 66.650, Many Prec@1: 0.653, Med Prec@1: 0.722, Few Prec@1: 0.000\n",
            "Training(E(46)): BT(0.209, 0.051) CE(0.6863, 0.6922) SCL_v(2.069200, 2.019326) CL(-0.284833, -0.393227 Prec@1(66.512, 61.719): 100%|████████████████████████████████████| 96/96 [00:20<00:00,  4.74it/s]\n",
            "Evaluating(E(46)): BT(1.992, 2.968) CE(1.3390, 1.1478) Prec@1(62.330, 68.750): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 25.34it/s]\n",
            "Best Prec@1: 66.650, Many Prec@1: 0.653, Med Prec@1: 0.722, Few Prec@1: 0.000\n",
            "Training(E(47)): BT(0.224, 0.052) CE(0.6793, 0.6984) SCL_v(2.058423, 2.058223) CL(-0.462777, -0.507039 Prec@1(67.017, 71.875): 100%|████████████████████████████████████| 96/96 [00:21<00:00,  4.43it/s]\n",
            "Evaluating(E(47)): BT(1.898, 2.835) CE(1.5135, 1.5443) Prec@1(68.610, 81.250): 100%|██████████████████████████████████| 79/79 [00:02<00:00, 26.48it/s]\n",
            "Best Prec@1: 68.610, Many Prec@1: 0.704, Med Prec@1: 0.616, Few Prec@1: 0.000\n",
            "Training(E(48)): BT(0.206, 0.059) CE(0.6598, 0.6654) SCL_v(2.063718, 2.112158) CL(-0.534496, -0.554230 Prec@1(67.318, 60.156): 100%|████████████████████████████████████| 96/96 [00:20<00:00,  4.79it/s]\n",
            "Evaluating(E(48)): BT(2.851, 4.067) CE(1.5583, 1.4463) Prec@1(59.970, 75.000): 100%|██████████████████████████████████| 79/79 [00:04<00:00, 18.72it/s]\n",
            "Best Prec@1: 68.610, Many Prec@1: 0.704, Med Prec@1: 0.616, Few Prec@1: 0.000\n",
            "Training(E(49)): BT(0.208, 0.051) CE(0.6739, 0.7791) SCL_v(2.071560, 2.296057) CL(-0.560726, -0.564263 Prec@1(66.016, 73.438): 100%|████████████████████████████████████| 96/96 [00:20<00:00,  4.78it/s]\n",
            "Evaluating(E(49)): BT(1.908, 2.877) CE(1.9490, 1.7761) Prec@1(63.360, 62.500): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 26.10it/s]\n",
            "Best Prec@1: 68.610, Many Prec@1: 0.704, Med Prec@1: 0.616, Few Prec@1: 0.000\n",
            "Training(E(50)): BT(0.226, 0.049) CE(0.6585, 0.5759) SCL_v(2.044471, 1.988177) CL(-0.570881, -0.568587 Prec@1(67.505, 73.438): 100%|████████████████████████████████████| 96/96 [00:21<00:00,  4.39it/s]\n",
            "Evaluating(E(50)): BT(1.935, 2.895) CE(1.6650, 1.9806) Prec@1(66.300, 50.000): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 25.95it/s]\n",
            "Best Prec@1: 68.610, Many Prec@1: 0.704, Med Prec@1: 0.616, Few Prec@1: 0.000\n",
            "Training(E(51)): BT(0.293, 0.125) CE(0.6626, 0.5639) SCL_v(2.045463, 1.914311) CL(0.518051, 0.518682 Prec@1(67.497, 76.562): 100%|██████████████████████████████████████| 96/96 [00:28<00:00,  3.40it/s]\n",
            "Evaluating(E(51)): BT(1.891, 2.857) CE(1.4990, 1.7014) Prec@1(69.270, 62.500): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 26.29it/s]\n",
            "Best Prec@1: 69.270, Many Prec@1: 0.692, Med Prec@1: 0.698, Few Prec@1: 0.000\n",
            "Training(E(52)): BT(0.225, 0.050) CE(0.6724, 0.8645) SCL_v(2.071158, 2.210605) CL(0.506685, 0.486198 Prec@1(67.147, 65.625): 100%|██████████████████████████████████████| 96/96 [00:21<00:00,  4.40it/s]\n",
            "Evaluating(E(52)): BT(2.065, 3.073) CE(1.3253, 1.6373) Prec@1(67.700, 56.250): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 24.57it/s]\n",
            "Best Prec@1: 69.270, Many Prec@1: 0.692, Med Prec@1: 0.698, Few Prec@1: 0.000\n",
            "Training(E(53)): BT(0.207, 0.054) CE(0.6604, 0.6940) SCL_v(2.041174, 2.203889) CL(0.449282, 0.406734 Prec@1(66.960, 64.062): 100%|██████████████████████████████████████| 96/96 [00:19<00:00,  4.81it/s]\n",
            "Evaluating(E(53)): BT(2.837, 4.259) CE(1.6556, 1.3766) Prec@1(57.800, 62.500): 100%|██████████████████████████████████| 79/79 [00:04<00:00, 17.94it/s]\n",
            "Best Prec@1: 69.270, Many Prec@1: 0.692, Med Prec@1: 0.698, Few Prec@1: 0.000\n",
            "Training(E(54)): BT(0.208, 0.052) CE(0.6637, 0.9576) SCL_v(2.038623, 2.120116) CL(0.321463, 0.207189 Prec@1(67.480, 61.719): 100%|██████████████████████████████████████| 96/96 [00:20<00:00,  4.76it/s]\n",
            "Evaluating(E(54)): BT(1.967, 2.900) CE(2.2087, 2.8010) Prec@1(56.320, 43.750): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 25.93it/s]\n",
            "Best Prec@1: 69.270, Many Prec@1: 0.692, Med Prec@1: 0.698, Few Prec@1: 0.000\n",
            "Training(E(55)): BT(0.227, 0.053) CE(0.6569, 0.6106) SCL_v(2.041689, 2.163629) CL(0.052943, -0.127550 Prec@1(67.839, 73.438): 100%|█████████████████████████████████████| 96/96 [00:21<00:00,  4.38it/s]\n",
            "Evaluating(E(55)): BT(1.957, 2.917) CE(2.1590, 2.0561) Prec@1(59.010, 62.500): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 25.82it/s]\n",
            "Best Prec@1: 69.270, Many Prec@1: 0.692, Med Prec@1: 0.698, Few Prec@1: 0.000\n",
            "Training(E(56)): BT(0.218, 0.053) CE(0.6501, 0.8854) SCL_v(2.051125, 2.131952) CL(-0.264175, -0.382060 Prec@1(67.350, 54.688): 100%|████████████████████████████████████| 96/96 [00:21<00:00,  4.55it/s]\n",
            "Evaluating(E(56)): BT(2.343, 3.319) CE(1.1765, 1.2654) Prec@1(66.570, 68.750): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 22.84it/s]\n",
            "Best Prec@1: 69.270, Many Prec@1: 0.692, Med Prec@1: 0.698, Few Prec@1: 0.000\n",
            "Training(E(57)): BT(0.208, 0.050) CE(0.6491, 0.6101) SCL_v(2.025199, 2.107008) CL(-0.454873, -0.496191 Prec@1(67.261, 71.875): 100%|████████████████████████████████████| 96/96 [00:20<00:00,  4.78it/s]\n",
            "Evaluating(E(57)): BT(2.225, 3.603) CE(1.4940, 1.5221) Prec@1(64.470, 68.750): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 20.68it/s]\n",
            "Best Prec@1: 69.270, Many Prec@1: 0.692, Med Prec@1: 0.698, Few Prec@1: 0.000\n",
            "Training(E(58)): BT(0.216, 0.052) CE(0.6464, 0.7698) SCL_v(2.032790, 2.233279) CL(-0.530087, -0.544295 Prec@1(68.075, 69.531): 100%|████████████████████████████████████| 96/96 [00:20<00:00,  4.60it/s]\n",
            "Evaluating(E(58)): BT(1.953, 2.918) CE(1.6745, 1.5508) Prec@1(66.340, 62.500): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 25.83it/s]\n",
            "Best Prec@1: 69.270, Many Prec@1: 0.692, Med Prec@1: 0.698, Few Prec@1: 0.000\n",
            "Training(E(59)): BT(0.238, 0.049) CE(0.6308, 0.5861) SCL_v(2.010966, 1.980098) CL(-0.557767, -0.563825 Prec@1(69.759, 74.219): 100%|████████████████████████████████████| 96/96 [00:23<00:00,  4.17it/s]\n",
            "Evaluating(E(59)): BT(1.890, 2.840) CE(1.6445, 1.3915) Prec@1(64.190, 56.250): 100%|██████████████████████████████████| 79/79 [00:02<00:00, 26.43it/s]\n",
            "Best Prec@1: 69.270, Many Prec@1: 0.692, Med Prec@1: 0.698, Few Prec@1: 0.000\n",
            "Training(E(60)): BT(0.208, 0.054) CE(0.6594, 0.6005) SCL_v(2.031606, 1.926768) CL(-0.570364, -0.575220 Prec@1(68.172, 67.969): 100%|████████████████████████████████████| 96/96 [00:20<00:00,  4.74it/s]\n",
            "Evaluating(E(60)): BT(2.783, 3.932) CE(1.6032, 1.1698) Prec@1(62.730, 75.000): 100%|██████████████████████████████████| 79/79 [00:04<00:00, 19.31it/s]\n",
            "Best Prec@1: 69.270, Many Prec@1: 0.692, Med Prec@1: 0.698, Few Prec@1: 0.000\n",
            "Training(E(61)): BT(0.292, 0.112) CE(0.6351, 0.6549) SCL_v(2.002416, 1.969006) CL(0.514552, 0.517481 Prec@1(68.929, 64.844): 100%|██████████████████████████████████████| 96/96 [00:28<00:00,  3.41it/s]\n",
            "Evaluating(E(61)): BT(1.962, 2.937) CE(1.3947, 1.1819) Prec@1(70.730, 75.000): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 25.61it/s]\n",
            "Best Prec@1: 70.730, Many Prec@1: 0.724, Med Prec@1: 0.642, Few Prec@1: 0.000\n",
            "Training(E(62)): BT(0.210, 0.065) CE(0.6267, 0.7787) SCL_v(2.005643, 2.365174) CL(0.497636, 0.469921 Prec@1(69.141, 73.438): 100%|██████████████████████████████████████| 96/96 [00:20<00:00,  4.70it/s]\n",
            "Evaluating(E(62)): BT(2.781, 3.908) CE(1.4688, 1.3187) Prec@1(68.280, 75.000): 100%|██████████████████████████████████| 79/79 [00:04<00:00, 19.48it/s]\n",
            "Best Prec@1: 70.730, Many Prec@1: 0.724, Med Prec@1: 0.642, Few Prec@1: 0.000\n",
            "Training(E(63)): BT(0.206, 0.052) CE(0.6385, 0.5558) SCL_v(2.002694, 1.820186) CL(0.435028, 0.386153 Prec@1(69.238, 71.875): 100%|██████████████████████████████████████| 96/96 [00:19<00:00,  4.81it/s]\n",
            "Evaluating(E(63)): BT(2.028, 3.112) CE(1.5037, 1.5746) Prec@1(64.580, 62.500): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 23.93it/s]\n",
            "Best Prec@1: 70.730, Many Prec@1: 0.724, Med Prec@1: 0.642, Few Prec@1: 0.000\n",
            "Training(E(64)): BT(0.220, 0.055) CE(0.6410, 0.6728) SCL_v(1.995744, 2.298845) CL(0.292238, 0.185069 Prec@1(69.539, 67.969): 100%|██████████████████████████████████████| 96/96 [00:21<00:00,  4.51it/s]\n",
            "Evaluating(E(64)): BT(1.910, 2.865) CE(1.1300, 1.0050) Prec@1(71.750, 75.000): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 26.26it/s]\n",
            "Best Prec@1: 71.750, Many Prec@1: 0.701, Med Prec@1: 0.784, Few Prec@1: 0.000\n",
            "Training(E(65)): BT(0.215, 0.065) CE(0.6461, 0.8278) SCL_v(2.020128, 2.315092) CL(0.028775, -0.123636 Prec@1(68.351, 61.719): 100%|█████████████████████████████████████| 96/96 [00:20<00:00,  4.59it/s]\n",
            "Evaluating(E(65)): BT(2.247, 3.195) CE(1.3677, 1.4021) Prec@1(67.850, 56.250): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 23.58it/s]\n",
            "Best Prec@1: 71.750, Many Prec@1: 0.701, Med Prec@1: 0.784, Few Prec@1: 0.000\n",
            "Training(E(66)): BT(0.205, 0.049) CE(0.6312, 0.7194) SCL_v(2.000301, 1.998100) CL(-0.267679, -0.378898 Prec@1(68.555, 64.844): 100%|████████████████████████████████████| 96/96 [00:19<00:00,  4.83it/s]\n",
            "Evaluating(E(66)): BT(1.940, 3.071) CE(1.3657, 1.3707) Prec@1(69.300, 68.750): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 23.98it/s]\n",
            "Best Prec@1: 71.750, Many Prec@1: 0.701, Med Prec@1: 0.784, Few Prec@1: 0.000\n",
            "Training(E(67)): BT(0.218, 0.052) CE(0.6337, 0.5971) SCL_v(1.998640, 1.916898) CL(-0.448189, -0.494270 Prec@1(69.849, 71.094): 100%|████████████████████████████████████| 96/96 [00:21<00:00,  4.55it/s]\n",
            "Evaluating(E(67)): BT(1.915, 2.872) CE(1.6086, 1.6771) Prec@1(66.480, 62.500): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 26.23it/s]\n",
            "Best Prec@1: 71.750, Many Prec@1: 0.701, Med Prec@1: 0.784, Few Prec@1: 0.000\n",
            "Training(E(68)): BT(0.215, 0.061) CE(0.6426, 0.7191) SCL_v(2.012339, 2.032428) CL(-0.526237, -0.543725 Prec@1(68.538, 71.875): 100%|████████████████████████████████████| 96/96 [00:20<00:00,  4.60it/s]\n",
            "Evaluating(E(68)): BT(1.892, 2.842) CE(1.5945, 2.0209) Prec@1(65.210, 56.250): 100%|██████████████████████████████████| 79/79 [00:02<00:00, 26.50it/s]\n",
            "Best Prec@1: 71.750, Many Prec@1: 0.701, Med Prec@1: 0.784, Few Prec@1: 0.000\n",
            "Training(E(69)): BT(0.206, 0.051) CE(0.6184, 0.5773) SCL_v(1.979293, 1.785627) CL(-0.554749, -0.563222 Prec@1(69.995, 71.875): 100%|████████████████████████████████████| 96/96 [00:19<00:00,  4.82it/s]\n",
            "Evaluating(E(69)): BT(2.197, 3.532) CE(1.2740, 1.2467) Prec@1(65.130, 68.750): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 21.03it/s]\n",
            "Best Prec@1: 71.750, Many Prec@1: 0.701, Med Prec@1: 0.784, Few Prec@1: 0.000\n",
            "Training(E(70)): BT(0.214, 0.049) CE(0.6050, 0.5797) SCL_v(1.978723, 1.907474) CL(-0.565849, -0.566595 Prec@1(70.353, 73.438): 100%|████████████████████████████████████| 96/96 [00:20<00:00,  4.64it/s]\n",
            "Evaluating(E(70)): BT(1.886, 2.807) CE(1.2261, 1.3048) Prec@1(69.640, 75.000): 100%|██████████████████████████████████| 79/79 [00:02<00:00, 26.73it/s]\n",
            "Best Prec@1: 71.750, Many Prec@1: 0.701, Med Prec@1: 0.784, Few Prec@1: 0.000\n",
            "Training(E(71)): BT(0.292, 0.122) CE(0.6171, 0.6232) SCL_v(1.998889, 2.121042) CL(0.505548, 0.495671 Prec@1(69.604, 67.188): 100%|██████████████████████████████████████| 96/96 [00:28<00:00,  3.41it/s]\n",
            "Evaluating(E(71)): BT(1.899, 2.881) CE(1.9668, 1.8933) Prec@1(62.060, 62.500): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 25.70it/s]\n",
            "Best Prec@1: 71.750, Many Prec@1: 0.701, Med Prec@1: 0.784, Few Prec@1: 0.000\n",
            "Training(E(72)): BT(0.220, 0.051) CE(0.6197, 0.4718) SCL_v(1.981125, 1.819699) CL(0.471035, 0.443908 Prec@1(69.303, 68.750): 100%|██████████████████████████████████████| 96/96 [00:21<00:00,  4.52it/s]\n",
            "Evaluating(E(72)): BT(1.943, 2.905) CE(1.6285, 1.9515) Prec@1(63.830, 50.000): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 25.89it/s]\n",
            "Best Prec@1: 71.750, Many Prec@1: 0.701, Med Prec@1: 0.784, Few Prec@1: 0.000\n",
            "Training(E(73)): BT(0.211, 0.053) CE(0.6141, 0.7937) SCL_v(1.989068, 2.317069) CL(0.407566, 0.355648 Prec@1(70.207, 62.500): 100%|██████████████████████████████████████| 96/96 [00:20<00:00,  4.67it/s]\n",
            "Evaluating(E(73)): BT(2.470, 3.428) CE(1.0894, 0.8707) Prec@1(71.500, 81.250): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 22.11it/s]\n",
            "Best Prec@1: 71.750, Many Prec@1: 0.701, Med Prec@1: 0.784, Few Prec@1: 0.000\n",
            "Training(E(74)): BT(0.204, 0.052) CE(0.6034, 0.4916) SCL_v(1.978043, 1.836390) CL(0.275866, 0.171156 Prec@1(69.564, 75.000): 100%|██████████████████████████████████████| 96/96 [00:19<00:00,  4.85it/s]\n",
            "Evaluating(E(74)): BT(1.978, 3.067) CE(1.1289, 1.2377) Prec@1(68.310, 68.750): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 23.79it/s]\n",
            "Best Prec@1: 71.750, Many Prec@1: 0.701, Med Prec@1: 0.784, Few Prec@1: 0.000\n",
            "Training(E(75)): BT(0.217, 0.049) CE(0.6052, 0.5394) SCL_v(1.973110, 1.950803) CL(0.040058, -0.090966 Prec@1(70.492, 68.750): 100%|█████████████████████████████████████| 96/96 [00:21<00:00,  4.57it/s]\n",
            "Evaluating(E(75)): BT(1.884, 2.809) CE(1.5990, 1.7600) Prec@1(64.260, 56.250): 100%|██████████████████████████████████| 79/79 [00:02<00:00, 26.68it/s]\n",
            "Best Prec@1: 71.750, Many Prec@1: 0.701, Med Prec@1: 0.784, Few Prec@1: 0.000\n",
            "Training(E(76)): BT(0.222, 0.049) CE(0.6211, 0.6651) SCL_v(1.973581, 2.083155) CL(-0.232005, -0.351379 Prec@1(70.223, 74.219): 100%|████████████████████████████████████| 96/96 [00:21<00:00,  4.47it/s]\n",
            "Evaluating(E(76)): BT(1.870, 2.797) CE(1.3085, 1.3222) Prec@1(73.130, 81.250): 100%|██████████████████████████████████| 79/79 [00:02<00:00, 26.79it/s]\n",
            "Best Prec@1: 73.130, Many Prec@1: 0.743, Med Prec@1: 0.683, Few Prec@1: 0.000\n",
            "Training(E(77)): BT(0.206, 0.050) CE(0.5938, 0.6279) SCL_v(1.945807, 1.892088) CL(-0.414363, -0.463074 Prec@1(70.361, 63.281): 100%|████████████████████████████████████| 96/96 [00:19<00:00,  4.81it/s]\n",
            "Evaluating(E(77)): BT(2.386, 3.786) CE(1.5024, 1.4575) Prec@1(69.200, 68.750): 100%|██████████████████████████████████| 79/79 [00:04<00:00, 19.53it/s]\n",
            "Best Prec@1: 73.130, Many Prec@1: 0.743, Med Prec@1: 0.683, Few Prec@1: 0.000\n",
            "Training(E(78)): BT(0.208, 0.050) CE(0.5756, 0.5612) SCL_v(1.937821, 1.783103) CL(-0.497632, -0.516300 Prec@1(71.924, 76.562): 100%|████████████████████████████████████| 96/96 [00:20<00:00,  4.78it/s]\n",
            "Evaluating(E(78)): BT(1.920, 2.841) CE(1.7308, 1.4116) Prec@1(66.970, 62.500): 100%|██████████████████████████████████| 79/79 [00:02<00:00, 26.44it/s]\n",
            "Best Prec@1: 73.130, Many Prec@1: 0.743, Med Prec@1: 0.683, Few Prec@1: 0.000\n",
            "Training(E(79)): BT(0.225, 0.050) CE(0.6064, 0.6462) SCL_v(1.971484, 1.950045) CL(-0.530188, -0.542273 Prec@1(70.508, 68.750): 100%|████████████████████████████████████| 96/96 [00:21<00:00,  4.42it/s]\n",
            "Evaluating(E(79)): BT(1.898, 2.846) CE(1.5323, 1.6288) Prec@1(70.830, 68.750): 100%|██████████████████████████████████| 79/79 [00:02<00:00, 26.44it/s]\n",
            "Best Prec@1: 73.130, Many Prec@1: 0.743, Med Prec@1: 0.683, Few Prec@1: 0.000\n",
            "Training(E(80)): BT(0.205, 0.052) CE(0.6003, 0.4274) SCL_v(1.949035, 1.946114) CL(-0.545959, -0.544248 Prec@1(70.874, 75.781): 100%|████████████████████████████████████| 96/96 [00:19<00:00,  4.83it/s]\n",
            "Evaluating(E(80)): BT(2.400, 3.770) CE(1.3300, 1.5856) Prec@1(66.710, 68.750): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 19.84it/s]\n",
            "Best Prec@1: 73.130, Many Prec@1: 0.743, Med Prec@1: 0.683, Few Prec@1: 0.000\n",
            "Training(E(81)): BT(0.282, 0.150) CE(0.6033, 0.5121) SCL_v(1.975980, 1.668498) CL(0.502844, 0.495292 Prec@1(69.816, 73.438): 100%|██████████████████████████████████████| 96/96 [00:27<00:00,  3.51it/s]\n",
            "Evaluating(E(81)): BT(2.379, 3.355) CE(1.2137, 1.3354) Prec@1(71.460, 75.000): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 22.58it/s]\n",
            "Best Prec@1: 73.130, Many Prec@1: 0.743, Med Prec@1: 0.683, Few Prec@1: 0.000\n",
            "Training(E(82)): BT(0.205, 0.049) CE(0.5950, 0.6786) SCL_v(1.929570, 1.989466) CL(0.491777, 0.479066 Prec@1(70.850, 64.844): 100%|██████████████████████████████████████| 96/96 [00:19<00:00,  4.83it/s]\n",
            "Evaluating(E(82)): BT(1.974, 3.115) CE(1.2451, 1.3715) Prec@1(71.290, 75.000): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 23.54it/s]\n",
            "Best Prec@1: 73.130, Many Prec@1: 0.743, Med Prec@1: 0.683, Few Prec@1: 0.000\n",
            "Training(E(83)): BT(0.215, 0.051) CE(0.5867, 0.4940) SCL_v(1.952294, 1.872300) CL(0.453897, 0.418816 Prec@1(71.257, 74.219): 100%|██████████████████████████████████████| 96/96 [00:20<00:00,  4.63it/s]\n",
            "Evaluating(E(83)): BT(1.897, 2.842) CE(1.4175, 1.4207) Prec@1(67.470, 68.750): 100%|██████████████████████████████████| 79/79 [00:02<00:00, 26.42it/s]\n",
            "Best Prec@1: 73.130, Many Prec@1: 0.743, Med Prec@1: 0.683, Few Prec@1: 0.000\n",
            "Training(E(84)): BT(0.219, 0.049) CE(0.5941, 0.5019) SCL_v(1.939669, 1.808092) CL(0.370496, 0.284407 Prec@1(70.605, 70.312): 100%|██████████████████████████████████████| 96/96 [00:21<00:00,  4.54it/s]\n",
            "Evaluating(E(84)): BT(1.905, 2.838) CE(1.7065, 1.5621) Prec@1(65.290, 75.000): 100%|██████████████████████████████████| 79/79 [00:02<00:00, 26.54it/s]\n",
            "Best Prec@1: 73.130, Many Prec@1: 0.743, Med Prec@1: 0.683, Few Prec@1: 0.000\n",
            "Training(E(85)): BT(0.205, 0.050) CE(0.5845, 0.5902) SCL_v(1.940251, 1.919257) CL(0.199107, 0.084579 Prec@1(71.273, 60.156): 100%|██████████████████████████████████████| 96/96 [00:19<00:00,  4.85it/s]\n",
            "Evaluating(E(85)): BT(2.278, 3.628) CE(1.0245, 0.6797) Prec@1(65.880, 75.000): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 20.27it/s]\n",
            "Best Prec@1: 73.130, Many Prec@1: 0.743, Med Prec@1: 0.683, Few Prec@1: 0.000\n",
            "Training(E(86)): BT(0.206, 0.052) CE(0.5769, 0.6356) SCL_v(1.943643, 2.015446) CL(-0.056322, -0.189990 Prec@1(72.184, 64.844): 100%|████████████████████████████████████| 96/96 [00:19<00:00,  4.83it/s]\n",
            "Evaluating(E(86)): BT(1.856, 2.773) CE(1.1716, 0.8696) Prec@1(72.830, 75.000): 100%|██████████████████████████████████| 79/79 [00:02<00:00, 26.86it/s]\n",
            "Best Prec@1: 73.130, Many Prec@1: 0.743, Med Prec@1: 0.683, Few Prec@1: 0.000\n",
            "Training(E(87)): BT(0.213, 0.061) CE(0.5771, 0.4515) SCL_v(1.930611, 1.930515) CL(-0.302686, -0.397849 Prec@1(71.663, 72.656): 100%|████████████████████████████████████| 96/96 [00:20<00:00,  4.65it/s]\n",
            "Evaluating(E(87)): BT(1.895, 2.830) CE(0.9961, 0.8383) Prec@1(69.780, 75.000): 100%|██████████████████████████████████| 79/79 [00:02<00:00, 26.50it/s]\n",
            "Best Prec@1: 73.130, Many Prec@1: 0.743, Med Prec@1: 0.683, Few Prec@1: 0.000\n",
            "Training(E(88)): BT(0.201, 0.050) CE(0.5774, 0.6223) SCL_v(1.919395, 2.049109) CL(-0.448221, -0.491876 Prec@1(71.851, 71.094): 100%|████████████████████████████████████| 96/96 [00:19<00:00,  4.93it/s]\n",
            "Evaluating(E(88)): BT(1.954, 3.117) CE(1.3653, 1.3531) Prec@1(69.620, 56.250): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 23.38it/s]\n",
            "Best Prec@1: 73.130, Many Prec@1: 0.743, Med Prec@1: 0.683, Few Prec@1: 0.000\n",
            "Training(E(89)): BT(0.210, 0.049) CE(0.5741, 0.5641) SCL_v(1.917192, 2.108560) CL(-0.512237, -0.532761 Prec@1(72.795, 71.094): 100%|████████████████████████████████████| 96/96 [00:20<00:00,  4.71it/s]\n",
            "Evaluating(E(89)): BT(1.800, 2.704) CE(1.7046, 1.4722) Prec@1(66.260, 68.750): 100%|██████████████████████████████████| 79/79 [00:02<00:00, 27.71it/s]\n",
            "Best Prec@1: 73.130, Many Prec@1: 0.743, Med Prec@1: 0.683, Few Prec@1: 0.000\n",
            "Training(E(90)): BT(0.206, 0.054) CE(0.5695, 0.5316) SCL_v(1.921145, 1.656218) CL(-0.541328, -0.556657 Prec@1(71.639, 68.750): 100%|████████████████████████████████████| 96/96 [00:20<00:00,  4.79it/s]\n",
            "Evaluating(E(90)): BT(2.324, 3.282) CE(1.1632, 1.3258) Prec@1(70.750, 62.500): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 23.03it/s]\n",
            "Best Prec@1: 73.130, Many Prec@1: 0.743, Med Prec@1: 0.683, Few Prec@1: 0.000\n",
            "Training(E(91)): BT(0.285, 0.118) CE(0.5719, 0.5518) SCL_v(1.927205, 1.853761) CL(0.486828, 0.463011 Prec@1(72.786, 76.562): 100%|██████████████████████████████████████| 96/96 [00:27<00:00,  3.49it/s]\n",
            "Evaluating(E(91)): BT(1.836, 2.760) CE(1.1241, 1.1580) Prec@1(70.930, 81.250): 100%|██████████████████████████████████| 79/79 [00:02<00:00, 27.24it/s]\n",
            "Best Prec@1: 73.130, Many Prec@1: 0.743, Med Prec@1: 0.683, Few Prec@1: 0.000\n",
            "Training(E(92)): BT(0.200, 0.050) CE(0.5660, 0.5834) SCL_v(1.910650, 1.976892) CL(0.457737, 0.437673 Prec@1(71.997, 74.219): 100%|██████████████████████████████████████| 96/96 [00:19<00:00,  4.95it/s]\n",
            "Evaluating(E(92)): BT(2.563, 3.921) CE(1.3289, 1.4960) Prec@1(72.180, 68.750): 100%|██████████████████████████████████| 79/79 [00:04<00:00, 19.19it/s]\n",
            "Best Prec@1: 73.130, Many Prec@1: 0.743, Med Prec@1: 0.683, Few Prec@1: 0.000\n",
            "Training(E(93)): BT(0.201, 0.051) CE(0.5521, 0.5829) SCL_v(1.882539, 1.829473) CL(0.405442, 0.365333 Prec@1(73.381, 71.094): 100%|██████████████████████████████████████| 96/96 [00:19<00:00,  4.93it/s]\n",
            "Evaluating(E(93)): BT(1.849, 2.762) CE(1.1582, 0.8807) Prec@1(72.590, 75.000): 100%|██████████████████████████████████| 79/79 [00:02<00:00, 27.21it/s]\n",
            "Best Prec@1: 73.130, Many Prec@1: 0.743, Med Prec@1: 0.683, Few Prec@1: 0.000\n",
            "Training(E(94)): BT(0.216, 0.050) CE(0.5758, 0.6651) SCL_v(1.936220, 1.915040) CL(0.313539, 0.250992 Prec@1(72.119, 62.500): 100%|██████████████████████████████████████| 96/96 [00:20<00:00,  4.60it/s]\n",
            "Evaluating(E(94)): BT(1.833, 2.742) CE(1.7879, 1.7950) Prec@1(66.380, 62.500): 100%|██████████████████████████████████| 79/79 [00:02<00:00, 27.39it/s]\n",
            "Best Prec@1: 73.130, Many Prec@1: 0.743, Med Prec@1: 0.683, Few Prec@1: 0.000\n",
            "Training(E(95)): BT(0.204, 0.049) CE(0.5587, 0.5077) SCL_v(1.911156, 1.709665) CL(0.141178, 0.028784 Prec@1(73.210, 68.750): 100%|██████████████████████████████████████| 96/96 [00:19<00:00,  4.87it/s]\n",
            "Evaluating(E(95)): BT(1.992, 3.154) CE(1.2099, 1.4987) Prec@1(70.470, 68.750): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 23.37it/s]\n",
            "Best Prec@1: 73.130, Many Prec@1: 0.743, Med Prec@1: 0.683, Few Prec@1: 0.000\n",
            "Training(E(96)): BT(0.213, 0.054) CE(0.5570, 0.5296) SCL_v(1.894671, 2.015728) CL(-0.084501, -0.197054 Prec@1(72.909, 66.406): 100%|████████████████████████████████████| 96/96 [00:20<00:00,  4.67it/s]\n",
            "Evaluating(E(96)): BT(1.837, 2.749) CE(1.4250, 1.6721) Prec@1(68.850, 62.500): 100%|██████████████████████████████████| 79/79 [00:02<00:00, 27.26it/s]\n",
            "Best Prec@1: 73.130, Many Prec@1: 0.743, Med Prec@1: 0.683, Few Prec@1: 0.000\n",
            "Training(E(97)): BT(0.209, 0.061) CE(0.5594, 0.5984) SCL_v(1.905745, 1.925349) CL(-0.292945, -0.373275 Prec@1(72.469, 71.094): 100%|████████████████████████████████████| 96/96 [00:20<00:00,  4.74it/s]\n",
            "Evaluating(E(97)): BT(2.240, 3.274) CE(1.1725, 1.2505) Prec@1(70.860, 62.500): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 23.12it/s]\n",
            "Best Prec@1: 73.130, Many Prec@1: 0.743, Med Prec@1: 0.683, Few Prec@1: 0.000\n",
            "Training(E(98)): BT(0.200, 0.050) CE(0.5510, 0.6303) SCL_v(1.893008, 2.195542) CL(-0.423095, -0.463555 Prec@1(73.934, 76.562): 100%|████████████████████████████████████| 96/96 [00:19<00:00,  4.96it/s]\n",
            "Evaluating(E(98)): BT(1.970, 3.117) CE(1.4210, 1.7154) Prec@1(73.500, 75.000): 100%|██████████████████████████████████| 79/79 [00:03<00:00, 23.29it/s]\n",
            "Best Prec@1: 73.500, Many Prec@1: 0.738, Med Prec@1: 0.725, Few Prec@1: 0.000\n",
            "Training(E(99)): BT(0.211, 0.050) CE(0.5464, 0.6161) SCL_v(1.868267, 1.891369) CL(-0.492305, -0.508350 Prec@1(73.299, 63.281): 100%|████████████████████████████████████| 96/96 [00:20<00:00,  4.70it/s]\n",
            "Evaluating(E(99)): BT(1.865, 2.788) CE(1.0301, 1.3494) Prec@1(75.270, 62.500): 100%|██████████████████████████████████| 79/79 [00:02<00:00, 26.97it/s]\n",
            "Best Prec@1: 75.270, Many Prec@1: 0.743, Med Prec@1: 0.792, Few Prec@1: 0.000\n",
            "Training(E(100)): BT(0.210, 0.054) CE(0.5449, 0.5387) SCL_v(1.883890, 1.774034) CL(-0.520938, -0.531515 Prec@1(74.080, 71.875): 100%|███████████████████████████████████| 96/96 [00:20<00:00,  4.70it/s]\n",
            "Evaluating(E(100)): BT(2.167, 3.115) CE(1.3545, 1.8709) Prec@1(72.330, 56.250): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 24.23it/s]\n",
            "Best Prec@1: 75.270, Many Prec@1: 0.743, Med Prec@1: 0.792, Few Prec@1: 0.000\n",
            "Training(E(101)): BT(0.287, 0.117) CE(0.5385, 0.5167) SCL_v(1.880852, 1.954236) CL(0.480130, 0.466059 Prec@1(73.698, 70.312): 100%|█████████████████████████████████████| 96/96 [00:27<00:00,  3.47it/s]\n",
            "Evaluating(E(101)): BT(1.845, 2.771) CE(1.2056, 0.8818) Prec@1(73.330, 75.000): 100%|█████████████████████████████████| 79/79 [00:02<00:00, 27.08it/s]\n",
            "Best Prec@1: 75.270, Many Prec@1: 0.743, Med Prec@1: 0.792, Few Prec@1: 0.000\n",
            "Training(E(102)): BT(0.204, 0.059) CE(0.5497, 0.4584) SCL_v(1.860328, 1.745093) CL(0.458718, 0.453534 Prec@1(73.910, 76.562): 100%|█████████████████████████████████████| 96/96 [00:19<00:00,  4.83it/s]\n",
            "Evaluating(E(102)): BT(2.928, 4.142) CE(1.2435, 0.9764) Prec@1(73.560, 81.250): 100%|█████████████████████████████████| 79/79 [00:04<00:00, 18.40it/s]\n",
            "Best Prec@1: 75.270, Many Prec@1: 0.743, Med Prec@1: 0.792, Few Prec@1: 0.000\n",
            "Training(E(103)): BT(0.202, 0.050) CE(0.5342, 0.4586) SCL_v(1.871252, 1.866902) CL(0.423220, 0.389391 Prec@1(73.828, 75.000): 100%|█████████████████████████████████████| 96/96 [00:19<00:00,  4.91it/s]\n",
            "Evaluating(E(103)): BT(1.869, 2.790) CE(1.5824, 1.5237) Prec@1(64.510, 50.000): 100%|█████████████████████████████████| 79/79 [00:02<00:00, 26.93it/s]\n",
            "Best Prec@1: 75.270, Many Prec@1: 0.743, Med Prec@1: 0.792, Few Prec@1: 0.000\n",
            "Training(E(104)): BT(0.219, 0.051) CE(0.5382, 0.5288) SCL_v(1.870778, 2.125149) CL(0.350265, 0.310365 Prec@1(74.268, 80.469): 100%|█████████████████████████████████████| 96/96 [00:21<00:00,  4.53it/s]\n",
            "Evaluating(E(104)): BT(1.892, 2.831) CE(1.4308, 1.8107) Prec@1(71.310, 43.750): 100%|█████████████████████████████████| 79/79 [00:02<00:00, 26.51it/s]\n",
            "Best Prec@1: 75.270, Many Prec@1: 0.743, Med Prec@1: 0.792, Few Prec@1: 0.000\n",
            "Training(E(105)): BT(0.203, 0.054) CE(0.5340, 0.6714) SCL_v(1.865819, 1.940816) CL(0.221220, 0.128017 Prec@1(74.284, 66.406): 100%|█████████████████████████████████████| 96/96 [00:19<00:00,  4.88it/s]\n",
            "Evaluating(E(105)): BT(2.856, 4.049) CE(1.0741, 1.1106) Prec@1(74.980, 68.750): 100%|█████████████████████████████████| 79/79 [00:04<00:00, 18.72it/s]\n",
            "Best Prec@1: 75.270, Many Prec@1: 0.743, Med Prec@1: 0.792, Few Prec@1: 0.000\n",
            "Training(E(106)): BT(0.204, 0.050) CE(0.5288, 0.4510) SCL_v(1.861491, 1.757140) CL(0.020842, -0.090507 Prec@1(74.569, 75.781): 100%|████████████████████████████████████| 96/96 [00:19<00:00,  4.87it/s]\n",
            "Evaluating(E(106)): BT(1.882, 2.798) CE(1.7279, 1.7321) Prec@1(69.230, 75.000): 100%|█████████████████████████████████| 79/79 [00:02<00:00, 26.85it/s]\n",
            "Best Prec@1: 75.270, Many Prec@1: 0.743, Med Prec@1: 0.792, Few Prec@1: 0.000\n",
            "Training(E(107)): BT(0.217, 0.050) CE(0.5259, 0.4390) SCL_v(1.862982, 1.895776) CL(-0.192529, -0.294994 Prec@1(74.495, 81.250): 100%|███████████████████████████████████| 96/96 [00:20<00:00,  4.57it/s]\n",
            "Evaluating(E(107)): BT(1.845, 2.759) CE(1.1357, 1.3152) Prec@1(74.280, 68.750): 100%|█████████████████████████████████| 79/79 [00:02<00:00, 27.23it/s]\n",
            "Best Prec@1: 75.270, Many Prec@1: 0.743, Med Prec@1: 0.792, Few Prec@1: 0.000\n",
            "Training(E(108)): BT(0.200, 0.051) CE(0.5200, 0.4353) SCL_v(1.860956, 1.778281) CL(-0.357165, -0.415596 Prec@1(74.740, 80.469): 100%|███████████████████████████████████| 96/96 [00:19<00:00,  4.94it/s]\n",
            "Evaluating(E(108)): BT(2.906, 4.156) CE(1.0850, 0.9714) Prec@1(74.460, 75.000): 100%|█████████████████████████████████| 79/79 [00:04<00:00, 18.40it/s]\n",
            "Best Prec@1: 75.270, Many Prec@1: 0.743, Med Prec@1: 0.792, Few Prec@1: 0.000\n",
            "Training(E(109)): BT(0.202, 0.050) CE(0.5364, 0.5814) SCL_v(1.865810, 1.915979) CL(-0.446849, -0.474094 Prec@1(73.617, 67.969): 100%|███████████████████████████████████| 96/96 [00:19<00:00,  4.90it/s]\n",
            "Evaluating(E(109)): BT(1.880, 2.804) CE(1.3632, 1.3700) Prec@1(72.690, 68.750): 100%|█████████████████████████████████| 79/79 [00:02<00:00, 26.83it/s]\n",
            "Best Prec@1: 75.270, Many Prec@1: 0.743, Med Prec@1: 0.792, Few Prec@1: 0.000\n",
            "Training(E(110)): BT(0.223, 0.054) CE(0.5166, 0.3887) SCL_v(1.832541, 1.656414) CL(-0.494761, -0.518213 Prec@1(75.244, 77.344): 100%|███████████████████████████████████| 96/96 [00:21<00:00,  4.46it/s]\n",
            "Evaluating(E(110)): BT(1.850, 2.747) CE(1.3957, 1.6100) Prec@1(72.460, 62.500): 100%|█████████████████████████████████| 79/79 [00:02<00:00, 27.22it/s]\n",
            "Best Prec@1: 75.270, Many Prec@1: 0.743, Med Prec@1: 0.792, Few Prec@1: 0.000\n",
            "Training(E(111)): BT(0.288, 0.128) CE(0.5099, 0.5334) SCL_v(1.826618, 1.892692) CL(0.476649, 0.475255 Prec@1(75.684, 75.781): 100%|█████████████████████████████████████| 96/96 [00:27<00:00,  3.46it/s]\n",
            "Evaluating(E(111)): BT(1.870, 2.788) CE(0.9872, 1.7817) Prec@1(75.240, 62.500): 100%|█████████████████████████████████| 79/79 [00:02<00:00, 26.86it/s]\n",
            "Best Prec@1: 75.270, Many Prec@1: 0.743, Med Prec@1: 0.792, Few Prec@1: 0.000\n",
            "Training(E(112)): BT(0.206, 0.053) CE(0.5143, 0.3097) SCL_v(1.845972, 1.746985) CL(0.464364, 0.444954 Prec@1(74.772, 82.812): 100%|█████████████████████████████████████| 96/96 [00:20<00:00,  4.80it/s]\n",
            "Evaluating(E(112)): BT(2.478, 3.512) CE(1.2539, 1.3471) Prec@1(74.200, 68.750): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 21.53it/s]\n",
            "Best Prec@1: 75.270, Many Prec@1: 0.743, Med Prec@1: 0.792, Few Prec@1: 0.000\n",
            "Training(E(113)): BT(0.200, 0.049) CE(0.4995, 0.5469) SCL_v(1.837529, 1.782232) CL(0.432791, 0.404956 Prec@1(75.529, 78.125): 100%|█████████████████████████████████████| 96/96 [00:19<00:00,  4.95it/s]\n",
            "Evaluating(E(113)): BT(1.905, 2.889) CE(0.9891, 1.3669) Prec@1(75.770, 62.500): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 25.49it/s]\n",
            "Best Prec@1: 75.770, Many Prec@1: 0.747, Med Prec@1: 0.801, Few Prec@1: 0.000\n",
            "Training(E(114)): BT(0.215, 0.050) CE(0.5307, 0.5102) SCL_v(1.824838, 1.835410) CL(0.375449, 0.338087 Prec@1(74.788, 81.250): 100%|█████████████████████████████████████| 96/96 [00:20<00:00,  4.62it/s]\n",
            "Evaluating(E(114)): BT(1.864, 2.783) CE(1.2801, 1.3429) Prec@1(72.190, 75.000): 100%|█████████████████████████████████| 79/79 [00:02<00:00, 26.95it/s]\n",
            "Best Prec@1: 75.770, Many Prec@1: 0.747, Med Prec@1: 0.801, Few Prec@1: 0.000\n",
            "Training(E(115)): BT(0.205, 0.058) CE(0.4921, 0.6271) SCL_v(1.806771, 2.047129) CL(0.272034, 0.215281 Prec@1(76.489, 78.125): 100%|█████████████████████████████████████| 96/96 [00:19<00:00,  4.83it/s]\n",
            "Evaluating(E(115)): BT(2.392, 3.305) CE(1.0726, 1.2414) Prec@1(76.710, 68.750): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 22.88it/s]\n",
            "Best Prec@1: 76.710, Many Prec@1: 0.752, Med Prec@1: 0.828, Few Prec@1: 0.000\n",
            "Training(E(116)): BT(0.198, 0.048) CE(0.4948, 0.4240) SCL_v(1.821073, 1.696900) CL(0.108692, 0.009235 Prec@1(75.236, 75.781): 100%|█████████████████████████████████████| 96/96 [00:19<00:00,  5.01it/s]\n",
            "Evaluating(E(116)): BT(1.937, 2.936) CE(1.1267, 0.9739) Prec@1(74.840, 68.750): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 25.25it/s]\n",
            "Best Prec@1: 76.710, Many Prec@1: 0.752, Med Prec@1: 0.828, Few Prec@1: 0.000\n",
            "Training(E(117)): BT(0.211, 0.048) CE(0.4923, 0.4002) SCL_v(1.818126, 1.652245) CL(-0.086485, -0.195845 Prec@1(76.782, 78.906): 100%|███████████████████████████████████| 96/96 [00:20<00:00,  4.71it/s]\n",
            "Evaluating(E(117)): BT(1.808, 2.712) CE(1.2251, 1.4099) Prec@1(73.850, 68.750): 100%|█████████████████████████████████| 79/79 [00:02<00:00, 27.58it/s]\n",
            "Best Prec@1: 76.710, Many Prec@1: 0.752, Med Prec@1: 0.828, Few Prec@1: 0.000\n",
            "Training(E(118)): BT(0.202, 0.058) CE(0.5009, 0.5343) SCL_v(1.821595, 2.041428) CL(-0.269595, -0.352872 Prec@1(76.115, 75.781): 100%|███████████████████████████████████| 96/96 [00:19<00:00,  4.89it/s]\n",
            "Evaluating(E(118)): BT(2.690, 3.759) CE(0.9929, 1.1928) Prec@1(77.100, 81.250): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 20.16it/s]\n",
            "Best Prec@1: 77.100, Many Prec@1: 0.767, Med Prec@1: 0.786, Few Prec@1: 0.000\n",
            "Training(E(119)): BT(0.202, 0.051) CE(0.4812, 0.2834) SCL_v(1.793644, 1.613315) CL(-0.397540, -0.433924 Prec@1(75.863, 81.250): 100%|███████████████████████████████████| 96/96 [00:19<00:00,  4.92it/s]\n",
            "Evaluating(E(119)): BT(1.845, 2.769) CE(0.8302, 0.8278) Prec@1(76.180, 75.000): 100%|█████████████████████████████████| 79/79 [00:02<00:00, 27.03it/s]\n",
            "Best Prec@1: 77.100, Many Prec@1: 0.767, Med Prec@1: 0.786, Few Prec@1: 0.000\n",
            "Training(E(120)): BT(0.213, 0.050) CE(0.4906, 0.4723) SCL_v(1.801725, 1.671439) CL(-0.465728, -0.488259 Prec@1(76.278, 73.438): 100%|███████████████████████████████████| 96/96 [00:20<00:00,  4.66it/s]\n",
            "Evaluating(E(120)): BT(1.983, 2.902) CE(0.9615, 1.3336) Prec@1(76.350, 62.500): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 25.96it/s]\n",
            "Best Prec@1: 77.100, Many Prec@1: 0.767, Med Prec@1: 0.786, Few Prec@1: 0.000\n",
            "Training(E(121)): BT(0.282, 0.122) CE(0.4818, 0.5240) SCL_v(1.794592, 1.876915) CL(0.460565, 0.466043 Prec@1(76.351, 85.938): 100%|█████████████████████████████████████| 96/96 [00:27<00:00,  3.52it/s]\n",
            "Evaluating(E(121)): BT(1.972, 2.902) CE(1.1016, 1.4081) Prec@1(76.410, 62.500): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 25.78it/s]\n",
            "Best Prec@1: 77.100, Many Prec@1: 0.767, Med Prec@1: 0.786, Few Prec@1: 0.000\n",
            "Training(E(122)): BT(0.219, 0.057) CE(0.4853, 0.3444) SCL_v(1.788948, 1.590540) CL(0.452775, 0.443215 Prec@1(76.538, 80.469): 100%|█████████████████████████████████████| 96/96 [00:21<00:00,  4.52it/s]\n",
            "Evaluating(E(122)): BT(1.955, 2.900) CE(1.0168, 1.0552) Prec@1(76.360, 75.000): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 25.96it/s]\n",
            "Best Prec@1: 77.100, Many Prec@1: 0.767, Med Prec@1: 0.786, Few Prec@1: 0.000\n",
            "Training(E(123)): BT(0.204, 0.051) CE(0.4639, 0.4443) SCL_v(1.759425, 1.754362) CL(0.427774, 0.409630 Prec@1(77.694, 74.219): 100%|█████████████████████████████████████| 96/96 [00:19<00:00,  4.86it/s]\n",
            "Evaluating(E(123)): BT(2.369, 3.762) CE(1.1395, 1.3895) Prec@1(74.000, 75.000): 100%|█████████████████████████████████| 79/79 [00:04<00:00, 19.55it/s]\n",
            "Best Prec@1: 77.100, Many Prec@1: 0.767, Med Prec@1: 0.786, Few Prec@1: 0.000\n",
            "Training(E(124)): BT(0.208, 0.049) CE(0.4757, 0.3776) SCL_v(1.786720, 1.824265) CL(0.388861, 0.362148 Prec@1(77.222, 84.375): 100%|█████████████████████████████████████| 96/96 [00:20<00:00,  4.78it/s]\n",
            "Evaluating(E(124)): BT(1.882, 2.825) CE(1.1259, 1.5313) Prec@1(75.640, 62.500): 100%|█████████████████████████████████| 79/79 [00:02<00:00, 26.60it/s]\n",
            "Best Prec@1: 77.100, Many Prec@1: 0.767, Med Prec@1: 0.786, Few Prec@1: 0.000\n",
            "Training(E(125)): BT(0.215, 0.059) CE(0.4671, 0.4269) SCL_v(1.766229, 1.780865) CL(0.320385, 0.275355 Prec@1(77.271, 81.250): 100%|█████████████████████████████████████| 96/96 [00:20<00:00,  4.60it/s]\n",
            "Evaluating(E(125)): BT(1.826, 2.739) CE(1.1861, 0.9714) Prec@1(76.420, 93.750): 100%|█████████████████████████████████| 79/79 [00:02<00:00, 27.25it/s]\n",
            "Best Prec@1: 77.100, Many Prec@1: 0.767, Med Prec@1: 0.786, Few Prec@1: 0.000\n",
            "Training(E(126)): BT(0.206, 0.052) CE(0.4763, 0.4180) SCL_v(1.772529, 1.638187) CL(0.215247, 0.141833 Prec@1(76.937, 78.906): 100%|█████████████████████████████████████| 96/96 [00:19<00:00,  4.81it/s]\n",
            "Evaluating(E(126)): BT(2.270, 3.636) CE(1.0286, 1.1876) Prec@1(78.620, 75.000): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 20.34it/s]\n",
            "Best Prec@1: 78.620, Many Prec@1: 0.778, Med Prec@1: 0.821, Few Prec@1: 0.000\n",
            "Training(E(127)): BT(0.213, 0.050) CE(0.4681, 0.4905) SCL_v(1.769351, 1.706770) CL(0.065965, -0.020742 Prec@1(78.011, 78.125): 100%|████████████████████████████████████| 96/96 [00:20<00:00,  4.67it/s]\n",
            "Evaluating(E(127)): BT(1.879, 2.819) CE(1.1009, 1.1058) Prec@1(76.120, 75.000): 100%|█████████████████████████████████| 79/79 [00:02<00:00, 26.57it/s]\n",
            "Best Prec@1: 78.620, Many Prec@1: 0.778, Med Prec@1: 0.821, Few Prec@1: 0.000\n",
            "Training(E(128)): BT(0.235, 0.050) CE(0.4457, 0.4667) SCL_v(1.745041, 1.983879) CL(-0.100973, -0.174836 Prec@1(78.092, 76.562): 100%|███████████████████████████████████| 96/96 [00:22<00:00,  4.22it/s]\n",
            "Evaluating(E(128)): BT(1.885, 2.813) CE(0.9444, 0.7895) Prec@1(77.600, 81.250): 100%|█████████████████████████████████| 79/79 [00:02<00:00, 26.68it/s]\n",
            "Best Prec@1: 78.620, Many Prec@1: 0.778, Med Prec@1: 0.821, Few Prec@1: 0.000\n",
            "Training(E(129)): BT(0.205, 0.053) CE(0.4466, 0.6249) SCL_v(1.739314, 1.918917) CL(-0.246942, -0.307443 Prec@1(78.564, 74.219): 100%|███████████████████████████████████| 96/96 [00:19<00:00,  4.81it/s]\n",
            "Evaluating(E(129)): BT(2.620, 3.694) CE(1.1496, 1.3379) Prec@1(74.830, 62.500): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 20.56it/s]\n",
            "Best Prec@1: 78.620, Many Prec@1: 0.778, Med Prec@1: 0.821, Few Prec@1: 0.000\n",
            "Training(E(130)): BT(0.201, 0.052) CE(0.4529, 0.4510) SCL_v(1.749410, 1.739186) CL(-0.358457, -0.394822 Prec@1(77.873, 77.344): 100%|███████████████████████████████████| 96/96 [00:19<00:00,  4.93it/s]\n",
            "Evaluating(E(130)): BT(1.991, 2.919) CE(1.2132, 1.2641) Prec@1(75.380, 75.000): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 25.62it/s]\n",
            "Best Prec@1: 78.620, Many Prec@1: 0.778, Med Prec@1: 0.821, Few Prec@1: 0.000\n",
            "Training(E(131)): BT(0.290, 0.117) CE(0.4533, 0.3538) SCL_v(1.737988, 1.628577) CL(0.453662, 0.461215 Prec@1(78.206, 78.906): 100%|█████████████████████████████████████| 96/96 [00:27<00:00,  3.43it/s]\n",
            "Evaluating(E(131)): BT(2.462, 3.808) CE(1.2840, 1.4324) Prec@1(73.390, 62.500): 100%|█████████████████████████████████| 79/79 [00:04<00:00, 19.58it/s]\n",
            "Best Prec@1: 78.620, Many Prec@1: 0.778, Med Prec@1: 0.821, Few Prec@1: 0.000\n",
            "Training(E(132)): BT(0.206, 0.051) CE(0.4468, 0.3263) SCL_v(1.742902, 1.581938) CL(0.442904, 0.433023 Prec@1(78.158, 81.250): 100%|█████████████████████████████████████| 96/96 [00:19<00:00,  4.81it/s]\n",
            "Evaluating(E(132)): BT(1.875, 2.798) CE(0.9539, 0.8844) Prec@1(77.790, 75.000): 100%|█████████████████████████████████| 79/79 [00:02<00:00, 26.85it/s]\n",
            "Best Prec@1: 78.620, Many Prec@1: 0.778, Med Prec@1: 0.821, Few Prec@1: 0.000\n",
            "Training(E(133)): BT(0.220, 0.053) CE(0.4397, 0.4230) SCL_v(1.716094, 1.582399) CL(0.424019, 0.410303 Prec@1(79.028, 75.781): 100%|█████████████████████████████████████| 96/96 [00:21<00:00,  4.51it/s]\n",
            "Evaluating(E(133)): BT(1.869, 2.788) CE(0.9216, 1.3368) Prec@1(77.240, 75.000): 100%|█████████████████████████████████| 79/79 [00:02<00:00, 26.92it/s]\n",
            "Best Prec@1: 78.620, Many Prec@1: 0.778, Med Prec@1: 0.821, Few Prec@1: 0.000\n",
            "Training(E(134)): BT(0.205, 0.053) CE(0.4379, 0.3533) SCL_v(1.724067, 1.625427) CL(0.393395, 0.364540 Prec@1(79.102, 78.125): 100%|█████████████████████████████████████| 96/96 [00:19<00:00,  4.85it/s]\n",
            "Evaluating(E(134)): BT(2.098, 3.372) CE(1.1166, 1.4514) Prec@1(76.800, 68.750): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 21.90it/s]\n",
            "Best Prec@1: 78.620, Many Prec@1: 0.778, Med Prec@1: 0.821, Few Prec@1: 0.000\n",
            "Training(E(135)): BT(0.214, 0.052) CE(0.4186, 0.4054) SCL_v(1.684898, 1.825641) CL(0.336919, 0.296146 Prec@1(80.493, 83.594): 100%|█████████████████████████████████████| 96/96 [00:20<00:00,  4.64it/s]\n",
            "Evaluating(E(135)): BT(1.945, 2.910) CE(0.9540, 1.4072) Prec@1(79.110, 68.750): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 25.78it/s]\n",
            "Best Prec@1: 79.110, Many Prec@1: 0.777, Med Prec@1: 0.847, Few Prec@1: 0.000\n",
            "Training(E(136)): BT(0.224, 0.050) CE(0.4346, 0.4870) SCL_v(1.738199, 1.845766) CL(0.249139, 0.197502 Prec@1(78.996, 74.219): 100%|█████████████████████████████████████| 96/96 [00:21<00:00,  4.43it/s]\n",
            "Evaluating(E(136)): BT(2.013, 3.051) CE(1.0406, 1.1210) Prec@1(78.610, 68.750): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 24.74it/s]\n",
            "Best Prec@1: 79.110, Many Prec@1: 0.777, Med Prec@1: 0.847, Few Prec@1: 0.000\n",
            "Training(E(137)): BT(0.208, 0.053) CE(0.4166, 0.3590) SCL_v(1.704913, 1.748815) CL(0.127779, 0.058909 Prec@1(79.907, 81.250): 100%|█████████████████████████████████████| 96/96 [00:20<00:00,  4.77it/s]\n",
            "Evaluating(E(137)): BT(2.646, 4.111) CE(0.9665, 1.5836) Prec@1(77.000, 68.750): 100%|█████████████████████████████████| 79/79 [00:04<00:00, 18.27it/s]\n",
            "Best Prec@1: 79.110, Many Prec@1: 0.777, Med Prec@1: 0.847, Few Prec@1: 0.000\n",
            "Training(E(138)): BT(0.208, 0.051) CE(0.4372, 0.4276) SCL_v(1.702192, 1.823630) CL(-0.012560, -0.090028 Prec@1(79.427, 81.250): 100%|███████████████████████████████████| 96/96 [00:20<00:00,  4.76it/s]\n",
            "Evaluating(E(138)): BT(1.988, 2.944) CE(1.1250, 1.3549) Prec@1(77.660, 68.750): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 25.42it/s]\n",
            "Best Prec@1: 79.110, Many Prec@1: 0.777, Med Prec@1: 0.847, Few Prec@1: 0.000\n",
            "Training(E(139)): BT(0.219, 0.056) CE(0.4110, 0.4629) SCL_v(1.691451, 1.790609) CL(-0.157408, -0.226860 Prec@1(80.379, 74.219): 100%|███████████████████████████████████| 96/96 [00:21<00:00,  4.54it/s]\n",
            "Evaluating(E(139)): BT(1.816, 2.719) CE(1.0777, 1.3590) Prec@1(77.680, 68.750): 100%|█████████████████████████████████| 79/79 [00:02<00:00, 27.64it/s]\n",
            "Best Prec@1: 79.110, Many Prec@1: 0.777, Med Prec@1: 0.847, Few Prec@1: 0.000\n",
            "Training(E(140)): BT(0.203, 0.050) CE(0.4145, 0.4025) SCL_v(1.694294, 1.806427) CL(-0.268387, -0.307888 Prec@1(79.997, 84.375): 100%|███████████████████████████████████| 96/96 [00:19<00:00,  4.90it/s]\n",
            "Evaluating(E(140)): BT(2.427, 3.830) CE(1.3924, 1.5781) Prec@1(75.160, 68.750): 100%|█████████████████████████████████| 79/79 [00:04<00:00, 19.40it/s]\n",
            "Best Prec@1: 79.110, Many Prec@1: 0.777, Med Prec@1: 0.847, Few Prec@1: 0.000\n",
            "Training(E(141)): BT(0.284, 0.136) CE(0.4119, 0.3354) SCL_v(1.678950, 1.584784) CL(0.439253, 0.439373 Prec@1(79.907, 79.688): 100%|█████████████████████████████████████| 96/96 [00:27<00:00,  3.49it/s]\n",
            "Evaluating(E(141)): BT(2.436, 3.385) CE(1.1932, 0.8029) Prec@1(77.710, 75.000): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 22.27it/s]\n",
            "Best Prec@1: 79.110, Many Prec@1: 0.777, Med Prec@1: 0.847, Few Prec@1: 0.000\n",
            "Training(E(142)): BT(0.206, 0.055) CE(0.4111, 0.3646) SCL_v(1.672631, 1.625010) CL(0.428377, 0.425954 Prec@1(80.339, 85.156): 100%|█████████████████████████████████████| 96/96 [00:19<00:00,  4.82it/s]\n",
            "Evaluating(E(142)): BT(1.958, 3.071) CE(1.2264, 0.8805) Prec@1(77.970, 75.000): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 23.91it/s]\n",
            "Best Prec@1: 79.110, Many Prec@1: 0.777, Med Prec@1: 0.847, Few Prec@1: 0.000\n",
            "Training(E(143)): BT(0.217, 0.050) CE(0.4025, 0.4002) SCL_v(1.668634, 1.800958) CL(0.407803, 0.406131 Prec@1(80.428, 78.125): 100%|█████████████████████████████████████| 96/96 [00:20<00:00,  4.58it/s]\n",
            "Evaluating(E(143)): BT(1.881, 2.796) CE(1.3039, 0.8982) Prec@1(76.130, 75.000): 100%|█████████████████████████████████| 79/79 [00:02<00:00, 26.78it/s]\n",
            "Best Prec@1: 79.110, Many Prec@1: 0.777, Med Prec@1: 0.847, Few Prec@1: 0.000\n",
            "Training(E(144)): BT(0.208, 0.055) CE(0.4010, 0.3219) SCL_v(1.677097, 1.631927) CL(0.383810, 0.364598 Prec@1(80.941, 86.719): 100%|█████████████████████████████████████| 96/96 [00:20<00:00,  4.74it/s]\n",
            "Evaluating(E(144)): BT(2.430, 3.383) CE(0.9415, 1.0940) Prec@1(79.170, 81.250): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 22.35it/s]\n",
            "Best Prec@1: 79.170, Many Prec@1: 0.796, Med Prec@1: 0.775, Few Prec@1: 0.000\n",
            "Training(E(145)): BT(0.209, 0.051) CE(0.3943, 0.4200) SCL_v(1.662121, 1.764786) CL(0.337827, 0.305690 Prec@1(81.535, 82.031): 100%|█████████████████████████████████████| 96/96 [00:20<00:00,  4.74it/s]\n",
            "Evaluating(E(145)): BT(2.026, 3.193) CE(1.0739, 1.2068) Prec@1(78.780, 75.000): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 22.88it/s]\n",
            "Best Prec@1: 79.170, Many Prec@1: 0.796, Med Prec@1: 0.775, Few Prec@1: 0.000\n",
            "Training(E(146)): BT(0.211, 0.050) CE(0.4156, 0.3343) SCL_v(1.681160, 1.615183) CL(0.275871, 0.230935 Prec@1(80.111, 84.375): 100%|█████████████████████████████████████| 96/96 [00:20<00:00,  4.70it/s]\n",
            "Evaluating(E(146)): BT(1.991, 3.001) CE(1.0542, 1.1772) Prec@1(78.310, 68.750): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 25.03it/s]\n",
            "Best Prec@1: 79.170, Many Prec@1: 0.796, Med Prec@1: 0.775, Few Prec@1: 0.000\n",
            "Training(E(147)): BT(0.209, 0.052) CE(0.3814, 0.4313) SCL_v(1.641777, 1.677034) CL(0.184583, 0.131329 Prec@1(81.047, 78.125): 100%|█████████████████████████████████████| 96/96 [00:20<00:00,  4.72it/s]\n",
            "Evaluating(E(147)): BT(2.184, 3.124) CE(1.1069, 1.4147) Prec@1(78.210, 62.500): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 24.15it/s]\n",
            "Best Prec@1: 79.170, Many Prec@1: 0.796, Med Prec@1: 0.775, Few Prec@1: 0.000\n",
            "Training(E(148)): BT(0.203, 0.052) CE(0.3855, 0.2808) SCL_v(1.654923, 1.411129) CL(0.076629, 0.018955 Prec@1(81.356, 82.812): 100%|█████████████████████████████████████| 96/96 [00:19<00:00,  4.89it/s]\n",
            "Evaluating(E(148)): BT(1.897, 2.938) CE(1.0552, 1.0402) Prec@1(77.930, 81.250): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 24.70it/s]\n",
            "Best Prec@1: 79.170, Many Prec@1: 0.796, Med Prec@1: 0.775, Few Prec@1: 0.000\n",
            "Training(E(149)): BT(0.214, 0.050) CE(0.3831, 0.3678) SCL_v(1.606631, 1.559041) CL(-0.036427, -0.087489 Prec@1(81.795, 85.156): 100%|███████████████████████████████████| 96/96 [00:20<00:00,  4.63it/s]\n",
            "Evaluating(E(149)): BT(1.865, 2.789) CE(1.1363, 1.1931) Prec@1(77.270, 68.750): 100%|█████████████████████████████████| 79/79 [00:02<00:00, 26.97it/s]\n",
            "Best Prec@1: 79.170, Many Prec@1: 0.796, Med Prec@1: 0.775, Few Prec@1: 0.000\n",
            "Training(E(150)): BT(0.207, 0.072) CE(0.3737, 0.3821) SCL_v(1.622225, 1.801885) CL(-0.140619, -0.190509 Prec@1(81.795, 82.812): 100%|███████████████████████████████████| 96/96 [00:20<00:00,  4.77it/s]\n",
            "Evaluating(E(150)): BT(2.572, 3.538) CE(1.2075, 1.0268) Prec@1(77.010, 81.250): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 21.41it/s]\n",
            "Best Prec@1: 79.170, Many Prec@1: 0.796, Med Prec@1: 0.775, Few Prec@1: 0.000\n",
            "Training(E(151)): BT(0.288, 0.127) CE(0.3737, 0.4144) SCL_v(1.613005, 1.699564) CL(0.423831, 0.417325 Prec@1(81.112, 76.562): 100%|█████████████████████████████████████| 96/96 [00:27<00:00,  3.45it/s]\n",
            "Evaluating(E(151)): BT(1.911, 2.856) CE(0.8889, 0.7623) Prec@1(77.080, 81.250): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 26.29it/s]\n",
            "Best Prec@1: 79.170, Many Prec@1: 0.796, Med Prec@1: 0.775, Few Prec@1: 0.000\n",
            "Training(E(152)): BT(0.201, 0.050) CE(0.3707, 0.2870) SCL_v(1.620839, 1.559233) CL(0.417185, 0.410504 Prec@1(81.844, 82.031): 100%|█████████████████████████████████████| 96/96 [00:19<00:00,  4.93it/s]\n",
            "Evaluating(E(152)): BT(2.660, 4.030) CE(1.1047, 1.0674) Prec@1(79.270, 75.000): 100%|█████████████████████████████████| 79/79 [00:04<00:00, 18.53it/s]\n",
            "Best Prec@1: 79.270, Many Prec@1: 0.806, Med Prec@1: 0.741, Few Prec@1: 0.000\n",
            "Training(E(153)): BT(0.207, 0.049) CE(0.3489, 0.3066) SCL_v(1.605661, 1.528331) CL(0.402158, 0.391322 Prec@1(83.228, 83.594): 100%|█████████████████████████████████████| 96/96 [00:20<00:00,  4.80it/s]\n",
            "Evaluating(E(153)): BT(1.819, 2.757) CE(0.8755, 0.9495) Prec@1(80.980, 81.250): 100%|█████████████████████████████████| 79/79 [00:02<00:00, 27.10it/s]\n",
            "Best Prec@1: 80.980, Many Prec@1: 0.811, Med Prec@1: 0.804, Few Prec@1: 0.000\n",
            "Training(E(154)): BT(0.222, 0.049) CE(0.3680, 0.3863) SCL_v(1.621295, 1.482171) CL(0.387210, 0.369271 Prec@1(83.016, 82.812): 100%|█████████████████████████████████████| 96/96 [00:21<00:00,  4.48it/s]\n",
            "Evaluating(E(154)): BT(1.873, 2.820) CE(0.9052, 0.8850) Prec@1(79.780, 87.500): 100%|█████████████████████████████████| 79/79 [00:02<00:00, 26.59it/s]\n",
            "Best Prec@1: 80.980, Many Prec@1: 0.811, Med Prec@1: 0.804, Few Prec@1: 0.000\n",
            "Training(E(155)): BT(0.203, 0.051) CE(0.3529, 0.2940) SCL_v(1.585165, 1.419565) CL(0.364179, 0.339083 Prec@1(82.544, 85.156): 100%|█████████████████████████████████████| 96/96 [00:19<00:00,  4.88it/s]\n",
            "Evaluating(E(155)): BT(2.615, 3.983) CE(1.0303, 1.0542) Prec@1(79.640, 75.000): 100%|█████████████████████████████████| 79/79 [00:04<00:00, 18.81it/s]\n",
            "Best Prec@1: 80.980, Many Prec@1: 0.811, Med Prec@1: 0.804, Few Prec@1: 0.000\n",
            "Training(E(156)): BT(0.198, 0.053) CE(0.3393, 0.2891) SCL_v(1.570609, 1.500899) CL(0.333637, 0.325229 Prec@1(83.773, 83.594): 100%|█████████████████████████████████████| 96/96 [00:19<00:00,  5.00it/s]\n",
            "Evaluating(E(156)): BT(1.808, 2.720) CE(1.0861, 1.2187) Prec@1(79.880, 75.000): 100%|█████████████████████████████████| 79/79 [00:02<00:00, 27.48it/s]\n",
            "Best Prec@1: 80.980, Many Prec@1: 0.811, Med Prec@1: 0.804, Few Prec@1: 0.000\n",
            "Training(E(157)): BT(0.218, 0.051) CE(0.3525, 0.3195) SCL_v(1.614607, 1.572101) CL(0.302280, 0.279282 Prec@1(83.366, 81.250): 100%|█████████████████████████████████████| 96/96 [00:21<00:00,  4.55it/s]\n",
            "Evaluating(E(157)): BT(1.860, 2.814) CE(0.9185, 1.1847) Prec@1(81.280, 68.750): 100%|█████████████████████████████████| 79/79 [00:02<00:00, 26.70it/s]\n",
            "Best Prec@1: 81.280, Many Prec@1: 0.822, Med Prec@1: 0.776, Few Prec@1: 0.000\n",
            "Training(E(158)): BT(0.205, 0.051) CE(0.3418, 0.2432) SCL_v(1.552413, 1.344047) CL(0.250724, 0.216805 Prec@1(83.455, 89.844): 100%|█████████████████████████████████████| 96/96 [00:19<00:00,  4.84it/s]\n",
            "Evaluating(E(158)): BT(2.183, 3.478) CE(1.1873, 1.2351) Prec@1(78.730, 75.000): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 21.05it/s]\n",
            "Best Prec@1: 81.280, Many Prec@1: 0.822, Med Prec@1: 0.776, Few Prec@1: 0.000\n",
            "Training(E(159)): BT(0.210, 0.050) CE(0.3405, 0.3028) SCL_v(1.569697, 1.462706) CL(0.190881, 0.149939 Prec@1(83.748, 87.500): 100%|█████████████████████████████████████| 96/96 [00:20<00:00,  4.72it/s]\n",
            "Evaluating(E(159)): BT(1.850, 2.752) CE(1.0868, 1.3748) Prec@1(78.930, 62.500): 100%|█████████████████████████████████| 79/79 [00:02<00:00, 27.18it/s]\n",
            "Best Prec@1: 81.280, Many Prec@1: 0.822, Med Prec@1: 0.776, Few Prec@1: 0.000\n",
            "Training(E(160)): BT(0.211, 0.053) CE(0.3432, 0.2594) SCL_v(1.565457, 1.423253) CL(0.118272, 0.080794 Prec@1(83.610, 85.156): 100%|█████████████████████████████████████| 96/96 [00:20<00:00,  4.69it/s]\n",
            "Evaluating(E(160)): BT(2.370, 3.323) CE(0.9034, 0.9714) Prec@1(80.950, 81.250): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 22.76it/s]\n",
            "Best Prec@1: 81.280, Many Prec@1: 0.822, Med Prec@1: 0.776, Few Prec@1: 0.000\n",
            "Training(E(161)): BT(0.286, 0.127) CE(0.3290, 0.2354) SCL_v(1.556081, 1.486116) CL(0.416764, 0.405541 Prec@1(84.334, 85.156): 100%|█████████████████████████████████████| 96/96 [00:27<00:00,  3.48it/s]\n",
            "Evaluating(E(161)): BT(2.097, 3.057) CE(1.2937, 1.1760) Prec@1(77.500, 62.500): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 24.67it/s]\n",
            "Best Prec@1: 81.280, Many Prec@1: 0.822, Med Prec@1: 0.776, Few Prec@1: 0.000\n",
            "Training(E(162)): BT(0.200, 0.057) CE(0.3182, 0.3635) SCL_v(1.530886, 1.511277) CL(0.409964, 0.408353 Prec@1(85.409, 83.594): 100%|█████████████████████████████████████| 96/96 [00:19<00:00,  4.93it/s]\n",
            "Evaluating(E(162)): BT(2.753, 3.974) CE(0.7582, 1.1635) Prec@1(82.650, 75.000): 100%|█████████████████████████████████| 79/79 [00:04<00:00, 19.07it/s]\n",
            "Best Prec@1: 82.650, Many Prec@1: 0.826, Med Prec@1: 0.830, Few Prec@1: 0.000\n",
            "Training(E(163)): BT(0.200, 0.050) CE(0.3187, 0.2452) SCL_v(1.528786, 1.612009) CL(0.402777, 0.397248 Prec@1(84.814, 91.406): 100%|█████████████████████████████████████| 96/96 [00:19<00:00,  4.97it/s]\n",
            "Evaluating(E(163)): BT(1.812, 2.727) CE(1.0170, 1.4072) Prec@1(80.970, 68.750): 100%|█████████████████████████████████| 79/79 [00:02<00:00, 27.37it/s]\n",
            "Best Prec@1: 82.650, Many Prec@1: 0.826, Med Prec@1: 0.830, Few Prec@1: 0.000\n",
            "Training(E(164)): BT(0.219, 0.051) CE(0.3193, 0.2640) SCL_v(1.525304, 1.412731) CL(0.391678, 0.399711 Prec@1(85.018, 83.594): 100%|█████████████████████████████████████| 96/96 [00:21<00:00,  4.52it/s]\n",
            "Evaluating(E(164)): BT(1.844, 2.774) CE(1.0186, 1.1453) Prec@1(81.080, 81.250): 100%|█████████████████████████████████| 79/79 [00:02<00:00, 27.04it/s]\n",
            "Best Prec@1: 82.650, Many Prec@1: 0.826, Med Prec@1: 0.830, Few Prec@1: 0.000\n",
            "Training(E(165)): BT(0.198, 0.055) CE(0.3238, 0.3507) SCL_v(1.528792, 1.725372) CL(0.386415, 0.380929 Prec@1(84.912, 84.375): 100%|█████████████████████████████████████| 96/96 [00:19<00:00,  5.01it/s]\n",
            "Evaluating(E(165)): BT(2.623, 4.061) CE(0.8549, 0.9442) Prec@1(81.680, 75.000): 100%|█████████████████████████████████| 79/79 [00:04<00:00, 18.33it/s]\n",
            "Best Prec@1: 82.650, Many Prec@1: 0.826, Med Prec@1: 0.830, Few Prec@1: 0.000\n",
            "Training(E(166)): BT(0.200, 0.056) CE(0.3085, 0.3609) SCL_v(1.508063, 1.541220) CL(0.368556, 0.363946 Prec@1(85.498, 86.719): 100%|█████████████████████████████████████| 96/96 [00:19<00:00,  4.96it/s]\n",
            "Evaluating(E(166)): BT(1.823, 2.726) CE(0.9136, 1.3703) Prec@1(82.030, 75.000): 100%|█████████████████████████████████| 79/79 [00:02<00:00, 27.51it/s]\n",
            "Best Prec@1: 82.650, Many Prec@1: 0.826, Med Prec@1: 0.830, Few Prec@1: 0.000\n",
            "Training(E(167)): BT(0.214, 0.063) CE(0.3084, 0.2484) SCL_v(1.516727, 1.485654) CL(0.352967, 0.334717 Prec@1(85.116, 87.500): 100%|█████████████████████████████████████| 96/96 [00:20<00:00,  4.64it/s]\n",
            "Evaluating(E(167)): BT(1.830, 2.739) CE(0.9252, 1.2803) Prec@1(81.850, 75.000): 100%|█████████████████████████████████| 79/79 [00:02<00:00, 27.41it/s]\n",
            "Best Prec@1: 82.650, Many Prec@1: 0.826, Med Prec@1: 0.830, Few Prec@1: 0.000\n",
            "Training(E(168)): BT(0.200, 0.049) CE(0.2958, 0.4377) SCL_v(1.501376, 1.733016) CL(0.332910, 0.329250 Prec@1(85.645, 82.031): 100%|█████████████████████████████████████| 96/96 [00:19<00:00,  4.95it/s]\n",
            "Evaluating(E(168)): BT(1.961, 3.084) CE(1.0191, 1.0349) Prec@1(81.200, 81.250): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 23.60it/s]\n",
            "Best Prec@1: 82.650, Many Prec@1: 0.826, Med Prec@1: 0.830, Few Prec@1: 0.000\n",
            "Training(E(169)): BT(0.210, 0.049) CE(0.2746, 0.3358) SCL_v(1.467761, 1.629217) CL(0.305677, 0.298458 Prec@1(86.922, 82.812): 100%|█████████████████████████████████████| 96/96 [00:20<00:00,  4.71it/s]\n",
            "Evaluating(E(169)): BT(1.877, 2.813) CE(0.8187, 1.1017) Prec@1(83.410, 81.250): 100%|█████████████████████████████████| 79/79 [00:02<00:00, 26.71it/s]\n",
            "Best Prec@1: 83.410, Many Prec@1: 0.837, Med Prec@1: 0.822, Few Prec@1: 0.000\n",
            "Training(E(170)): BT(0.208, 0.054) CE(0.2965, 0.3018) SCL_v(1.500301, 1.495158) CL(0.281851, 0.270548 Prec@1(85.465, 90.625): 100%|█████████████████████████████████████| 96/96 [00:20<00:00,  4.74it/s]\n",
            "Evaluating(E(170)): BT(2.329, 3.262) CE(0.9441, 1.0801) Prec@1(81.780, 75.000): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 23.13it/s]\n",
            "Best Prec@1: 83.410, Many Prec@1: 0.837, Med Prec@1: 0.822, Few Prec@1: 0.000\n",
            "Training(E(171)): BT(0.299, 0.128) CE(0.2911, 0.2674) SCL_v(1.497547, 1.312937) CL(0.401777, 0.388416 Prec@1(86.336, 87.500): 100%|█████████████████████████████████████| 96/96 [00:28<00:00,  3.32it/s]\n",
            "Evaluating(E(171)): BT(1.870, 2.834) CE(0.7416, 0.9525) Prec@1(83.910, 75.000): 100%|█████████████████████████████████| 79/79 [00:02<00:00, 26.52it/s]\n",
            "Best Prec@1: 83.910, Many Prec@1: 0.837, Med Prec@1: 0.847, Few Prec@1: 0.000\n",
            "Training(E(172)): BT(0.212, 0.053) CE(0.2866, 0.2874) SCL_v(1.477904, 1.543108) CL(0.389594, 0.386389 Prec@1(86.060, 86.719): 100%|█████████████████████████████████████| 96/96 [00:20<00:00,  4.67it/s]\n",
            "Evaluating(E(172)): BT(2.475, 3.427) CE(0.8907, 1.1006) Prec@1(82.910, 75.000): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 22.09it/s]\n",
            "Best Prec@1: 83.910, Many Prec@1: 0.837, Med Prec@1: 0.847, Few Prec@1: 0.000\n",
            "Training(E(173)): BT(0.200, 0.049) CE(0.2803, 0.2393) SCL_v(1.455635, 1.454812) CL(0.382766, 0.381858 Prec@1(87.093, 85.156): 100%|█████████████████████████████████████| 96/96 [00:19<00:00,  4.95it/s]\n",
            "Evaluating(E(173)): BT(1.826, 2.750) CE(0.7728, 1.1328) Prec@1(83.160, 75.000): 100%|█████████████████████████████████| 79/79 [00:02<00:00, 27.33it/s]\n",
            "Best Prec@1: 83.910, Many Prec@1: 0.837, Med Prec@1: 0.847, Few Prec@1: 0.000\n",
            "Training(E(174)): BT(0.216, 0.050) CE(0.2748, 0.3326) SCL_v(1.461916, 1.495923) CL(0.380142, 0.369938 Prec@1(86.263, 88.281): 100%|█████████████████████████████████████| 96/96 [00:20<00:00,  4.59it/s]\n",
            "Evaluating(E(174)): BT(1.782, 2.696) CE(0.8810, 1.1329) Prec@1(83.340, 75.000): 100%|█████████████████████████████████| 79/79 [00:02<00:00, 27.75it/s]\n",
            "Best Prec@1: 83.910, Many Prec@1: 0.837, Med Prec@1: 0.847, Few Prec@1: 0.000\n",
            "Training(E(175)): BT(0.200, 0.050) CE(0.2809, 0.2407) SCL_v(1.455605, 1.411845) CL(0.374017, 0.367039 Prec@1(86.377, 84.375): 100%|█████████████████████████████████████| 96/96 [00:19<00:00,  4.96it/s]\n",
            "Evaluating(E(175)): BT(2.852, 4.271) CE(0.9175, 1.3065) Prec@1(82.420, 81.250): 100%|█████████████████████████████████| 79/79 [00:04<00:00, 17.50it/s]\n",
            "Best Prec@1: 83.910, Many Prec@1: 0.837, Med Prec@1: 0.847, Few Prec@1: 0.000\n",
            "Training(E(176)): BT(0.200, 0.049) CE(0.2692, 0.2503) SCL_v(1.443195, 1.392312) CL(0.369018, 0.366930 Prec@1(87.256, 85.156): 100%|█████████████████████████████████████| 96/96 [00:19<00:00,  4.97it/s]\n",
            "Evaluating(E(176)): BT(1.829, 2.737) CE(0.8741, 1.3333) Prec@1(83.630, 68.750): 100%|█████████████████████████████████| 79/79 [00:02<00:00, 27.46it/s]\n",
            "Best Prec@1: 83.910, Many Prec@1: 0.837, Med Prec@1: 0.847, Few Prec@1: 0.000\n",
            "Training(E(177)): BT(0.215, 0.048) CE(0.2617, 0.3475) SCL_v(1.437111, 1.480761) CL(0.361202, 0.359115 Prec@1(87.443, 85.938): 100%|█████████████████████████████████████| 96/96 [00:20<00:00,  4.62it/s]\n",
            "Evaluating(E(177)): BT(1.838, 2.732) CE(0.8071, 1.0461) Prec@1(83.660, 75.000): 100%|█████████████████████████████████| 79/79 [00:02<00:00, 27.27it/s]\n",
            "Best Prec@1: 83.910, Many Prec@1: 0.837, Med Prec@1: 0.847, Few Prec@1: 0.000\n",
            "Training(E(178)): BT(0.201, 0.049) CE(0.2577, 0.2720) SCL_v(1.428136, 1.392061) CL(0.353840, 0.354384 Prec@1(87.419, 85.938): 100%|█████████████████████████████████████| 96/96 [00:19<00:00,  4.94it/s]\n",
            "Evaluating(E(178)): BT(2.094, 3.361) CE(0.8936, 1.0783) Prec@1(82.960, 75.000): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 21.88it/s]\n",
            "Best Prec@1: 83.910, Many Prec@1: 0.837, Med Prec@1: 0.847, Few Prec@1: 0.000\n",
            "Training(E(179)): BT(0.205, 0.048) CE(0.2601, 0.2673) SCL_v(1.430034, 1.433617) CL(0.349261, 0.348677 Prec@1(87.866, 86.719): 100%|█████████████████████████████████████| 96/96 [00:19<00:00,  4.85it/s]\n",
            "Evaluating(E(179)): BT(1.919, 2.941) CE(0.9577, 1.0947) Prec@1(82.970, 68.750): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 25.55it/s]\n",
            "Best Prec@1: 83.910, Many Prec@1: 0.837, Med Prec@1: 0.847, Few Prec@1: 0.000\n",
            "Training(E(180)): BT(0.204, 0.053) CE(0.2546, 0.2517) SCL_v(1.419484, 1.358019) CL(0.344064, 0.345928 Prec@1(87.484, 86.719): 100%|█████████████████████████████████████| 96/96 [00:19<00:00,  4.83it/s]\n",
            "Evaluating(E(180)): BT(2.191, 3.108) CE(0.9174, 1.1865) Prec@1(83.090, 75.000): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 24.30it/s]\n",
            "Best Prec@1: 83.910, Many Prec@1: 0.837, Med Prec@1: 0.847, Few Prec@1: 0.000\n",
            "Training(E(181)): BT(0.282, 0.128) CE(0.2453, 0.2539) SCL_v(1.406465, 1.369133) CL(0.387579, 0.386631 Prec@1(88.070, 87.500): 100%|█████████████████████████████████████| 96/96 [00:27<00:00,  3.53it/s]\n",
            "Evaluating(E(181)): BT(1.846, 2.765) CE(0.9509, 1.2208) Prec@1(82.610, 75.000): 100%|█████████████████████████████████| 79/79 [00:02<00:00, 27.08it/s]\n",
            "Best Prec@1: 83.910, Many Prec@1: 0.837, Med Prec@1: 0.847, Few Prec@1: 0.000\n",
            "Training(E(182)): BT(0.200, 0.050) CE(0.2555, 0.2078) SCL_v(1.408500, 1.283773) CL(0.385423, 0.385590 Prec@1(88.005, 90.625): 100%|█████████████████████████████████████| 96/96 [00:19<00:00,  4.96it/s]\n",
            "Evaluating(E(182)): BT(2.274, 3.587) CE(0.8715, 1.0586) Prec@1(83.390, 75.000): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 20.59it/s]\n",
            "Best Prec@1: 83.910, Many Prec@1: 0.837, Med Prec@1: 0.847, Few Prec@1: 0.000\n",
            "Training(E(183)): BT(0.204, 0.049) CE(0.2425, 0.2381) SCL_v(1.413857, 1.508310) CL(0.382767, 0.384272 Prec@1(88.118, 87.500): 100%|█████████████████████████████████████| 96/96 [00:19<00:00,  4.88it/s]\n",
            "Evaluating(E(183)): BT(1.823, 2.740) CE(0.8875, 0.9943) Prec@1(83.560, 75.000): 100%|█████████████████████████████████| 79/79 [00:02<00:00, 27.28it/s]\n",
            "Best Prec@1: 83.910, Many Prec@1: 0.837, Med Prec@1: 0.847, Few Prec@1: 0.000\n",
            "Training(E(184)): BT(0.201, 0.055) CE(0.2347, 0.1608) SCL_v(1.387355, 1.316129) CL(0.381971, 0.383260 Prec@1(88.395, 87.500): 100%|█████████████████████████████████████| 96/96 [00:19<00:00,  4.91it/s]\n",
            "Evaluating(E(184)): BT(2.516, 3.569) CE(0.9705, 1.0940) Prec@1(82.610, 75.000): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 21.27it/s]\n",
            "Best Prec@1: 83.910, Many Prec@1: 0.837, Med Prec@1: 0.847, Few Prec@1: 0.000\n",
            "Training(E(185)): BT(0.201, 0.062) CE(0.2422, 0.2060) SCL_v(1.403725, 1.355056) CL(0.382747, 0.382536 Prec@1(88.379, 89.844): 100%|█████████████████████████████████████| 96/96 [00:19<00:00,  4.94it/s]\n",
            "Evaluating(E(185)): BT(1.821, 2.722) CE(0.8836, 1.2143) Prec@1(83.680, 75.000): 100%|█████████████████████████████████| 79/79 [00:02<00:00, 27.09it/s]\n",
            "Best Prec@1: 83.910, Many Prec@1: 0.837, Med Prec@1: 0.847, Few Prec@1: 0.000\n",
            "Training(E(186)): BT(0.217, 0.050) CE(0.2449, 0.2248) SCL_v(1.403780, 1.429974) CL(0.380084, 0.378527 Prec@1(88.403, 91.406): 100%|█████████████████████████████████████| 96/96 [00:20<00:00,  4.58it/s]\n",
            "Evaluating(E(186)): BT(1.848, 2.762) CE(0.8237, 1.1582) Prec@1(84.200, 75.000): 100%|█████████████████████████████████| 79/79 [00:02<00:00, 27.12it/s]\n",
            "Best Prec@1: 84.200, Many Prec@1: 0.852, Med Prec@1: 0.802, Few Prec@1: 0.000\n",
            "Training(E(187)): BT(0.206, 0.057) CE(0.2289, 0.2069) SCL_v(1.384795, 1.414499) CL(0.377219, 0.380428 Prec@1(88.908, 92.188): 100%|█████████████████████████████████████| 96/96 [00:20<00:00,  4.79it/s]\n",
            "Evaluating(E(187)): BT(2.483, 3.422) CE(0.9038, 1.2266) Prec@1(83.640, 75.000): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 22.12it/s]\n",
            "Best Prec@1: 84.200, Many Prec@1: 0.852, Med Prec@1: 0.802, Few Prec@1: 0.000\n",
            "Training(E(188)): BT(0.203, 0.050) CE(0.2437, 0.3432) SCL_v(1.393385, 1.418526) CL(0.376525, 0.380277 Prec@1(88.273, 86.719): 100%|█████████████████████████████████████| 96/96 [00:19<00:00,  4.88it/s]\n",
            "Evaluating(E(188)): BT(1.977, 2.942) CE(0.8737, 1.3188) Prec@1(83.590, 75.000): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 25.04it/s]\n",
            "Best Prec@1: 84.200, Many Prec@1: 0.852, Med Prec@1: 0.802, Few Prec@1: 0.000\n",
            "Training(E(189)): BT(0.212, 0.052) CE(0.2321, 0.2110) SCL_v(1.381335, 1.492810) CL(0.376585, 0.371952 Prec@1(88.997, 94.531): 100%|█████████████████████████████████████| 96/96 [00:20<00:00,  4.68it/s]\n",
            "Evaluating(E(189)): BT(1.853, 2.789) CE(0.8967, 1.3533) Prec@1(83.490, 75.000): 100%|█████████████████████████████████| 79/79 [00:02<00:00, 26.84it/s]\n",
            "Best Prec@1: 84.200, Many Prec@1: 0.852, Med Prec@1: 0.802, Few Prec@1: 0.000\n",
            "Training(E(190)): BT(0.201, 0.062) CE(0.2320, 0.1051) SCL_v(1.377135, 1.319248) CL(0.374461, 0.376856 Prec@1(88.908, 92.188): 100%|█████████████████████████████████████| 96/96 [00:19<00:00,  4.91it/s]\n",
            "Evaluating(E(190)): BT(2.649, 3.720) CE(0.9030, 1.3474) Prec@1(83.470, 75.000): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 20.47it/s]\n",
            "Best Prec@1: 84.200, Many Prec@1: 0.852, Med Prec@1: 0.802, Few Prec@1: 0.000\n",
            "Training(E(191)): BT(0.280, 0.183) CE(0.2196, 0.1452) SCL_v(1.374932, 1.295990) CL(0.383016, 0.387334 Prec@1(89.705, 91.406): 100%|█████████████████████████████████████| 96/96 [00:27<00:00,  3.54it/s]\n",
            "Evaluating(E(191)): BT(1.851, 2.796) CE(0.8936, 1.3318) Prec@1(83.610, 75.000): 100%|█████████████████████████████████| 79/79 [00:02<00:00, 26.83it/s]\n",
            "Best Prec@1: 84.200, Many Prec@1: 0.852, Med Prec@1: 0.802, Few Prec@1: 0.000\n",
            "Training(E(192)): BT(0.203, 0.050) CE(0.2294, 0.2505) SCL_v(1.393600, 1.347900) CL(0.387561, 0.391653 Prec@1(89.160, 85.938): 100%|█████████████████████████████████████| 96/96 [00:19<00:00,  4.89it/s]\n",
            "Evaluating(E(192)): BT(1.989, 3.234) CE(0.9050, 1.3510) Prec@1(83.570, 75.000): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 22.59it/s]\n",
            "Best Prec@1: 84.200, Many Prec@1: 0.852, Med Prec@1: 0.802, Few Prec@1: 0.000\n",
            "Training(E(193)): BT(0.210, 0.050) CE(0.2206, 0.1910) SCL_v(1.363141, 1.407261) CL(0.386762, 0.387265 Prec@1(89.518, 89.062): 100%|█████████████████████████████████████| 96/96 [00:20<00:00,  4.71it/s]\n",
            "Evaluating(E(193)): BT(1.843, 2.759) CE(0.8966, 1.3385) Prec@1(83.450, 75.000): 100%|█████████████████████████████████| 79/79 [00:02<00:00, 27.10it/s]\n",
            "Best Prec@1: 84.200, Many Prec@1: 0.852, Med Prec@1: 0.802, Few Prec@1: 0.000\n",
            "Training(E(194)): BT(0.208, 0.054) CE(0.2260, 0.1365) SCL_v(1.374026, 1.300174) CL(0.386763, 0.387271 Prec@1(89.323, 92.188): 100%|█████████████████████████████████████| 96/96 [00:20<00:00,  4.73it/s]\n",
            "Evaluating(E(194)): BT(2.194, 3.109) CE(0.8842, 1.3236) Prec@1(83.600, 75.000): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 24.14it/s]\n",
            "Best Prec@1: 84.200, Many Prec@1: 0.852, Med Prec@1: 0.802, Few Prec@1: 0.000\n",
            "Training(E(195)): BT(0.203, 0.050) CE(0.2229, 0.3287) SCL_v(1.368978, 1.563231) CL(0.385943, 0.390919 Prec@1(88.949, 83.594): 100%|█████████████████████████████████████| 96/96 [00:19<00:00,  4.90it/s]\n",
            "Evaluating(E(195)): BT(1.970, 3.032) CE(0.8896, 1.3186) Prec@1(83.590, 75.000): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 24.00it/s]\n",
            "Best Prec@1: 84.200, Many Prec@1: 0.852, Med Prec@1: 0.802, Few Prec@1: 0.000\n",
            "Training(E(196)): BT(0.212, 0.055) CE(0.2190, 0.1244) SCL_v(1.383620, 1.261757) CL(0.386307, 0.386469 Prec@1(89.079, 89.062): 100%|█████████████████████████████████████| 96/96 [00:20<00:00,  4.68it/s]\n",
            "Evaluating(E(196)): BT(1.846, 2.754) CE(0.8817, 1.3016) Prec@1(83.610, 75.000): 100%|█████████████████████████████████| 79/79 [00:02<00:00, 27.18it/s]\n",
            "Best Prec@1: 84.200, Many Prec@1: 0.852, Med Prec@1: 0.802, Few Prec@1: 0.000\n",
            "Training(E(197)): BT(0.222, 0.056) CE(0.2085, 0.2247) SCL_v(1.331600, 1.317533) CL(0.385101, 0.390579 Prec@1(89.738, 90.625): 100%|█████████████████████████████████████| 96/96 [00:21<00:00,  4.44it/s]\n",
            "Evaluating(E(197)): BT(1.856, 2.763) CE(0.8690, 1.2818) Prec@1(83.820, 75.000): 100%|█████████████████████████████████| 79/79 [00:02<00:00, 27.01it/s]\n",
            "Best Prec@1: 84.200, Many Prec@1: 0.852, Med Prec@1: 0.802, Few Prec@1: 0.000\n",
            "Training(E(198)): BT(0.201, 0.050) CE(0.2197, 0.1483) SCL_v(1.363727, 1.167626) CL(0.385163, 0.379400 Prec@1(89.714, 92.188): 100%|█████████████████████████████████████| 96/96 [00:19<00:00,  4.93it/s]\n",
            "Evaluating(E(198)): BT(1.937, 3.004) CE(0.8729, 1.2962) Prec@1(83.720, 75.000): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 24.48it/s]\n",
            "Best Prec@1: 84.200, Many Prec@1: 0.852, Med Prec@1: 0.802, Few Prec@1: 0.000\n",
            "Training(E(199)): BT(0.212, 0.053) CE(0.2174, 0.1997) SCL_v(1.362155, 1.429036) CL(0.384724, 0.384963 Prec@1(89.209, 89.062): 100%|█████████████████████████████████████| 96/96 [00:20<00:00,  4.67it/s]\n",
            "Evaluating(E(199)): BT(1.841, 2.753) CE(0.8788, 1.2734) Prec@1(83.750, 75.000): 100%|█████████████████████████████████| 79/79 [00:02<00:00, 27.26it/s]\n",
            "Best Prec@1: 84.200, Many Prec@1: 0.852, Med Prec@1: 0.802, Few Prec@1: 0.000\n",
            "Training(E(200)): BT(0.205, 0.054) CE(0.2294, 0.1987) SCL_v(1.366399, 1.304100) CL(0.385365, 0.388638 Prec@1(89.437, 89.062): 100%|█████████████████████████████████████| 96/96 [00:19<00:00,  4.81it/s]\n",
            "Evaluating(E(200)): BT(2.603, 3.597) CE(0.8938, 1.2902) Prec@1(83.730, 75.000): 100%|█████████████████████████████████| 79/79 [00:03<00:00, 21.09it/s]\n",
            "Best Prec@1: 84.200, Many Prec@1: 0.852, Med Prec@1: 0.802, Few Prec@1: 0.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qDbya7C6C5XV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}